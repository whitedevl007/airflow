[2023-05-19T11:38:28.362+0530] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: concurrent_bash_tasks.submitt_topology manual__2023-05-19T06:06:21.111209+00:00 [queued]>
[2023-05-19T11:38:28.371+0530] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: concurrent_bash_tasks.submitt_topology manual__2023-05-19T06:06:21.111209+00:00 [queued]>
[2023-05-19T11:38:28.371+0530] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2023-05-19T11:38:28.389+0530] {taskinstance.py:1350} INFO - Executing <Task(BashOperator): submitt_topology> on 2023-05-19 06:06:21.111209+00:00
[2023-05-19T11:38:28.393+0530] {standard_task_runner.py:57} INFO - Started process 11776 to run task
[2023-05-19T11:38:28.398+0530] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'concurrent_bash_tasks', 'submitt_topology', 'manual__2023-05-19T06:06:21.111209+00:00', '--job-id', '685', '--raw', '--subdir', 'DAGS_FOLDER/kafkastorm.py', '--cfg-path', '/tmp/tmphxfkacmo']
[2023-05-19T11:38:28.400+0530] {standard_task_runner.py:85} INFO - Job 685: Subtask submitt_topology
[2023-05-19T11:38:28.449+0530] {task_command.py:410} INFO - Running <TaskInstance: concurrent_bash_tasks.submitt_topology manual__2023-05-19T06:06:21.111209+00:00 [running]> on host nizam-HP-15-Notebook-PC
[2023-05-19T11:38:28.531+0530] {taskinstance.py:1568} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='concurrent_bash_tasks' AIRFLOW_CTX_TASK_ID='submitt_topology' AIRFLOW_CTX_EXECUTION_DATE='2023-05-19T06:06:21.111209+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-05-19T06:06:21.111209+00:00'
[2023-05-19T11:38:28.533+0530] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2023-05-19T11:38:28.534+0530] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'cd /home/nizam/project/Kafka-Storm && sparse run --name first_topology']
[2023-05-19T11:38:28.544+0530] {subprocess.py:86} INFO - Output:
[2023-05-19T11:38:42.439+0530] {subprocess.py:93} INFO - Cleaning from prior builds...
[2023-05-19T11:38:44.427+0530] {subprocess.py:93} INFO - Creating topology Uber-JAR...
[2023-05-19T11:39:08.897+0530] {subprocess.py:93} INFO - Uber-JAR created: /home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar
[2023-05-19T11:39:21.067+0530] {subprocess.py:93} INFO - Removing _resources temporary directory...SLF4J: Class path contains multiple SLF4J bindings.
[2023-05-19T11:39:21.069+0530] {subprocess.py:93} INFO - SLF4J: Found binding in [jar:file:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[2023-05-19T11:39:21.069+0530] {subprocess.py:93} INFO - SLF4J: Found binding in [jar:file:/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[2023-05-19T11:39:21.070+0530] {subprocess.py:93} INFO - SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[2023-05-19T11:39:21.074+0530] {subprocess.py:93} INFO - SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
[2023-05-19T11:39:23.767+0530] {subprocess.py:93} INFO - Running: /usr/lib/jvm/java-11-openjdk-amd64/bin/java -client -Ddaemon.name= -Dstorm.options= -Dstorm.home=/home/nizam/Downloads/apache-storm-1.2.3 -Dstorm.log.dir=/home/nizam/Downloads/apache-storm-1.2.3/logs -Djava.library.path=/usr/local/lib:/opt/local/lib:/usr/lib -Dstorm.conf.file= -cp /home/nizam/Downloads/apache-storm-1.2.3/*:/home/nizam/Downloads/apache-storm-1.2.3/lib/*:/home/nizam/Downloads/apache-storm-1.2.3/extlib/*:/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar:/home/nizam/Downloads/apache-storm-1.2.3/conf:/home/nizam/Downloads/apache-storm-1.2.3/bin -Dstorm.jar=/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar -Dstorm.dependency.jars= -Dstorm.dependency.artifacts={} org.apache.storm.flux.Flux --local --no-splash --sleep 9223372036854775807 /tmp/tmpceuo4yx0.yaml
[2023-05-19T11:39:23.980+0530] {subprocess.py:93} INFO - SLF4J: Class path contains multiple SLF4J bindings.
[2023-05-19T11:39:23.981+0530] {subprocess.py:93} INFO - SLF4J: Found binding in [jar:file:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[2023-05-19T11:39:23.982+0530] {subprocess.py:93} INFO - SLF4J: Found binding in [jar:file:/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[2023-05-19T11:39:23.982+0530] {subprocess.py:93} INFO - SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[2023-05-19T11:39:23.992+0530] {subprocess.py:93} INFO - SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
[2023-05-19T11:39:25.350+0530] {subprocess.py:93} INFO - Parsing file: /tmp/tmpceuo4yx0.yaml
[2023-05-19T11:39:25.447+0530] {subprocess.py:93} INFO - 1647 [main] INFO  o.a.s.f.p.FluxParser - loading YAML from input stream...
[2023-05-19T11:39:25.455+0530] {subprocess.py:93} INFO - 1657 [main] INFO  o.a.s.f.p.FluxParser - Not performing property substitution.
[2023-05-19T11:39:25.456+0530] {subprocess.py:93} INFO - 1657 [main] INFO  o.a.s.f.p.FluxParser - Not performing environment variable substitution.
[2023-05-19T11:39:25.637+0530] {subprocess.py:93} INFO - 1837 [main] INFO  o.a.s.f.FluxBuilder - Detected DSL topology...
[2023-05-19T11:39:25.900+0530] {subprocess.py:93} INFO - 2101 [main] WARN  o.a.s.u.Utils - STORM-VERSION new 1.2.3 old null
[2023-05-19T11:39:25.900+0530] {subprocess.py:93} INFO - ---------- TOPOLOGY DETAILS ----------
[2023-05-19T11:39:25.901+0530] {subprocess.py:93} INFO - Topology Name: first_topology
[2023-05-19T11:39:25.901+0530] {subprocess.py:93} INFO - --------------- SPOUTS ---------------
[2023-05-19T11:39:25.901+0530] {subprocess.py:93} INFO - kafka_spout [1] (org.apache.storm.flux.wrappers.spouts.FluxShellSpout)
[2023-05-19T11:39:25.901+0530] {subprocess.py:93} INFO - ---------------- BOLTS ---------------
[2023-05-19T11:39:25.901+0530] {subprocess.py:93} INFO - filter_bolt [1] (org.apache.storm.flux.wrappers.bolts.FluxShellBolt)
[2023-05-19T11:39:25.902+0530] {subprocess.py:93} INFO - --------------- STREAMS ---------------
[2023-05-19T11:39:25.902+0530] {subprocess.py:93} INFO - kafka_spout --FIELDS--> filter_bolt
[2023-05-19T11:39:25.902+0530] {subprocess.py:93} INFO - --------------------------------------
[2023-05-19T11:39:25.902+0530] {subprocess.py:93} INFO - 2103 [main] INFO  o.a.s.f.Flux - Running in local mode...
[2023-05-19T11:39:30.749+0530] {subprocess.py:93} INFO - 6951 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT
[2023-05-19T11:39:30.749+0530] {subprocess.py:93} INFO - 6951 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:host.name=nizam-HP-15-Notebook-PC
[2023-05-19T11:39:30.750+0530] {subprocess.py:93} INFO - 6951 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.version=11.0.19
[2023-05-19T11:39:30.750+0530] {subprocess.py:93} INFO - 6951 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.vendor=Ubuntu
[2023-05-19T11:39:30.750+0530] {subprocess.py:93} INFO - 6951 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64
[2023-05-19T11:39:30.750+0530] {subprocess.py:93} INFO - 6952 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.class.path=/home/nizam/Downloads/apache-storm-1.2.3/*:/home/nizam/Downloads/apache-storm-1.2.3/lib/ring-cors-0.1.5.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/metrics-graphite-3.1.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/kryo-3.0.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/objenesis-2.1.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-slf4j-impl-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-api-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/disruptor-3.3.11.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-over-slf4j-1.6.6.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-core-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/clojure-1.7.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/storm-core-1.2.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/minlog-1.3.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/servlet-api-2.5.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/reflectasm-1.10.1.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/metrics-core-3.1.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/storm-rename-hack-1.2.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/asm-5.0.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/slf4j-api-1.7.21.jar:/home/nizam/Downloads/apache-storm-1.2.3/extlib/*:/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar:/home/nizam/Downloads/apache-storm-1.2.3/conf:/home/nizam/Downloads/apache-storm-1.2.3/bin
[2023-05-19T11:39:30.751+0530] {subprocess.py:93} INFO - 6952 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib
[2023-05-19T11:39:30.751+0530] {subprocess.py:93} INFO - 6952 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.io.tmpdir=/tmp
[2023-05-19T11:39:30.751+0530] {subprocess.py:93} INFO - 6952 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.compiler=<NA>
[2023-05-19T11:39:30.751+0530] {subprocess.py:93} INFO - 6952 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:os.name=Linux
[2023-05-19T11:39:30.751+0530] {subprocess.py:93} INFO - 6952 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:os.arch=amd64
[2023-05-19T11:39:30.751+0530] {subprocess.py:93} INFO - 6953 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:os.version=5.19.0-41-generic
[2023-05-19T11:39:30.752+0530] {subprocess.py:93} INFO - 6953 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:user.name=nizam
[2023-05-19T11:39:30.752+0530] {subprocess.py:93} INFO - 6953 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:user.home=/home/nizam
[2023-05-19T11:39:30.752+0530] {subprocess.py:93} INFO - 6953 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:user.dir=/home/nizam/project/Kafka-Storm
[2023-05-19T11:39:30.778+0530] {subprocess.py:93} INFO - 6980 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 datadir /tmp/06bce963-9242-466b-9b85-54e12ebbe8ca/version-2 snapdir /tmp/06bce963-9242-466b-9b85-54e12ebbe8ca/version-2
[2023-05-19T11:39:30.848+0530] {subprocess.py:93} INFO - 7050 [main] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - binding to port 0.0.0.0/0.0.0.0:2000
[2023-05-19T11:39:30.859+0530] {subprocess.py:93} INFO - 7061 [main] INFO  o.a.s.zookeeper - Starting inprocess zookeeper at port 2000 and dir /tmp/06bce963-9242-466b-9b85-54e12ebbe8ca
[2023-05-19T11:39:31.068+0530] {subprocess.py:93} INFO - 7268 [main] INFO  o.a.s.d.nimbus - Starting Nimbus with conf {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.nimbus.zookeeper.acls.fixup=true, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=*****, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=["org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter"], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=null, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=["localhost"], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, backpressure.znode.timeout.secs=30, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/11de072a-27e3-4816-9633-8b7fb64c6b21, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/11de072a-27e3-4816-9633-8b7fb64c6b21, backpressure.znode.update.freq.secs=15, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, storm.nimbus.zookeeper.acls.check=true, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, logs.users=null, storm.cluster.metrics.consumer.publish.interval.secs=60, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, blobstore.superuser=nizam, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=[6700 6701 6702 6703], topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=["localhost"], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.thrift.socket.timeout.ms=600000, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, nimbus.host=localhost, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
[2023-05-19T11:39:31.070+0530] {subprocess.py:93} INFO - 7271 [main] INFO  o.a.s.n.NimbusInfo - Nimbus figures out its name to nizam-HP-15-Notebook-PC
[2023-05-19T11:39:31.301+0530] {subprocess.py:93} INFO - 7502 [main] INFO  o.a.s.s.o.a.c.u.Compatibility - Running in ZooKeeper 3.4.x compatibility mode
[2023-05-19T11:39:31.353+0530] {subprocess.py:93} INFO - 7555 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-19T11:39:31.363+0530] {subprocess.py:93} INFO - 7565 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT
[2023-05-19T11:39:31.363+0530] {subprocess.py:93} INFO - 7565 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:host.name=nizam-HP-15-Notebook-PC
[2023-05-19T11:39:31.364+0530] {subprocess.py:93} INFO - 7565 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.version=11.0.19
[2023-05-19T11:39:31.364+0530] {subprocess.py:93} INFO - 7565 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.vendor=Ubuntu
[2023-05-19T11:39:31.364+0530] {subprocess.py:93} INFO - 7565 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64
[2023-05-19T11:39:31.364+0530] {subprocess.py:93} INFO - 7565 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.class.path=/home/nizam/Downloads/apache-storm-1.2.3/*:/home/nizam/Downloads/apache-storm-1.2.3/lib/ring-cors-0.1.5.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/metrics-graphite-3.1.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/kryo-3.0.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/objenesis-2.1.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-slf4j-impl-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-api-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/disruptor-3.3.11.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-over-slf4j-1.6.6.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-core-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/clojure-1.7.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/storm-core-1.2.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/minlog-1.3.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/servlet-api-2.5.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/reflectasm-1.10.1.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/metrics-core-3.1.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/storm-rename-hack-1.2.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/asm-5.0.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/slf4j-api-1.7.21.jar:/home/nizam/Downloads/apache-storm-1.2.3/extlib/*:/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar:/home/nizam/Downloads/apache-storm-1.2.3/conf:/home/nizam/Downloads/apache-storm-1.2.3/bin
[2023-05-19T11:39:31.365+0530] {subprocess.py:93} INFO - 7566 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib
[2023-05-19T11:39:31.365+0530] {subprocess.py:93} INFO - 7566 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.io.tmpdir=/tmp
[2023-05-19T11:39:31.365+0530] {subprocess.py:93} INFO - 7566 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.compiler=<NA>
[2023-05-19T11:39:31.365+0530] {subprocess.py:93} INFO - 7566 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:os.name=Linux
[2023-05-19T11:39:31.368+0530] {subprocess.py:93} INFO - 7566 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:os.arch=amd64
[2023-05-19T11:39:31.368+0530] {subprocess.py:93} INFO - 7568 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:os.version=5.19.0-41-generic
[2023-05-19T11:39:31.368+0530] {subprocess.py:93} INFO - 7568 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:user.name=nizam
[2023-05-19T11:39:31.369+0530] {subprocess.py:93} INFO - 7569 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:user.home=/home/nizam
[2023-05-19T11:39:31.369+0530] {subprocess.py:93} INFO - 7569 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:user.dir=/home/nizam/project/Kafka-Storm
[2023-05-19T11:39:31.369+0530] {subprocess.py:93} INFO - 7570 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@1dd64243
[2023-05-19T11:39:31.432+0530] {subprocess.py:93} INFO - 7633 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-19T11:39:31.442+0530] {subprocess.py:93} INFO - 7642 [main] INFO  o.a.s.b.FileBlobStoreImpl - Creating new blob store based in /tmp/11de072a-27e3-4816-9633-8b7fb64c6b21/blobs
[2023-05-19T11:39:31.449+0530] {subprocess.py:93} INFO - 7650 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-19T11:39:31.454+0530] {subprocess.py:93} INFO - 7656 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59124
[2023-05-19T11:39:31.455+0530] {subprocess.py:93} INFO - 7656 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-19T11:39:31.458+0530] {subprocess.py:93} INFO - 7660 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-19T11:39:31.460+0530] {subprocess.py:93} INFO - 7662 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@413eaf5d
[2023-05-19T11:39:31.475+0530] {subprocess.py:93} INFO - 7676 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-19T11:39:31.475+0530] {subprocess.py:93} INFO - 7677 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-19T11:39:31.477+0530] {subprocess.py:93} INFO - 7679 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-19T11:39:31.478+0530] {subprocess.py:93} INFO - 7679 [main] INFO  o.a.s.d.nimbus - Using default scheduler
[2023-05-19T11:39:31.479+0530] {subprocess.py:93} INFO - 7681 [main] INFO  o.a.s.n.NimbusInfo - Nimbus figures out its name to nizam-HP-15-Notebook-PC
[2023-05-19T11:39:31.486+0530] {subprocess.py:93} INFO - 7688 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59124
[2023-05-19T11:39:31.492+0530] {subprocess.py:93} INFO - 7692 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59128
[2023-05-19T11:39:31.493+0530] {subprocess.py:93} INFO - 7694 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59128
[2023-05-19T11:39:31.494+0530] {subprocess.py:93} INFO - 7695 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.p.FileTxnLog - Creating new log file: log.1
[2023-05-19T11:39:31.515+0530] {subprocess.py:93} INFO - 7716 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100004b04d70000, negotiated timeout = 20000
[2023-05-19T11:39:31.522+0530] {subprocess.py:93} INFO - 7724 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100004b04d70000 with negotiated timeout 20000 for client /127.0.0.1:59124
[2023-05-19T11:39:31.531+0530] {subprocess.py:93} INFO - 7733 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100004b04d70001, negotiated timeout = 20000
[2023-05-19T11:39:31.532+0530] {subprocess.py:93} INFO - 7733 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-19T11:39:31.533+0530] {subprocess.py:93} INFO - 7735 [main-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
[2023-05-19T11:39:31.534+0530] {subprocess.py:93} INFO - 7736 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-19T11:39:31.536+0530] {subprocess.py:93} INFO - 7738 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100004b04d70001 with negotiated timeout 20000 for client /127.0.0.1:59128
[2023-05-19T11:39:31.538+0530] {subprocess.py:93} INFO - 7740 [main] INFO  o.a.s.n.NimbusInfo - Nimbus figures out its name to nizam-HP-15-Notebook-PC
[2023-05-19T11:39:31.555+0530] {subprocess.py:93} INFO - 7757 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-19T11:39:31.556+0530] {subprocess.py:93} INFO - 7758 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@448892f1
[2023-05-19T11:39:31.558+0530] {subprocess.py:93} INFO - 7759 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-19T11:39:31.560+0530] {subprocess.py:93} INFO - 7761 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-19T11:39:31.562+0530] {subprocess.py:93} INFO - 7764 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-19T11:39:31.563+0530] {subprocess.py:93} INFO - 7764 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59144
[2023-05-19T11:39:31.564+0530] {subprocess.py:93} INFO - 7765 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59144
[2023-05-19T11:39:31.570+0530] {subprocess.py:93} INFO - 7771 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100004b04d70002 with negotiated timeout 20000 for client /127.0.0.1:59144
[2023-05-19T11:39:31.570+0530] {subprocess.py:93} INFO - 7772 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100004b04d70002, negotiated timeout = 20000
[2023-05-19T11:39:31.570+0530] {subprocess.py:93} INFO - 7772 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-19T11:39:31.571+0530] {subprocess.py:93} INFO - 7773 [main-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
[2023-05-19T11:39:31.616+0530] {subprocess.py:93} INFO - 7818 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-19T11:39:31.621+0530] {subprocess.py:93} INFO - 7823 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x100004b04d70002
[2023-05-19T11:39:31.626+0530] {subprocess.py:93} INFO - 7828 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x100004b04d70002 closed
[2023-05-19T11:39:31.627+0530] {subprocess.py:93} INFO - 7828 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:59144 which had sessionid 0x100004b04d70002
[2023-05-19T11:39:31.628+0530] {subprocess.py:93} INFO - 7828 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x100004b04d70002
[2023-05-19T11:39:31.630+0530] {subprocess.py:93} INFO - 7832 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-19T11:39:31.636+0530] {subprocess.py:93} INFO - 7837 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@2820b369
[2023-05-19T11:39:31.642+0530] {subprocess.py:93} INFO - 7840 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-19T11:39:31.643+0530] {subprocess.py:93} INFO - 7843 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-19T11:39:31.646+0530] {subprocess.py:93} INFO - 7848 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@4f6ff62
[2023-05-19T11:39:31.647+0530] {subprocess.py:93} INFO - 7848 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-19T11:39:31.648+0530] {subprocess.py:93} INFO - 7850 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59152
[2023-05-19T11:39:31.649+0530] {subprocess.py:93} INFO - 7850 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-19T11:39:31.650+0530] {subprocess.py:93} INFO - 7852 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59152
[2023-05-19T11:39:31.654+0530] {subprocess.py:93} INFO - 7856 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-19T11:39:31.659+0530] {subprocess.py:93} INFO - 7858 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100004b04d70003 with negotiated timeout 20000 for client /127.0.0.1:59152
[2023-05-19T11:39:31.659+0530] {subprocess.py:93} INFO - 7856 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-19T11:39:31.660+0530] {subprocess.py:93} INFO - 7858 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100004b04d70003, negotiated timeout = 20000
[2023-05-19T11:39:31.660+0530] {subprocess.py:93} INFO - 7860 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-19T11:39:31.661+0530] {subprocess.py:93} INFO - 7862 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59168
[2023-05-19T11:39:31.662+0530] {subprocess.py:93} INFO - 7863 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59168
[2023-05-19T11:39:31.662+0530] {subprocess.py:93} INFO - 7864 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-19T11:39:31.665+0530] {subprocess.py:93} INFO - 7867 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100004b04d70004 with negotiated timeout 20000 for client /127.0.0.1:59168
[2023-05-19T11:39:31.665+0530] {subprocess.py:93} INFO - 7867 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100004b04d70004, negotiated timeout = 20000
[2023-05-19T11:39:31.666+0530] {subprocess.py:93} INFO - 7868 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-19T11:39:32.739+0530] {subprocess.py:93} INFO - 8941 [main] INFO  o.a.s.zookeeper - Queued up for leader lock.
[2023-05-19T11:39:32.756+0530] {subprocess.py:93} INFO - 8957 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x100004b04d70001 type:create cxid:0x1 zxid:0x12 txntype:-1 reqpath:n/a Error Path:/storm/leader-lock Error:KeeperErrorCode = NoNode for /storm/leader-lock
[2023-05-19T11:39:32.763+0530] {subprocess.py:93} INFO - 8964 [Curator-Framework-0] WARN  o.a.s.s.o.a.c.u.ZKPaths - The version of ZooKeeper being used doesn't support Container nodes. CreateMode.PERSISTENT will be used instead.
[2023-05-19T11:39:32.780+0530] {subprocess.py:93} INFO - 8981 [main] INFO  o.a.s.d.m.MetricsUtils - Using statistics reporter plugin:org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter
[2023-05-19T11:39:32.782+0530] {subprocess.py:93} INFO - 8983 [main] INFO  o.a.s.d.m.r.JmxPreparableReporter - Preparing...
[2023-05-19T11:39:32.822+0530] {subprocess.py:93} INFO - 9023 [main-EventThread] INFO  o.a.s.z.Zookeeper - active-topology-blobs [] local-topology-blobs [] diff-topology-blobs []
[2023-05-19T11:39:32.823+0530] {subprocess.py:93} INFO - 9025 [main-EventThread] INFO  o.a.s.z.Zookeeper - active-topology-dependencies [] local-blobs [] diff-topology-dependencies []
[2023-05-19T11:39:32.824+0530] {subprocess.py:93} INFO - 9026 [main-EventThread] INFO  o.a.s.z.Zookeeper - Accepting leadership, all active topologies and corresponding dependencies found locally.
[2023-05-19T11:39:32.826+0530] {subprocess.py:93} INFO - 9028 [main] INFO  o.a.s.d.common - Started statistics report plugin...
[2023-05-19T11:39:32.861+0530] {subprocess.py:93} INFO - 9062 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-19T11:39:32.862+0530] {subprocess.py:93} INFO - 9063 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@74badf19
[2023-05-19T11:39:32.864+0530] {subprocess.py:93} INFO - 9065 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-19T11:39:32.864+0530] {subprocess.py:93} INFO - 9065 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-19T11:39:32.866+0530] {subprocess.py:93} INFO - 9067 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-19T11:39:32.867+0530] {subprocess.py:93} INFO - 9067 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59176
[2023-05-19T11:39:32.867+0530] {subprocess.py:93} INFO - 9067 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59176
[2023-05-19T11:39:32.871+0530] {subprocess.py:93} INFO - 9073 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100004b04d70005 with negotiated timeout 20000 for client /127.0.0.1:59176
[2023-05-19T11:39:32.871+0530] {subprocess.py:93} INFO - 9073 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100004b04d70005, negotiated timeout = 20000
[2023-05-19T11:39:32.872+0530] {subprocess.py:93} INFO - 9073 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-19T11:39:32.878+0530] {subprocess.py:93} INFO - 9080 [main-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
[2023-05-19T11:39:32.887+0530] {subprocess.py:93} INFO - 9085 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-19T11:39:32.888+0530] {subprocess.py:93} INFO - 9086 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x100004b04d70005
[2023-05-19T11:39:32.889+0530] {subprocess.py:93} INFO - 9088 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x100004b04d70005 closed
[2023-05-19T11:39:32.890+0530] {subprocess.py:93} INFO - 9088 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] WARN  o.a.s.s.o.a.z.s.NIOServerCnxn - Unable to read additional data from client sessionid 0x100004b04d70005, likely client has closed socket
[2023-05-19T11:39:32.890+0530] {subprocess.py:93} INFO - 9089 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x100004b04d70005
[2023-05-19T11:39:32.891+0530] {subprocess.py:93} INFO - 9089 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:59176 which had sessionid 0x100004b04d70005
[2023-05-19T11:39:32.892+0530] {subprocess.py:93} INFO - 9093 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-19T11:39:32.893+0530] {subprocess.py:93} INFO - 9094 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@4efe014f
[2023-05-19T11:39:32.895+0530] {subprocess.py:93} INFO - 9097 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-19T11:39:32.898+0530] {subprocess.py:93} INFO - 9099 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-19T11:39:32.899+0530] {subprocess.py:93} INFO - 9101 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-19T11:39:32.900+0530] {subprocess.py:93} INFO - 9101 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@66dd04e2
[2023-05-19T11:39:32.902+0530] {subprocess.py:93} INFO - 9104 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59184
[2023-05-19T11:39:32.902+0530] {subprocess.py:93} INFO - 9104 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-19T11:39:32.904+0530] {subprocess.py:93} INFO - 9106 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59184
[2023-05-19T11:39:32.907+0530] {subprocess.py:93} INFO - 9109 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-19T11:39:32.908+0530] {subprocess.py:93} INFO - 9109 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-19T11:39:32.908+0530] {subprocess.py:93} INFO - 9110 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59198
[2023-05-19T11:39:32.908+0530] {subprocess.py:93} INFO - 9110 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100004b04d70006 with negotiated timeout 20000 for client /127.0.0.1:59184
[2023-05-19T11:39:32.909+0530] {subprocess.py:93} INFO - 9111 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-19T11:39:32.910+0530] {subprocess.py:93} INFO - 9111 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100004b04d70006, negotiated timeout = 20000
[2023-05-19T11:39:32.910+0530] {subprocess.py:93} INFO - 9111 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-19T11:39:32.910+0530] {subprocess.py:93} INFO - 9111 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59198
[2023-05-19T11:39:32.912+0530] {subprocess.py:93} INFO - 9113 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100004b04d70007 with negotiated timeout 20000 for client /127.0.0.1:59198
[2023-05-19T11:39:32.913+0530] {subprocess.py:93} INFO - 9114 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100004b04d70007, negotiated timeout = 20000
[2023-05-19T11:39:32.914+0530] {subprocess.py:93} INFO - 9116 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-19T11:39:32.915+0530] {subprocess.py:93} INFO - 9117 [main-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
[2023-05-19T11:39:32.918+0530] {subprocess.py:93} INFO - 9119 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-19T11:39:32.919+0530] {subprocess.py:93} INFO - 9121 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x100004b04d70007
[2023-05-19T11:39:32.921+0530] {subprocess.py:93} INFO - 9123 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:59198 which had sessionid 0x100004b04d70007
[2023-05-19T11:39:32.922+0530] {subprocess.py:93} INFO - 9123 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x100004b04d70007 closed
[2023-05-19T11:39:32.923+0530] {subprocess.py:93} INFO - 9123 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x100004b04d70007
[2023-05-19T11:39:32.923+0530] {subprocess.py:93} INFO - 9124 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-19T11:39:32.924+0530] {subprocess.py:93} INFO - 9125 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@4b511e61
[2023-05-19T11:39:32.926+0530] {subprocess.py:93} INFO - 9127 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-19T11:39:32.926+0530] {subprocess.py:93} INFO - 9127 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-19T11:39:32.927+0530] {subprocess.py:93} INFO - 9128 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59200
[2023-05-19T11:39:32.927+0530] {subprocess.py:93} INFO - 9129 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-19T11:39:32.927+0530] {subprocess.py:93} INFO - 9129 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59200
[2023-05-19T11:39:32.930+0530] {subprocess.py:93} INFO - 9132 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100004b04d70008 with negotiated timeout 20000 for client /127.0.0.1:59200
[2023-05-19T11:39:32.931+0530] {subprocess.py:93} INFO - 9133 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100004b04d70008, negotiated timeout = 20000
[2023-05-19T11:39:32.933+0530] {subprocess.py:93} INFO - 9135 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-19T11:39:32.972+0530] {subprocess.py:93} INFO - 9174 [main] INFO  o.a.s.z.Zookeeper - Staring ZK Curator
[2023-05-19T11:39:32.972+0530] {subprocess.py:93} INFO - 9174 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-19T11:39:32.973+0530] {subprocess.py:93} INFO - 9175 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@785ef70f
[2023-05-19T11:39:32.976+0530] {subprocess.py:93} INFO - 9178 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-19T11:39:32.976+0530] {subprocess.py:93} INFO - 9178 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-19T11:39:32.978+0530] {subprocess.py:93} INFO - 9179 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59212
[2023-05-19T11:39:32.978+0530] {subprocess.py:93} INFO - 9180 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-19T11:39:32.979+0530] {subprocess.py:93} INFO - 9180 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59212
[2023-05-19T11:39:32.981+0530] {subprocess.py:93} INFO - 9183 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100004b04d70009 with negotiated timeout 20000 for client /127.0.0.1:59212
[2023-05-19T11:39:32.982+0530] {subprocess.py:93} INFO - 9183 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100004b04d70009, negotiated timeout = 20000
[2023-05-19T11:39:32.982+0530] {subprocess.py:93} INFO - 9184 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-19T11:39:32.985+0530] {subprocess.py:93} INFO - 9187 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-19T11:39:32.987+0530] {subprocess.py:93} INFO - 9189 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x100004b04d70009
[2023-05-19T11:39:32.989+0530] {subprocess.py:93} INFO - 9190 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x100004b04d70009 closed
[2023-05-19T11:39:32.991+0530] {subprocess.py:93} INFO - 9191 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x100004b04d70009
[2023-05-19T11:39:32.991+0530] {subprocess.py:93} INFO - 9191 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:59212 which had sessionid 0x100004b04d70009
[2023-05-19T11:39:32.991+0530] {subprocess.py:93} INFO - 9193 [main] INFO  o.a.s.z.Zookeeper - Staring ZK Curator
[2023-05-19T11:39:32.991+0530] {subprocess.py:93} INFO - 9193 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-19T11:39:32.992+0530] {subprocess.py:93} INFO - 9193 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@2d2af12e
[2023-05-19T11:39:32.993+0530] {subprocess.py:93} INFO - 9195 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-19T11:39:32.994+0530] {subprocess.py:93} INFO - 9195 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-19T11:39:32.994+0530] {subprocess.py:93} INFO - 9196 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-19T11:39:32.996+0530] {subprocess.py:93} INFO - 9197 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59226
[2023-05-19T11:39:32.996+0530] {subprocess.py:93} INFO - 9197 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59226
[2023-05-19T11:39:32.999+0530] {subprocess.py:93} INFO - 9200 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100004b04d7000a with negotiated timeout 20000 for client /127.0.0.1:59226
[2023-05-19T11:39:32.999+0530] {subprocess.py:93} INFO - 9200 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100004b04d7000a, negotiated timeout = 20000
[2023-05-19T11:39:32.999+0530] {subprocess.py:93} INFO - 9201 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-19T11:39:33.016+0530] {subprocess.py:93} INFO - 9218 [main] INFO  o.a.s.l.Localizer - Reconstruct localized resource: /tmp/1ac7e498-61d0-47d3-9537-b750e113c580/supervisor/usercache
[2023-05-19T11:39:33.017+0530] {subprocess.py:93} INFO - 9218 [main] WARN  o.a.s.l.Localizer - No left over resources found for any user during reconstructing of local resources at: /tmp/1ac7e498-61d0-47d3-9537-b750e113c580/supervisor/usercache
[2023-05-19T11:39:33.027+0530] {subprocess.py:93} INFO - 9226 [main] INFO  o.a.s.d.s.Supervisor - Starting Supervisor with conf {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.nimbus.zookeeper.acls.fixup=true, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=*****, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=[org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=null, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=[localhost], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, backpressure.znode.timeout.secs=30, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/11de072a-27e3-4816-9633-8b7fb64c6b21, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/1ac7e498-61d0-47d3-9537-b750e113c580, backpressure.znode.update.freq.secs=15, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, storm.nimbus.zookeeper.acls.check=true, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, logs.users=null, storm.cluster.metrics.consumer.publish.interval.secs=60, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, blobstore.superuser=nizam, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=[1024, 1025, 1026], topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=[localhost], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.thrift.socket.timeout.ms=600000, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, nimbus.host=localhost, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
[2023-05-19T11:39:33.044+0530] {subprocess.py:93} INFO - 9245 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1024 Starting in state EMPTY - assignment null
[2023-05-19T11:39:33.044+0530] {subprocess.py:93} INFO - 9246 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1025 Starting in state EMPTY - assignment null
[2023-05-19T11:39:33.044+0530] {subprocess.py:93} INFO - 9246 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1026 Starting in state EMPTY - assignment null
[2023-05-19T11:39:33.045+0530] {subprocess.py:93} INFO - 9247 [main] INFO  o.a.s.l.AsyncLocalizer - Cleaning up unused topologies in /tmp/1ac7e498-61d0-47d3-9537-b750e113c580/supervisor/stormdist
[2023-05-19T11:39:33.060+0530] {subprocess.py:93} INFO - 9262 [main] INFO  o.a.s.d.s.Supervisor - Starting supervisor with id 5d2bfb48-6713-4c03-afa9-325967805910 at host nizam-HP-15-Notebook-PC.
[2023-05-19T11:39:33.065+0530] {subprocess.py:93} INFO - 9267 [main] INFO  o.a.s.z.Zookeeper - Staring ZK Curator
[2023-05-19T11:39:33.066+0530] {subprocess.py:93} INFO - 9267 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-19T11:39:33.067+0530] {subprocess.py:93} INFO - 9269 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@fefb66c
[2023-05-19T11:39:33.070+0530] {subprocess.py:93} INFO - 9271 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-19T11:39:33.072+0530] {subprocess.py:93} INFO - 9273 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-19T11:39:33.073+0530] {subprocess.py:93} INFO - 9274 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-19T11:39:33.073+0530] {subprocess.py:93} INFO - 9274 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59238
[2023-05-19T11:39:33.073+0530] {subprocess.py:93} INFO - 9274 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59238
[2023-05-19T11:39:33.075+0530] {subprocess.py:93} INFO - 9277 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100004b04d7000b with negotiated timeout 20000 for client /127.0.0.1:59238
[2023-05-19T11:39:33.075+0530] {subprocess.py:93} INFO - 9277 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100004b04d7000b, negotiated timeout = 20000
[2023-05-19T11:39:33.076+0530] {subprocess.py:93} INFO - 9277 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-19T11:39:33.077+0530] {subprocess.py:93} INFO - 9279 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-19T11:39:33.079+0530] {subprocess.py:93} INFO - 9281 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x100004b04d7000b
[2023-05-19T11:39:33.081+0530] {subprocess.py:93} INFO - 9283 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x100004b04d7000b closed
[2023-05-19T11:39:33.082+0530] {subprocess.py:93} INFO - 9283 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x100004b04d7000b
[2023-05-19T11:39:33.082+0530] {subprocess.py:93} INFO - 9284 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:59238 which had sessionid 0x100004b04d7000b
[2023-05-19T11:39:33.083+0530] {subprocess.py:93} INFO - 9284 [main] INFO  o.a.s.z.Zookeeper - Staring ZK Curator
[2023-05-19T11:39:33.083+0530] {subprocess.py:93} INFO - 9284 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-19T11:39:33.084+0530] {subprocess.py:93} INFO - 9285 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@4ba1c1a2
[2023-05-19T11:39:33.085+0530] {subprocess.py:93} INFO - 9287 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-19T11:39:33.087+0530] {subprocess.py:93} INFO - 9288 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-19T11:39:33.088+0530] {subprocess.py:93} INFO - 9289 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-19T11:39:33.088+0530] {subprocess.py:93} INFO - 9289 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59248
[2023-05-19T11:39:33.089+0530] {subprocess.py:93} INFO - 9291 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59248
[2023-05-19T11:39:33.092+0530] {subprocess.py:93} INFO - 9294 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100004b04d7000c with negotiated timeout 20000 for client /127.0.0.1:59248
[2023-05-19T11:39:33.092+0530] {subprocess.py:93} INFO - 9294 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100004b04d7000c, negotiated timeout = 20000
[2023-05-19T11:39:33.093+0530] {subprocess.py:93} INFO - 9295 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-19T11:39:33.104+0530] {subprocess.py:93} INFO - 9306 [main] INFO  o.a.s.l.Localizer - Reconstruct localized resource: /tmp/31b2f9fc-1176-44b9-8518-81bcf761451c/supervisor/usercache
[2023-05-19T11:39:33.105+0530] {subprocess.py:93} INFO - 9306 [main] WARN  o.a.s.l.Localizer - No left over resources found for any user during reconstructing of local resources at: /tmp/31b2f9fc-1176-44b9-8518-81bcf761451c/supervisor/usercache
[2023-05-19T11:39:33.109+0530] {subprocess.py:93} INFO - 9308 [main] INFO  o.a.s.d.s.Supervisor - Starting Supervisor with conf {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.nimbus.zookeeper.acls.fixup=true, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=*****, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=[org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=null, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=[localhost], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, backpressure.znode.timeout.secs=30, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/11de072a-27e3-4816-9633-8b7fb64c6b21, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/31b2f9fc-1176-44b9-8518-81bcf761451c, backpressure.znode.update.freq.secs=15, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, storm.nimbus.zookeeper.acls.check=true, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, logs.users=null, storm.cluster.metrics.consumer.publish.interval.secs=60, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, blobstore.superuser=nizam, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=[1027, 1028, 1029], topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=[localhost], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.thrift.socket.timeout.ms=600000, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, nimbus.host=localhost, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
[2023-05-19T11:39:33.116+0530] {subprocess.py:93} INFO - 9318 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1027 Starting in state EMPTY - assignment null
[2023-05-19T11:39:33.118+0530] {subprocess.py:93} INFO - 9319 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1028 Starting in state EMPTY - assignment null
[2023-05-19T11:39:33.118+0530] {subprocess.py:93} INFO - 9320 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1029 Starting in state EMPTY - assignment null
[2023-05-19T11:39:33.118+0530] {subprocess.py:93} INFO - 9320 [main] INFO  o.a.s.l.AsyncLocalizer - Cleaning up unused topologies in /tmp/31b2f9fc-1176-44b9-8518-81bcf761451c/supervisor/stormdist
[2023-05-19T11:39:33.119+0530] {subprocess.py:93} INFO - 9321 [main] INFO  o.a.s.d.s.Supervisor - Starting supervisor with id 46de6844-db96-474a-9165-2fa39be4cf89 at host nizam-HP-15-Notebook-PC.
[2023-05-19T11:39:33.130+0530] {subprocess.py:93} INFO - 9332 [main] WARN  o.a.s.u.Utils - STORM-VERSION new 1.2.3 old 1.2.3
[2023-05-19T11:39:33.213+0530] {subprocess.py:93} INFO - 9415 [main] INFO  o.a.s.d.nimbus - Received topology submission for first_topology (storm-1.2.3 JDK-11.0.19) with conf {topology.max.task.parallelism=null, topology.submitter.principal=, pystorm.log.backup_count=10, topology.acker.executors=1, topology.eventlogger.executors=0, pystorm.log.level=info, topology.workers=1, storm.zookeeper.superACL=null, pystorm.log.max_bytes=1000000, topology.python.path=/first_topology/bin/python, topology.users=clojure.lang.LazySeq@1, topology.submitter.user=nizam, topology.kryo.register=null, sudo_user=, virtualenv_root=, storm.workers.list=[], topology.kryo.decorators=clojure.lang.LazySeq@1, storm.id=first_topology-1-1684476573, topology.name=first_topology}
[2023-05-19T11:39:33.229+0530] {subprocess.py:93} INFO - 9431 [main] INFO  o.a.s.d.nimbus - uploadedJar
[2023-05-19T11:39:33.269+0530] {subprocess.py:93} INFO - 9471 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x100004b04d70001 type:create cxid:0x9 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/storm/blobstoremaxkeysequencenumber Error:KeeperErrorCode = NoNode for /storm/blobstoremaxkeysequencenumber
[2023-05-19T11:39:33.287+0530] {subprocess.py:93} INFO - 9488 [main] INFO  o.a.s.cluster - setup-path/blobstore/first_topology-1-1684476573-stormconf.ser/nizam-HP-15-Notebook-PC:6627-1
[2023-05-19T11:39:33.336+0530] {subprocess.py:93} INFO - 9538 [main] INFO  o.a.s.cluster - setup-path/blobstore/first_topology-1-1684476573-stormcode.ser/nizam-HP-15-Notebook-PC:6627-1
[2023-05-19T11:39:33.395+0530] {subprocess.py:93} INFO - 9597 [main] INFO  o.a.s.d.nimbus - desired replication count 1 achieved, current-replication-count for conf key = 1, current-replication-count for code key = 1, current-replication-count for jar key = 1
[2023-05-19T11:39:33.522+0530] {subprocess.py:93} INFO - 9724 [main] INFO  o.a.s.d.nimbus - Activating first_topology: first_topology-1-1684476573
[2023-05-19T11:39:33.930+0530] {subprocess.py:93} INFO - 10130 [timer] INFO  o.a.s.s.EvenScheduler - Available slots: (["5d2bfb48-6713-4c03-afa9-325967805910" 1024] ["5d2bfb48-6713-4c03-afa9-325967805910" 1025] ["5d2bfb48-6713-4c03-afa9-325967805910" 1026] ["46de6844-db96-474a-9165-2fa39be4cf89" 1027] ["46de6844-db96-474a-9165-2fa39be4cf89" 1028] ["46de6844-db96-474a-9165-2fa39be4cf89" 1029])
[2023-05-19T11:39:34.073+0530] {subprocess.py:93} INFO - 10275 [timer] INFO  o.a.s.d.nimbus - Setting new assignment for topology id first_topology-1-1684476573: #org.apache.storm.daemon.common.Assignment{:master-code-dir "/tmp/11de072a-27e3-4816-9633-8b7fb64c6b21", :node->host {"5d2bfb48-6713-4c03-afa9-325967805910" "nizam-HP-15-Notebook-PC"}, :executor->node+port {[2 2] ["5d2bfb48-6713-4c03-afa9-325967805910" 1024], [1 1] ["5d2bfb48-6713-4c03-afa9-325967805910" 1024], [3 3] ["5d2bfb48-6713-4c03-afa9-325967805910" 1024]}, :executor->start-time-secs {[1 1] 1684476573, [2 2] 1684476573, [3 3] 1684476573}, :worker->resources {["5d2bfb48-6713-4c03-afa9-325967805910" 1024] [0.0 0.0 0.0]}, :owner "nizam"}
[2023-05-19T11:39:35.051+0530] {subprocess.py:93} INFO - 11253 [SLOT_1024] INFO  o.a.s.d.s.Slot - STATE EMPTY msInState: 2008 -> WAITING_FOR_BASIC_LOCALIZATION msInState: 0
[2023-05-19T11:39:35.052+0530] {subprocess.py:93} INFO - 11254 [Async Localizer] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-19T11:39:35.054+0530] {subprocess.py:93} INFO - 11255 [Async Localizer] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@77921486
[2023-05-19T11:39:35.056+0530] {subprocess.py:93} INFO - 11257 [Async Localizer] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-19T11:39:35.056+0530] {subprocess.py:93} INFO - 11257 [Async Localizer-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-19T11:39:35.057+0530] {subprocess.py:93} INFO - 11258 [Async Localizer] INFO  o.a.s.b.FileBlobStoreImpl - Creating new blob store based in /tmp/11de072a-27e3-4816-9633-8b7fb64c6b21/blobs
[2023-05-19T11:39:35.057+0530] {subprocess.py:93} INFO - 11258 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59262
[2023-05-19T11:39:35.058+0530] {subprocess.py:93} INFO - 11260 [Async Localizer-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-19T11:39:35.060+0530] {subprocess.py:93} INFO - 11262 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59262
[2023-05-19T11:39:35.062+0530] {subprocess.py:93} INFO - 11264 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100004b04d7000d with negotiated timeout 20000 for client /127.0.0.1:59262
[2023-05-19T11:39:35.064+0530] {subprocess.py:93} INFO - 11265 [Async Localizer-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100004b04d7000d, negotiated timeout = 20000
[2023-05-19T11:39:35.065+0530] {subprocess.py:93} INFO - 11267 [Async Localizer-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-19T11:39:35.080+0530] {subprocess.py:93} INFO - 11282 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-19T11:39:35.084+0530] {subprocess.py:93} INFO - 11285 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x100004b04d7000d
[2023-05-19T11:39:35.086+0530] {subprocess.py:93} INFO - 11287 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:59262 which had sessionid 0x100004b04d7000d
[2023-05-19T11:39:35.087+0530] {subprocess.py:93} INFO - 11289 [Async Localizer-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x100004b04d7000d
[2023-05-19T11:39:35.088+0530] {subprocess.py:93} INFO - 11290 [Async Localizer] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x100004b04d7000d closed
[2023-05-19T11:39:35.131+0530] {subprocess.py:93} INFO - 11332 [Async Localizer] INFO  o.a.s.l.AsyncLocalizer - Extracting resources from jar at /home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar to /tmp/1ac7e498-61d0-47d3-9537-b750e113c580/supervisor/tmp/12792d73-e24b-46a3-a6f4-06e15cd4bdd1/
[2023-05-19T11:39:35.157+0530] {subprocess.py:93} INFO - 11359 [SLOT_1024] INFO  o.a.s.d.s.Slot - STATE WAITING_FOR_BASIC_LOCALIZATION msInState: 106 -> WAITING_FOR_BLOB_LOCALIZATION msInState: 0
[2023-05-19T11:39:35.165+0530] {subprocess.py:93} INFO - 11367 [SLOT_1024] INFO  o.a.s.d.s.Container - Setting up 5d2bfb48-6713-4c03-afa9-325967805910:b9a091d4-0556-4442-aa67-ceef525907a9
[2023-05-19T11:39:35.167+0530] {subprocess.py:93} INFO - 11368 [SLOT_1024] INFO  o.a.s.d.s.Container - GET worker-user for b9a091d4-0556-4442-aa67-ceef525907a9
[2023-05-19T11:39:35.185+0530] {subprocess.py:93} INFO - 11387 [SLOT_1024] INFO  o.a.s.d.s.Container - SET worker-user b9a091d4-0556-4442-aa67-ceef525907a9 nizam
[2023-05-19T11:39:35.195+0530] {subprocess.py:93} INFO - 11397 [SLOT_1024] INFO  o.a.s.d.worker - Launching worker for first_topology-1-1684476573 on 5d2bfb48-6713-4c03-afa9-325967805910:1024 with id b9a091d4-0556-4442-aa67-ceef525907a9 and conf {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.nimbus.zookeeper.acls.fixup=true, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=*****, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=["org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter"], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=null, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=["localhost"], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, backpressure.znode.timeout.secs=30, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/11de072a-27e3-4816-9633-8b7fb64c6b21, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/1ac7e498-61d0-47d3-9537-b750e113c580, backpressure.znode.update.freq.secs=15, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, storm.nimbus.zookeeper.acls.check=true, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, logs.users=null, storm.cluster.metrics.consumer.publish.interval.secs=60, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, blobstore.superuser=nizam, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=clojure.lang.LazySeq@ff880, topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=["localhost"], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.thrift.socket.timeout.ms=600000, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, nimbus.host=localhost, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
[2023-05-19T11:39:35.196+0530] {subprocess.py:93} INFO - 11398 [SLOT_1024] INFO  o.a.s.m.StormMetricRegistry - Starting metrics reporters...
[2023-05-19T11:39:35.205+0530] {subprocess.py:93} INFO - 11407 [SLOT_1024] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-19T11:39:35.209+0530] {subprocess.py:93} INFO - 11409 [SLOT_1024] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@2cd62391
[2023-05-19T11:39:35.210+0530] {subprocess.py:93} INFO - 11412 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-19T11:39:35.211+0530] {subprocess.py:93} INFO - 11412 [SLOT_1024] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-19T11:39:35.211+0530] {subprocess.py:93} INFO - 11413 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-19T11:39:35.212+0530] {subprocess.py:93} INFO - 11413 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59278
[2023-05-19T11:39:35.212+0530] {subprocess.py:93} INFO - 11414 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59278
[2023-05-19T11:39:35.215+0530] {subprocess.py:93} INFO - 11416 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100004b04d7000e with negotiated timeout 20000 for client /127.0.0.1:59278
[2023-05-19T11:39:35.215+0530] {subprocess.py:93} INFO - 11416 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100004b04d7000e, negotiated timeout = 20000
[2023-05-19T11:39:35.215+0530] {subprocess.py:93} INFO - 11416 [SLOT_1024-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-19T11:39:35.215+0530] {subprocess.py:93} INFO - 11417 [SLOT_1024-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
[2023-05-19T11:39:35.218+0530] {subprocess.py:93} INFO - 11420 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-19T11:39:35.220+0530] {subprocess.py:93} INFO - 11421 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x100004b04d7000e
[2023-05-19T11:39:35.221+0530] {subprocess.py:93} INFO - 11423 [SLOT_1024-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x100004b04d7000e
[2023-05-19T11:39:35.222+0530] {subprocess.py:93} INFO - 11423 [SLOT_1024] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x100004b04d7000e closed
[2023-05-19T11:39:35.222+0530] {subprocess.py:93} INFO - 11422 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:59278 which had sessionid 0x100004b04d7000e
[2023-05-19T11:39:35.223+0530] {subprocess.py:93} INFO - 11425 [SLOT_1024] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-19T11:39:35.225+0530] {subprocess.py:93} INFO - 11427 [SLOT_1024] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@1cdc4bc1
[2023-05-19T11:39:35.227+0530] {subprocess.py:93} INFO - 11428 [SLOT_1024] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-19T11:39:35.227+0530] {subprocess.py:93} INFO - 11428 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-19T11:39:35.228+0530] {subprocess.py:93} INFO - 11429 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-19T11:39:35.228+0530] {subprocess.py:93} INFO - 11429 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59282
[2023-05-19T11:39:35.228+0530] {subprocess.py:93} INFO - 11430 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59282
[2023-05-19T11:39:35.229+0530] {subprocess.py:93} INFO - 11431 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100004b04d7000f with negotiated timeout 20000 for client /127.0.0.1:59282
[2023-05-19T11:39:35.230+0530] {subprocess.py:93} INFO - 11432 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100004b04d7000f, negotiated timeout = 20000
[2023-05-19T11:39:35.231+0530] {subprocess.py:93} INFO - 11433 [SLOT_1024-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-19T11:39:35.244+0530] {subprocess.py:93} INFO - 11446 [SLOT_1024] INFO  o.a.s.s.a.AuthUtils - Got AutoCreds []
[2023-05-19T11:39:35.249+0530] {subprocess.py:93} INFO - 11451 [SLOT_1024] INFO  o.a.s.d.worker - Reading Assignments.
[2023-05-19T11:39:35.590+0530] {subprocess.py:93} INFO - 11792 [SLOT_1024] INFO  o.a.s.d.worker - Registering IConnectionCallbacks for 5d2bfb48-6713-4c03-afa9-325967805910:1024
[2023-05-19T11:39:35.758+0530] {subprocess.py:93} INFO - 11960 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor filter_bolt:[2 2]
[2023-05-19T11:39:35.809+0530] {subprocess.py:93} INFO - 12011 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks filter_bolt:[2 2]
[2023-05-19T11:39:35.953+0530] {subprocess.py:93} INFO - WARNING: An illegal reflective access operation has occurred
[2023-05-19T11:39:35.954+0530] {subprocess.py:93} INFO - WARNING: Illegal reflective access by com.esotericsoftware.kryo.util.UnsafeUtil (file:/home/nizam/Downloads/apache-storm-1.2.3/lib/kryo-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int,java.lang.Object)
[2023-05-19T11:39:35.954+0530] {subprocess.py:93} INFO - WARNING: Please consider reporting this to the maintainers of com.esotericsoftware.kryo.util.UnsafeUtil
[2023-05-19T11:39:35.954+0530] {subprocess.py:93} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2023-05-19T11:39:35.955+0530] {subprocess.py:93} INFO - WARNING: All illegal access operations will be denied in a future release
[2023-05-19T11:39:36.299+0530] {subprocess.py:93} INFO - 12501 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor filter_bolt:[2 2]
[2023-05-19T11:39:36.326+0530] {subprocess.py:93} INFO - 12527 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor kafka_spout:[3 3]
[2023-05-19T11:39:36.333+0530] {subprocess.py:93} INFO - 12535 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks kafka_spout:[3 3]
[2023-05-19T11:39:36.349+0530] {subprocess.py:93} INFO - 12551 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor kafka_spout:[3 3]
[2023-05-19T11:39:36.366+0530] {subprocess.py:93} INFO - 12568 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor __acker:[1 1]
[2023-05-19T11:39:36.368+0530] {subprocess.py:93} INFO - 12569 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks __acker:[1 1]
[2023-05-19T11:39:36.372+0530] {subprocess.py:93} INFO - 12574 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor __acker:[1 1]
[2023-05-19T11:39:36.385+0530] {subprocess.py:93} INFO - 12587 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor __system:[-1 -1]
[2023-05-19T11:39:36.386+0530] {subprocess.py:93} INFO - 12588 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks __system:[-1 -1]
[2023-05-19T11:39:36.394+0530] {subprocess.py:93} INFO - 12596 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor __system:[-1 -1]
[2023-05-19T11:39:36.438+0530] {subprocess.py:93} INFO - 12639 [SLOT_1024] INFO  o.a.s.d.worker - Started with log levels: {"" #object[org.apache.logging.log4j.Level 0x6a770877 "INFO"], "org.apache.zookeeper" #object[org.apache.logging.log4j.Level 0x7c4534fc "WARN"]}
[2023-05-19T11:39:36.446+0530] {subprocess.py:93} INFO - 12647 [refresh-active-timer] INFO  o.a.s.d.worker - All connections are ready for worker 5d2bfb48-6713-4c03-afa9-325967805910:1024 with id b9a091d4-0556-4442-aa67-ceef525907a9
[2023-05-19T11:39:36.452+0530] {subprocess.py:93} INFO - 12653 [SLOT_1024] INFO  o.a.s.d.worker - Worker has topology config {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.nimbus.zookeeper.acls.fixup=true, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=*****, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=["org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter"], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, topology.submitter.principal=, pystorm.log.backup_count=10, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=1, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=["localhost"], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, backpressure.znode.timeout.secs=30, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/11de072a-27e3-4816-9633-8b7fb64c6b21, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, pystorm.log.level=info, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/11de072a-27e3-4816-9633-8b7fb64c6b21, backpressure.znode.update.freq.secs=15, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, storm.nimbus.zookeeper.acls.check=true, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, storm.zookeeper.superACL=null, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, pystorm.log.max_bytes=1000000, logs.users=null, storm.cluster.metrics.consumer.publish.interval.secs=60, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, topology.python.path=/first_topology/bin/python, blobstore.superuser=nizam, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=[6700 6701 6702 6703], topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, topology.users=[], nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.submitter.user=nizam, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, topology.kryo.register=null, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=["localhost"], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.thrift.socket.timeout.ms=600000, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, sudo_user=, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], virtualenv_root=, drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.workers.list=[], topology.kryo.decorators=[], storm.id=first_topology-1-1684476573, topology.name=first_topology, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, nimbus.host=localhost, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
[2023-05-19T11:39:36.453+0530] {subprocess.py:93} INFO - 12654 [SLOT_1024] INFO  o.a.s.d.worker - Worker b9a091d4-0556-4442-aa67-ceef525907a9 for storm first_topology-1-1684476573 on 5d2bfb48-6713-4c03-afa9-325967805910:1024 has finished loading
[2023-05-19T11:39:36.453+0530] {subprocess.py:93} INFO - 12655 [SLOT_1024] INFO  o.a.s.d.s.Container - SET worker-user b9a091d4-0556-4442-aa67-ceef525907a9 nizam
[2023-05-19T11:39:36.455+0530] {subprocess.py:93} INFO - 12657 [SLOT_1024] INFO  o.a.s.d.s.Slot - STATE WAITING_FOR_BLOB_LOCALIZATION msInState: 1298 -> WAITING_FOR_WORKER_START msInState: 0 topo:first_topology-1-1684476573 worker:b9a091d4-0556-4442-aa67-ceef525907a9
[2023-05-19T11:39:36.456+0530] {subprocess.py:93} INFO - 12657 [SLOT_1024] INFO  o.a.s.d.s.Slot - SLOT 1024: Changing current assignment from null to LocalAssignment(topology_id:first_topology-1-1684476573, executors:[ExecutorInfo(task_start:2, task_end:2), ExecutorInfo(task_start:1, task_end:1), ExecutorInfo(task_start:3, task_end:3)], resources:WorkerResources(mem_on_heap:0.0, mem_off_heap:0.0, cpu:0.0), owner:nizam)
[2023-05-19T11:39:36.463+0530] {subprocess.py:93} INFO - 12664 [SLOT_1024] INFO  o.a.s.d.s.Slot - STATE WAITING_FOR_WORKER_START msInState: 7 topo:first_topology-1-1684476573 worker:b9a091d4-0556-4442-aa67-ceef525907a9 -> RUNNING msInState: 0 topo:first_topology-1-1684476573 worker:b9a091d4-0556-4442-aa67-ceef525907a9
[2023-05-19T11:39:37.456+0530] {subprocess.py:93} INFO - 13658 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.d.executor - Opening spout kafka_spout:(3)
[2023-05-19T11:39:37.465+0530] {subprocess.py:93} INFO - 13667 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.u.ShellProcess - Storm multilang serializer: org.apache.storm.multilang.JsonSerializer
[2023-05-19T11:39:37.473+0530] {subprocess.py:93} INFO - 13675 [Thread-21-__acker-executor[1 1]] INFO  o.a.s.d.executor - Preparing bolt __acker:(1)
[2023-05-19T11:39:37.493+0530] {subprocess.py:93} INFO - 13694 [Thread-21-__acker-executor[1 1]] INFO  o.a.s.d.executor - Prepared bolt __acker:(1)
[2023-05-19T11:39:37.502+0530] {subprocess.py:93} INFO - 13704 [Thread-17-filter_bolt-executor[2 2]] INFO  o.a.s.d.executor - Preparing bolt filter_bolt:(2)
[2023-05-19T11:39:37.503+0530] {subprocess.py:93} INFO - 13705 [Thread-23-__system-executor[-1 -1]] INFO  o.a.s.d.executor - Preparing bolt __system:(-1)
[2023-05-19T11:39:37.503+0530] {subprocess.py:93} INFO - 13705 [Thread-17-filter_bolt-executor[2 2]] INFO  o.a.s.u.ShellProcess - Storm multilang serializer: org.apache.storm.multilang.JsonSerializer
[2023-05-19T11:39:37.509+0530] {subprocess.py:93} INFO - 13711 [Thread-23-__system-executor[-1 -1]] INFO  o.a.s.d.executor - Prepared bolt __system:(-1)
[2023-05-19T11:39:38.154+0530] {subprocess.py:93} INFO - 14356 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.s.ShellSpout - Launched subprocess with pid 12213
[2023-05-19T11:39:38.161+0530] {subprocess.py:93} INFO - 14362 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.d.executor - Opened spout kafka_spout:(3)
[2023-05-19T11:39:38.164+0530] {subprocess.py:93} INFO - 14366 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.d.executor - Activating spout kafka_spout:(3)
[2023-05-19T11:39:38.165+0530] {subprocess.py:93} INFO - 14367 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.s.ShellSpout - Start checking heartbeat...
[2023-05-19T11:39:38.168+0530] {subprocess.py:93} INFO - 14369 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.s.ShellSpout - ShellLog pid:12213, name:kafka_spout pystorm StormHandler logging enabled, so all messages at levels greater than "pystorm.log.level" (info) will be sent to Storm.
[2023-05-19T11:39:38.233+0530] {subprocess.py:93} INFO - 14435 [Thread-17-filter_bolt-executor[2 2]] INFO  o.a.s.t.ShellBolt - Launched subprocess with pid 12214
[2023-05-19T11:39:38.235+0530] {subprocess.py:93} INFO - 14437 [Thread-17-filter_bolt-executor[2 2]] INFO  o.a.s.t.ShellBolt - Start checking heartbeat...
[2023-05-19T11:39:38.236+0530] {subprocess.py:93} INFO - 14438 [Thread-26] INFO  o.a.s.t.ShellBolt - ShellLog pid:12214, name:filter_bolt pystorm StormHandler logging enabled, so all messages at levels greater than "pystorm.log.level" (info) will be sent to Storm.
[2023-05-19T11:39:38.237+0530] {subprocess.py:93} INFO - 14439 [Thread-17-filter_bolt-executor[2 2]] INFO  o.a.s.d.executor - Prepared bolt filter_bolt:(2)
[2023-05-19T11:39:38.457+0530] {subprocess.py:93} INFO - 14659 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.s.ShellSpout - ShellLog pid:12213, name:kafka_spout ConsumerRecord(topic='test', partition=0, offset=10954, timestamp=1684476451876, timestamp_type=0, key=None, value=b'{"name": "unnimaya", "email": "unnimaya@gmail.com", "phone": "9988776655", "resume": {"Personal_info": {"name": "John mathew", "Age": "34", "DOB": "19-11-1989", "email": "john@gmail.com", "phone": "(91)7869569810"}, "location": {"address": "21734 broadway st", "postalCode": "CA 94115", "city": "Delhi", "countryCode": "IN"}, "education": {"area": "Software Development", "studyType": "Bachelor", "institution": "University", "startDate": "04-06-2009", "endDate": "03-05-2013", "score": "4.0"}, "skills": {"Softskills": [{"Englishspeaking": "", "Englishwriting": "", "Leadership": ""}], "Techskills": [{"python": "3"}, {"Hadoop": "5"}, {"HTML": "2"}, {"Nodejs": "4"}, {"Angular": "3"}]}, "work": {"name": "Company", "position": "Developer", "startDate": "13-05-2014", "endDate": "20-05-2020"}, "certificates": [{"name": "Experiencecertificate", "date": "06-07-2020", "issuer": "Company"}], "projects": [{"name": "Project", "description": "Description\\u2026", "role": "Team Lead"}]}}', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=982, serialized_header_size=-1)
[2023-05-19T11:39:38.859+0530] {subprocess.py:93} INFO - 15061 [Thread-26] INFO  o.a.s.t.ShellBolt - ShellLog pid:12214, name:filter_bolt unnimaya added to hdfs
[2023-05-19T11:39:58.371+0530] {process_utils.py:131} INFO - Sending Signals.SIGTERM to group 11776. PIDs of all processes in the group: [11777, 11945, 11946, 12213, 12214, 11776]
[2023-05-19T11:39:58.372+0530] {process_utils.py:86} INFO - Sending the signal Signals.SIGTERM to group 11776
[2023-05-19T11:39:58.372+0530] {taskinstance.py:1540} ERROR - Received SIGTERM. Terminating subprocesses.
[2023-05-19T11:39:58.373+0530] {subprocess.py:104} INFO - Sending SIGTERM signal to process group
[2023-05-19T11:39:58.393+0530] {process_utils.py:79} INFO - Process psutil.Process(pid=12214, status='terminated', started='11:39:37') (12214) terminated with exit code None
[2023-05-19T11:39:58.411+0530] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/airflow/operators/bash.py", line 201, in execute
    result = self.subprocess_hook.run_command(
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/airflow/hooks/subprocess.py", line 91, in run_command
    for raw_line in iter(self.sub_process.stdout.readline, b""):
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1542, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2023-05-19T11:39:58.424+0530] {taskinstance.py:1368} INFO - Marking task as FAILED. dag_id=concurrent_bash_tasks, task_id=submitt_topology, execution_date=20230519T060621, start_date=20230519T060828, end_date=20230519T060958
[2023-05-19T11:39:58.445+0530] {standard_task_runner.py:104} ERROR - Failed to execute job 685 for task submitt_topology (Task received SIGTERM signal; 11776)
[2023-05-19T11:39:58.567+0530] {process_utils.py:79} INFO - Process psutil.Process(pid=12213, status='terminated', started='11:39:37') (12213) terminated with exit code None
[2023-05-19T11:39:58.568+0530] {process_utils.py:79} INFO - Process psutil.Process(pid=11945, status='terminated', started='11:39:08') (11945) terminated with exit code None
[2023-05-19T11:39:58.568+0530] {process_utils.py:79} INFO - Process psutil.Process(pid=11777, status='terminated', started='11:38:28') (11777) terminated with exit code None
[2023-05-19T11:39:58.568+0530] {process_utils.py:79} INFO - Process psutil.Process(pid=11776, status='terminated', exitcode=1, started='11:38:27') (11776) terminated with exit code 1
[2023-05-19T11:39:58.781+0530] {process_utils.py:79} INFO - Process psutil.Process(pid=11946, status='terminated', started='11:39:08') (11946) terminated with exit code None
