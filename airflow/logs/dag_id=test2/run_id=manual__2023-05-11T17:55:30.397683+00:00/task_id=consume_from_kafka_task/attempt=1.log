[2023-05-11T23:26:10.213+0530] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: test2.consume_from_kafka_task manual__2023-05-11T17:55:30.397683+00:00 [queued]>
[2023-05-11T23:26:10.220+0530] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: test2.consume_from_kafka_task manual__2023-05-11T17:55:30.397683+00:00 [queued]>
[2023-05-11T23:26:10.220+0530] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-11T23:26:10.235+0530] {taskinstance.py:1350} INFO - Executing <Task(PythonOperator): consume_from_kafka_task> on 2023-05-11 17:55:30.397683+00:00
[2023-05-11T23:26:10.239+0530] {standard_task_runner.py:57} INFO - Started process 11091 to run task
[2023-05-11T23:26:10.243+0530] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'test2', 'consume_from_kafka_task', 'manual__2023-05-11T17:55:30.397683+00:00', '--job-id', '144', '--raw', '--subdir', 'DAGS_FOLDER/test.py', '--cfg-path', '/tmp/tmp6_ibwk_3']
[2023-05-11T23:26:10.244+0530] {standard_task_runner.py:85} INFO - Job 144: Subtask consume_from_kafka_task
[2023-05-11T23:26:10.290+0530] {task_command.py:410} INFO - Running <TaskInstance: test2.consume_from_kafka_task manual__2023-05-11T17:55:30.397683+00:00 [running]> on host nizam-HP-15-Notebook-PC
[2023-05-11T23:26:10.355+0530] {taskinstance.py:1568} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='test2' AIRFLOW_CTX_TASK_ID='consume_from_kafka_task' AIRFLOW_CTX_EXECUTION_DATE='2023-05-11T17:55:30.397683+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-05-11T17:55:30.397683+00:00'
[2023-05-11T23:26:10.359+0530] {conn.py:380} INFO - <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: connecting to localhost:9092 [('127.0.0.1', 9092) IPv4]
[2023-05-11T23:26:10.359+0530] {conn.py:1205} INFO - Probing node bootstrap-0 broker version
[2023-05-11T23:26:10.360+0530] {conn.py:410} INFO - <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: Connection complete.
[2023-05-11T23:26:10.471+0530] {conn.py:1267} INFO - Broker version identified as 2.5.0
[2023-05-11T23:26:10.471+0530] {conn.py:1268} INFO - Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
[2023-05-11T23:26:10.473+0530] {subscription_state.py:171} INFO - Updating subscribed topics to: ('test',)
[2023-05-11T23:26:10.478+0530] {cluster.py:371} INFO - Group coordinator for group1 is BrokerMetadata(nodeId='coordinator-1001', host='localhost', port=9092, rack=None)
[2023-05-11T23:26:10.479+0530] {base.py:693} INFO - Discovered coordinator coordinator-1001 for group group1
[2023-05-11T23:26:10.479+0530] {base.py:741} INFO - Starting new heartbeat thread
[2023-05-11T23:26:10.480+0530] {consumer.py:348} INFO - Revoking previously assigned partitions set() for group group1
[2023-05-11T23:26:10.481+0530] {conn.py:380} INFO - <BrokerConnection node_id=coordinator-1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: connecting to localhost:9092 [('127.0.0.1', 9092) IPv4]
[2023-05-11T23:26:10.481+0530] {conn.py:410} INFO - <BrokerConnection node_id=coordinator-1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: Connection complete.
[2023-05-11T23:26:10.482+0530] {conn.py:919} INFO - <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: Closing connection. 
[2023-05-11T23:26:10.583+0530] {base.py:450} INFO - (Re-)joining group group1
[2023-05-11T23:26:10.586+0530] {conn.py:380} INFO - <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: connecting to localhost:9092 [('127.0.0.1', 9092) IPv4]
[2023-05-11T23:26:10.587+0530] {conn.py:410} INFO - <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: Connection complete.
[2023-05-11T23:26:10.614+0530] {base.py:521} INFO - Elected group leader -- performing partition assignments using range
[2023-05-11T23:26:10.634+0530] {base.py:335} INFO - Successfully joined group group1 with generation 175
[2023-05-11T23:26:10.635+0530] {subscription_state.py:257} INFO - Updated partition assignment: [TopicPartition(topic='test', partition=0)]
[2023-05-11T23:26:10.635+0530] {consumer.py:245} INFO - Setting newly assigned partitions {TopicPartition(topic='test', partition=0)} for group group1
[2023-05-11T23:26:10.642+0530] {conn.py:380} INFO - <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: connecting to localhost:9092 [('127.0.0.1', 9092) IPv4]
[2023-05-11T23:26:10.642+0530] {conn.py:410} INFO - <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: Connection complete.
[2023-05-11T23:26:10.643+0530] {conn.py:919} INFO - <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: Closing connection. 
[2023-05-12T00:01:26.642+0530] {client_async.py:698} WARNING - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]> timed out after 305000 ms. Closing connection.
[2023-05-12T00:01:26.647+0530] {conn.py:919} INFO - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: Closing connection. [Error 7] RequestTimedOutError: Request timed out after 305000 ms
[2023-05-12T00:01:26.648+0530] {future.py:79} ERROR - Fetch to node 1001 failed: [Error 7] RequestTimedOutError: Request timed out after 305000 ms
[2023-05-12T00:01:26.648+0530] {client_async.py:952} INFO - Closing idle connection coordinator-1001, last active 2025490 ms ago
[2023-05-12T00:01:26.649+0530] {conn.py:919} INFO - <BrokerConnection node_id=coordinator-1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: Closing connection. 
[2023-05-12T00:01:26.650+0530] {conn.py:380} INFO - <BrokerConnection node_id=coordinator-1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: connecting to localhost:9092 [('127.0.0.1', 9092) IPv4]
[2023-05-12T00:01:26.650+0530] {conn.py:410} INFO - <BrokerConnection node_id=coordinator-1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: Connection complete.
[2023-05-12T00:01:26.651+0530] {conn.py:380} INFO - <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: connecting to localhost:9092 [('127.0.0.1', 9092) IPv4]
[2023-05-12T00:01:26.652+0530] {conn.py:410} INFO - <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: Connection complete.
[2023-05-12T00:01:26.652+0530] {consumer.py:794} WARNING - Auto offset commit failed for group group1: NodeNotReadyError: coordinator-1001
[2023-05-12T00:01:26.656+0530] {base.py:985} WARNING - Heartbeat session expired, marking coordinator dead
[2023-05-12T00:01:26.656+0530] {base.py:715} WARNING - Marking the coordinator dead (node coordinator-1001) for group group1: Heartbeat session expired.
[2023-05-12T00:01:28.898+0530] {cluster.py:371} INFO - Group coordinator for group1 is BrokerMetadata(nodeId='coordinator-1001', host='localhost', port=9092, rack=None)
[2023-05-12T00:01:28.898+0530] {base.py:693} INFO - Discovered coordinator coordinator-1001 for group group1
[2023-05-12T00:01:28.958+0530] {consumer.py:794} WARNING - Auto offset commit failed for group group1: CommitFailedError: Commit cannot be completed since the group has already
            rebalanced and assigned the partitions to another member.
            This means that the time between subsequent calls to poll()
            was longer than the configured max_poll_interval_ms, which
            typically implies that the poll loop is spending too much
            time message processing. You can address this either by
            increasing the rebalance timeout with max_poll_interval_ms,
            or by reducing the maximum size of batches returned in poll()
            with max_poll_records.
            
[2023-05-12T00:01:28.959+0530] {consumer.py:539} ERROR - Offset commit failed: This is likely to cause duplicate message delivery
Traceback (most recent call last):
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/kafka/coordinator/consumer.py", line 528, in _maybe_auto_commit_offsets_sync
    self.commit_offsets_sync(self._subscription.all_consumed_offsets())
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/kafka/coordinator/consumer.py", line 521, in commit_offsets_sync
    raise future.exception # pylint: disable-msg=raising-bad-type
kafka.errors.CommitFailedError: CommitFailedError: Commit cannot be completed since the group has already
            rebalanced and assigned the partitions to another member.
            This means that the time between subsequent calls to poll()
            was longer than the configured max_poll_interval_ms, which
            typically implies that the poll loop is spending too much
            time message processing. You can address this either by
            increasing the rebalance timeout with max_poll_interval_ms,
            or by reducing the maximum size of batches returned in poll()
            with max_poll_records.
            
[2023-05-12T00:01:28.964+0530] {consumer.py:348} INFO - Revoking previously assigned partitions {TopicPartition(topic='test', partition=0)} for group group1
[2023-05-12T00:01:28.965+0530] {base.py:450} INFO - (Re-)joining group group1
[2023-05-12T00:01:28.989+0530] {base.py:521} INFO - Elected group leader -- performing partition assignments using range
[2023-05-12T00:01:29.003+0530] {base.py:335} INFO - Successfully joined group group1 with generation 177
[2023-05-12T00:01:29.004+0530] {subscription_state.py:257} INFO - Updated partition assignment: [TopicPartition(topic='test', partition=0)]
[2023-05-12T00:01:29.004+0530] {consumer.py:245} INFO - Setting newly assigned partitions {TopicPartition(topic='test', partition=0)} for group group1
[2023-05-12T00:03:36.317+0530] {process_utils.py:131} INFO - Sending Signals.SIGTERM to group 11091. PIDs of all processes in the group: [11091]
[2023-05-12T00:03:36.323+0530] {process_utils.py:86} INFO - Sending the signal Signals.SIGTERM to group 11091
[2023-05-12T00:03:36.323+0530] {taskinstance.py:1540} ERROR - Received SIGTERM. Terminating subprocesses.
[2023-05-12T00:03:36.342+0530] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/home/nizam/airflow/dags/test.py", line 30, in consume_from_kafka
    for message in consumer:
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/kafka/consumer/group.py", line 1193, in __next__
    return self.next_v2()
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/kafka/consumer/group.py", line 1201, in next_v2
    return next(self._iterator)
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/kafka/consumer/group.py", line 1116, in _message_generator_v2
    record_map = self.poll(timeout_ms=timeout_ms, update_offsets=False)
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/kafka/consumer/group.py", line 655, in poll
    records = self._poll_once(remaining, max_records, update_offsets=update_offsets)
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/kafka/consumer/group.py", line 702, in _poll_once
    self._client.poll(timeout_ms=timeout_ms)
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/kafka/client_async.py", line 602, in poll
    self._poll(timeout / 1000)
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/kafka/client_async.py", line 634, in _poll
    ready = self._selector.select(timeout)
  File "/usr/lib/python3.10/selectors.py", line 469, in select
    fd_event_list = self._selector.poll(timeout, max_ev)
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1542, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2023-05-12T00:03:36.354+0530] {taskinstance.py:1368} INFO - Marking task as UP_FOR_RETRY. dag_id=test2, task_id=consume_from_kafka_task, execution_date=20230511T175530, start_date=20230511T175610, end_date=20230511T183336
[2023-05-12T00:03:36.372+0530] {standard_task_runner.py:104} ERROR - Failed to execute job 144 for task consume_from_kafka_task (Task received SIGTERM signal; 11091)
[2023-05-12T00:03:36.415+0530] {process_utils.py:79} INFO - Process psutil.Process(pid=11091, status='terminated', exitcode=1, started='23:26:09') (11091) terminated with exit code 1
