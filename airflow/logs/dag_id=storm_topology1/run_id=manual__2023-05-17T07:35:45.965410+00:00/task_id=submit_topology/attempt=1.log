[2023-05-17T13:23:20.401+0530] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: storm_topology1.submit_topology manual__2023-05-17T07:35:45.965410+00:00 [queued]>
[2023-05-17T13:23:20.409+0530] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: storm_topology1.submit_topology manual__2023-05-17T07:35:45.965410+00:00 [queued]>
[2023-05-17T13:23:20.409+0530] {taskinstance.py:1331} INFO - Starting attempt 1 of 2
[2023-05-17T13:23:20.427+0530] {taskinstance.py:1350} INFO - Executing <Task(BashOperator): submit_topology> on 2023-05-17 07:35:45.965410+00:00
[2023-05-17T13:23:20.431+0530] {standard_task_runner.py:57} INFO - Started process 8175 to run task
[2023-05-17T13:23:20.436+0530] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'storm_topology1', 'submit_topology', 'manual__2023-05-17T07:35:45.965410+00:00', '--job-id', '331', '--raw', '--subdir', 'DAGS_FOLDER/mongokafka.py', '--cfg-path', '/tmp/tmpaysjtd9o']
[2023-05-17T13:23:20.437+0530] {standard_task_runner.py:85} INFO - Job 331: Subtask submit_topology
[2023-05-17T13:23:20.502+0530] {task_command.py:410} INFO - Running <TaskInstance: storm_topology1.submit_topology manual__2023-05-17T07:35:45.965410+00:00 [running]> on host nizam-HP-15-Notebook-PC
[2023-05-17T13:23:20.639+0530] {taskinstance.py:1568} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='storm_topology1' AIRFLOW_CTX_TASK_ID='submit_topology' AIRFLOW_CTX_EXECUTION_DATE='2023-05-17T07:35:45.965410+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-05-17T07:35:45.965410+00:00'
[2023-05-17T13:23:20.642+0530] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2023-05-17T13:23:20.646+0530] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'cd /home/nizam/project/Kafka-Storm && sparse run --name first_topology']
[2023-05-17T13:23:20.660+0530] {subprocess.py:86} INFO - Output:
[2023-05-17T13:23:34.880+0530] {subprocess.py:93} INFO - Cleaning from prior builds...
[2023-05-17T13:23:37.331+0530] {subprocess.py:93} INFO - Creating topology Uber-JAR...
[2023-05-17T13:24:02.433+0530] {subprocess.py:93} INFO - Uber-JAR created: /home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar
[2023-05-17T13:24:14.070+0530] {subprocess.py:93} INFO - Removing _resources temporary directory...SLF4J: Class path contains multiple SLF4J bindings.
[2023-05-17T13:24:14.070+0530] {subprocess.py:93} INFO - SLF4J: Found binding in [jar:file:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[2023-05-17T13:24:14.071+0530] {subprocess.py:93} INFO - SLF4J: Found binding in [jar:file:/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[2023-05-17T13:24:14.071+0530] {subprocess.py:93} INFO - SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[2023-05-17T13:24:14.074+0530] {subprocess.py:93} INFO - SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
[2023-05-17T13:24:17.630+0530] {subprocess.py:93} INFO - Running: /usr/lib/jvm/java-11-openjdk-amd64/bin/java -client -Ddaemon.name= -Dstorm.options= -Dstorm.home=/home/nizam/Downloads/apache-storm-1.2.3 -Dstorm.log.dir=/home/nizam/Downloads/apache-storm-1.2.3/logs -Djava.library.path=/usr/local/lib:/opt/local/lib:/usr/lib -Dstorm.conf.file= -cp /home/nizam/Downloads/apache-storm-1.2.3/*:/home/nizam/Downloads/apache-storm-1.2.3/lib/*:/home/nizam/Downloads/apache-storm-1.2.3/extlib/*:/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar:/home/nizam/Downloads/apache-storm-1.2.3/conf:/home/nizam/Downloads/apache-storm-1.2.3/bin -Dstorm.jar=/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar -Dstorm.dependency.jars= -Dstorm.dependency.artifacts={} org.apache.storm.flux.Flux --local --no-splash --sleep 9223372036854775807 /tmp/tmpngtzyk6p.yaml
[2023-05-17T13:24:17.940+0530] {subprocess.py:93} INFO - SLF4J: Class path contains multiple SLF4J bindings.
[2023-05-17T13:24:17.942+0530] {subprocess.py:93} INFO - SLF4J: Found binding in [jar:file:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[2023-05-17T13:24:17.943+0530] {subprocess.py:93} INFO - SLF4J: Found binding in [jar:file:/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[2023-05-17T13:24:17.943+0530] {subprocess.py:93} INFO - SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[2023-05-17T13:24:17.954+0530] {subprocess.py:93} INFO - SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
[2023-05-17T13:24:19.683+0530] {subprocess.py:93} INFO - Parsing file: /tmp/tmpngtzyk6p.yaml
[2023-05-17T13:24:19.826+0530] {subprocess.py:93} INFO - 2118 [main] INFO  o.a.s.f.p.FluxParser - loading YAML from input stream...
[2023-05-17T13:24:19.832+0530] {subprocess.py:93} INFO - 2129 [main] INFO  o.a.s.f.p.FluxParser - Not performing property substitution.
[2023-05-17T13:24:19.833+0530] {subprocess.py:93} INFO - 2129 [main] INFO  o.a.s.f.p.FluxParser - Not performing environment variable substitution.
[2023-05-17T13:24:20.010+0530] {subprocess.py:93} INFO - 2307 [main] INFO  o.a.s.f.FluxBuilder - Detected DSL topology...
[2023-05-17T13:24:20.411+0530] {subprocess.py:93} INFO - 2707 [main] WARN  o.a.s.u.Utils - STORM-VERSION new 1.2.3 old null
[2023-05-17T13:24:20.411+0530] {subprocess.py:93} INFO - ---------- TOPOLOGY DETAILS ----------
[2023-05-17T13:24:20.412+0530] {subprocess.py:93} INFO - Topology Name: first_topology
[2023-05-17T13:24:20.412+0530] {subprocess.py:93} INFO - --------------- SPOUTS ---------------
[2023-05-17T13:24:20.412+0530] {subprocess.py:93} INFO - kafka_spout [1] (org.apache.storm.flux.wrappers.spouts.FluxShellSpout)
[2023-05-17T13:24:20.412+0530] {subprocess.py:93} INFO - ---------------- BOLTS ---------------
[2023-05-17T13:24:20.413+0530] {subprocess.py:93} INFO - filter_bolt [1] (org.apache.storm.flux.wrappers.bolts.FluxShellBolt)
[2023-05-17T13:24:20.413+0530] {subprocess.py:93} INFO - --------------- STREAMS ---------------
[2023-05-17T13:24:20.413+0530] {subprocess.py:93} INFO - kafka_spout --FIELDS--> filter_bolt
[2023-05-17T13:24:20.413+0530] {subprocess.py:93} INFO - --------------------------------------
[2023-05-17T13:24:20.414+0530] {subprocess.py:93} INFO - 2711 [main] INFO  o.a.s.f.Flux - Running in local mode...
[2023-05-17T13:24:27.299+0530] {subprocess.py:93} INFO - 9595 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT
[2023-05-17T13:24:27.299+0530] {subprocess.py:93} INFO - 9595 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:host.name=nizam-HP-15-Notebook-PC
[2023-05-17T13:24:27.299+0530] {subprocess.py:93} INFO - 9596 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.version=11.0.18
[2023-05-17T13:24:27.300+0530] {subprocess.py:93} INFO - 9596 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.vendor=Ubuntu
[2023-05-17T13:24:27.300+0530] {subprocess.py:93} INFO - 9596 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64
[2023-05-17T13:24:27.300+0530] {subprocess.py:93} INFO - 9596 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.class.path=/home/nizam/Downloads/apache-storm-1.2.3/*:/home/nizam/Downloads/apache-storm-1.2.3/lib/ring-cors-0.1.5.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/metrics-graphite-3.1.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/kryo-3.0.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/objenesis-2.1.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-slf4j-impl-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-api-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/disruptor-3.3.11.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-over-slf4j-1.6.6.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-core-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/clojure-1.7.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/storm-core-1.2.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/minlog-1.3.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/servlet-api-2.5.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/reflectasm-1.10.1.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/metrics-core-3.1.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/storm-rename-hack-1.2.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/asm-5.0.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/slf4j-api-1.7.21.jar:/home/nizam/Downloads/apache-storm-1.2.3/extlib/*:/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar:/home/nizam/Downloads/apache-storm-1.2.3/conf:/home/nizam/Downloads/apache-storm-1.2.3/bin
[2023-05-17T13:24:27.300+0530] {subprocess.py:93} INFO - 9596 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib
[2023-05-17T13:24:27.301+0530] {subprocess.py:93} INFO - 9597 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.io.tmpdir=/tmp
[2023-05-17T13:24:27.301+0530] {subprocess.py:93} INFO - 9597 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.compiler=<NA>
[2023-05-17T13:24:27.301+0530] {subprocess.py:93} INFO - 9597 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:os.name=Linux
[2023-05-17T13:24:27.301+0530] {subprocess.py:93} INFO - 9597 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:os.arch=amd64
[2023-05-17T13:24:27.302+0530] {subprocess.py:93} INFO - 9597 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:os.version=5.19.0-41-generic
[2023-05-17T13:24:27.302+0530] {subprocess.py:93} INFO - 9597 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:user.name=nizam
[2023-05-17T13:24:27.302+0530] {subprocess.py:93} INFO - 9598 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:user.home=/home/nizam
[2023-05-17T13:24:27.302+0530] {subprocess.py:93} INFO - 9598 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:user.dir=/home/nizam/project/Kafka-Storm
[2023-05-17T13:24:27.321+0530] {subprocess.py:93} INFO - 9618 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 datadir /tmp/43476178-ea1c-4cd8-9d67-0a658aa54565/version-2 snapdir /tmp/43476178-ea1c-4cd8-9d67-0a658aa54565/version-2
[2023-05-17T13:24:27.360+0530] {subprocess.py:93} INFO - 9657 [main] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - binding to port 0.0.0.0/0.0.0.0:2000
[2023-05-17T13:24:27.366+0530] {subprocess.py:93} INFO - 9663 [main] INFO  o.a.s.zookeeper - Starting inprocess zookeeper at port 2000 and dir /tmp/43476178-ea1c-4cd8-9d67-0a658aa54565
[2023-05-17T13:24:27.530+0530] {subprocess.py:93} INFO - 9825 [main] INFO  o.a.s.d.nimbus - Starting Nimbus with conf {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.nimbus.zookeeper.acls.fixup=true, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=*****, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=["org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter"], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=null, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=["localhost"], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, backpressure.znode.timeout.secs=30, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/f614faf5-39ea-415e-8817-e526c61e89c6, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/f614faf5-39ea-415e-8817-e526c61e89c6, backpressure.znode.update.freq.secs=15, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, storm.nimbus.zookeeper.acls.check=true, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, logs.users=null, storm.cluster.metrics.consumer.publish.interval.secs=60, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, blobstore.superuser=nizam, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=[6700 6701 6702 6703], topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=["localhost"], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.thrift.socket.timeout.ms=600000, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, nimbus.host=localhost, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
[2023-05-17T13:24:27.532+0530] {subprocess.py:93} INFO - 9828 [main] INFO  o.a.s.n.NimbusInfo - Nimbus figures out its name to nizam-HP-15-Notebook-PC
[2023-05-17T13:24:27.646+0530] {subprocess.py:93} INFO - 9943 [main] INFO  o.a.s.s.o.a.c.u.Compatibility - Running in ZooKeeper 3.4.x compatibility mode
[2023-05-17T13:24:27.681+0530] {subprocess.py:93} INFO - 9978 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T13:24:27.691+0530] {subprocess.py:93} INFO - 9987 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT
[2023-05-17T13:24:27.691+0530] {subprocess.py:93} INFO - 9988 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:host.name=nizam-HP-15-Notebook-PC
[2023-05-17T13:24:27.691+0530] {subprocess.py:93} INFO - 9988 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.version=11.0.18
[2023-05-17T13:24:27.692+0530] {subprocess.py:93} INFO - 9988 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.vendor=Ubuntu
[2023-05-17T13:24:27.692+0530] {subprocess.py:93} INFO - 9988 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64
[2023-05-17T13:24:27.692+0530] {subprocess.py:93} INFO - 9988 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.class.path=/home/nizam/Downloads/apache-storm-1.2.3/*:/home/nizam/Downloads/apache-storm-1.2.3/lib/ring-cors-0.1.5.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/metrics-graphite-3.1.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/kryo-3.0.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/objenesis-2.1.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-slf4j-impl-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-api-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/disruptor-3.3.11.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-over-slf4j-1.6.6.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-core-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/clojure-1.7.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/storm-core-1.2.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/minlog-1.3.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/servlet-api-2.5.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/reflectasm-1.10.1.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/metrics-core-3.1.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/storm-rename-hack-1.2.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/asm-5.0.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/slf4j-api-1.7.21.jar:/home/nizam/Downloads/apache-storm-1.2.3/extlib/*:/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar:/home/nizam/Downloads/apache-storm-1.2.3/conf:/home/nizam/Downloads/apache-storm-1.2.3/bin
[2023-05-17T13:24:27.692+0530] {subprocess.py:93} INFO - 9989 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib
[2023-05-17T13:24:27.692+0530] {subprocess.py:93} INFO - 9989 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.io.tmpdir=/tmp
[2023-05-17T13:24:27.693+0530] {subprocess.py:93} INFO - 9989 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.compiler=<NA>
[2023-05-17T13:24:27.693+0530] {subprocess.py:93} INFO - 9989 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:os.name=Linux
[2023-05-17T13:24:27.693+0530] {subprocess.py:93} INFO - 9989 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:os.arch=amd64
[2023-05-17T13:24:27.693+0530] {subprocess.py:93} INFO - 9989 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:os.version=5.19.0-41-generic
[2023-05-17T13:24:27.693+0530] {subprocess.py:93} INFO - 9989 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:user.name=nizam
[2023-05-17T13:24:27.694+0530] {subprocess.py:93} INFO - 9990 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:user.home=/home/nizam
[2023-05-17T13:24:27.694+0530] {subprocess.py:93} INFO - 9990 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:user.dir=/home/nizam/project/Kafka-Storm
[2023-05-17T13:24:27.694+0530] {subprocess.py:93} INFO - 9991 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@71285693
[2023-05-17T13:24:27.727+0530] {subprocess.py:93} INFO - 10024 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T13:24:27.729+0530] {subprocess.py:93} INFO - 10026 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T13:24:27.732+0530] {subprocess.py:93} INFO - 10028 [main] INFO  o.a.s.b.FileBlobStoreImpl - Creating new blob store based in /tmp/f614faf5-39ea-415e-8817-e526c61e89c6/blobs
[2023-05-17T13:24:27.734+0530] {subprocess.py:93} INFO - 10030 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38298
[2023-05-17T13:24:27.734+0530] {subprocess.py:93} INFO - 10030 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T13:24:27.750+0530] {subprocess.py:93} INFO - 10046 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T13:24:27.751+0530] {subprocess.py:93} INFO - 10048 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38298
[2023-05-17T13:24:27.754+0530] {subprocess.py:93} INFO - 10050 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@472719df
[2023-05-17T13:24:27.760+0530] {subprocess.py:93} INFO - 10057 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.p.FileTxnLog - Creating new log file: log.1
[2023-05-17T13:24:27.761+0530] {subprocess.py:93} INFO - 10057 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T13:24:27.761+0530] {subprocess.py:93} INFO - 10058 [main] INFO  o.a.s.d.nimbus - Using default scheduler
[2023-05-17T13:24:27.783+0530] {subprocess.py:93} INFO - 10078 [main] INFO  o.a.s.n.NimbusInfo - Nimbus figures out its name to nizam-HP-15-Notebook-PC
[2023-05-17T13:24:27.783+0530] {subprocess.py:93} INFO - 10061 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T13:24:27.784+0530] {subprocess.py:93} INFO - 10081 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38302
[2023-05-17T13:24:27.787+0530] {subprocess.py:93} INFO - 10082 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T13:24:27.789+0530] {subprocess.py:93} INFO - 10085 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38302
[2023-05-17T13:24:27.808+0530] {subprocess.py:93} INFO - 10104 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100001e49530000, negotiated timeout = 20000
[2023-05-17T13:24:27.813+0530] {subprocess.py:93} INFO - 10110 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100001e49530000 with negotiated timeout 20000 for client /127.0.0.1:38298
[2023-05-17T13:24:27.817+0530] {subprocess.py:93} INFO - 10113 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T13:24:27.818+0530] {subprocess.py:93} INFO - 10115 [main] INFO  o.a.s.n.NimbusInfo - Nimbus figures out its name to nizam-HP-15-Notebook-PC
[2023-05-17T13:24:27.826+0530] {subprocess.py:93} INFO - 10122 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100001e49530001 with negotiated timeout 20000 for client /127.0.0.1:38302
[2023-05-17T13:24:27.826+0530] {subprocess.py:93} INFO - 10123 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100001e49530001, negotiated timeout = 20000
[2023-05-17T13:24:27.827+0530] {subprocess.py:93} INFO - 10123 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T13:24:27.827+0530] {subprocess.py:93} INFO - 10124 [main-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
[2023-05-17T13:24:27.842+0530] {subprocess.py:93} INFO - 10139 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T13:24:27.844+0530] {subprocess.py:93} INFO - 10140 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@69a76b74
[2023-05-17T13:24:27.846+0530] {subprocess.py:93} INFO - 10142 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T13:24:27.847+0530] {subprocess.py:93} INFO - 10143 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38312
[2023-05-17T13:24:27.847+0530] {subprocess.py:93} INFO - 10143 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T13:24:27.847+0530] {subprocess.py:93} INFO - 10144 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T13:24:27.847+0530] {subprocess.py:93} INFO - 10144 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38312
[2023-05-17T13:24:27.856+0530] {subprocess.py:93} INFO - 10153 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100001e49530002 with negotiated timeout 20000 for client /127.0.0.1:38312
[2023-05-17T13:24:27.858+0530] {subprocess.py:93} INFO - 10154 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100001e49530002, negotiated timeout = 20000
[2023-05-17T13:24:27.859+0530] {subprocess.py:93} INFO - 10156 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T13:24:27.860+0530] {subprocess.py:93} INFO - 10156 [main-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
[2023-05-17T13:24:27.910+0530] {subprocess.py:93} INFO - 10207 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-17T13:24:27.919+0530] {subprocess.py:93} INFO - 10216 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x100001e49530002
[2023-05-17T13:24:27.923+0530] {subprocess.py:93} INFO - 10220 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x100001e49530002 closed
[2023-05-17T13:24:27.923+0530] {subprocess.py:93} INFO - 10220 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x100001e49530002
[2023-05-17T13:24:27.925+0530] {subprocess.py:93} INFO - 10222 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:38312 which had sessionid 0x100001e49530002
[2023-05-17T13:24:27.929+0530] {subprocess.py:93} INFO - 10226 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T13:24:27.930+0530] {subprocess.py:93} INFO - 10227 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@85cd413
[2023-05-17T13:24:27.931+0530] {subprocess.py:93} INFO - 10228 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T13:24:27.932+0530] {subprocess.py:93} INFO - 10229 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T13:24:27.933+0530] {subprocess.py:93} INFO - 10230 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T13:24:27.936+0530] {subprocess.py:93} INFO - 10231 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38320
[2023-05-17T13:24:27.936+0530] {subprocess.py:93} INFO - 10231 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38320
[2023-05-17T13:24:27.936+0530] {subprocess.py:93} INFO - 10232 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T13:24:27.936+0530] {subprocess.py:93} INFO - 10232 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@2507a170
[2023-05-17T13:24:27.939+0530] {subprocess.py:93} INFO - 10235 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T13:24:27.939+0530] {subprocess.py:93} INFO - 10235 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T13:24:27.939+0530] {subprocess.py:93} INFO - 10235 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T13:24:27.940+0530] {subprocess.py:93} INFO - 10236 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38330
[2023-05-17T13:24:27.940+0530] {subprocess.py:93} INFO - 10237 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38330
[2023-05-17T13:24:27.942+0530] {subprocess.py:93} INFO - 10239 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100001e49530003 with negotiated timeout 20000 for client /127.0.0.1:38320
[2023-05-17T13:24:27.944+0530] {subprocess.py:93} INFO - 10240 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100001e49530003, negotiated timeout = 20000
[2023-05-17T13:24:27.948+0530] {subprocess.py:93} INFO - 10244 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T13:24:27.952+0530] {subprocess.py:93} INFO - 10244 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100001e49530004 with negotiated timeout 20000 for client /127.0.0.1:38330
[2023-05-17T13:24:27.953+0530] {subprocess.py:93} INFO - 10250 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100001e49530004, negotiated timeout = 20000
[2023-05-17T13:24:27.955+0530] {subprocess.py:93} INFO - 10251 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T13:24:28.037+0530] {subprocess.py:93} INFO - 10333 [main] INFO  o.a.s.zookeeper - Queued up for leader lock.
[2023-05-17T13:24:28.056+0530] {subprocess.py:93} INFO - 10353 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x100001e49530001 type:create cxid:0x1 zxid:0x12 txntype:-1 reqpath:n/a Error Path:/storm/leader-lock Error:KeeperErrorCode = NoNode for /storm/leader-lock
[2023-05-17T13:24:28.062+0530] {subprocess.py:93} INFO - 10359 [Curator-Framework-0] WARN  o.a.s.s.o.a.c.u.ZKPaths - The version of ZooKeeper being used doesn't support Container nodes. CreateMode.PERSISTENT will be used instead.
[2023-05-17T13:24:28.090+0530] {subprocess.py:93} INFO - 10387 [main] INFO  o.a.s.d.m.MetricsUtils - Using statistics reporter plugin:org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter
[2023-05-17T13:24:28.093+0530] {subprocess.py:93} INFO - 10390 [main] INFO  o.a.s.d.m.r.JmxPreparableReporter - Preparing...
[2023-05-17T13:24:28.126+0530] {subprocess.py:93} INFO - 10422 [main] INFO  o.a.s.d.common - Started statistics report plugin...
[2023-05-17T13:24:28.126+0530] {subprocess.py:93} INFO - 10422 [main-EventThread] INFO  o.a.s.z.Zookeeper - active-topology-blobs [] local-topology-blobs [] diff-topology-blobs []
[2023-05-17T13:24:28.128+0530] {subprocess.py:93} INFO - 10424 [main-EventThread] INFO  o.a.s.z.Zookeeper - active-topology-dependencies [] local-blobs [] diff-topology-dependencies []
[2023-05-17T13:24:28.129+0530] {subprocess.py:93} INFO - 10426 [main-EventThread] INFO  o.a.s.z.Zookeeper - Accepting leadership, all active topologies and corresponding dependencies found locally.
[2023-05-17T13:24:28.154+0530] {subprocess.py:93} INFO - 10451 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T13:24:28.155+0530] {subprocess.py:93} INFO - 10452 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@1b36d248
[2023-05-17T13:24:28.157+0530] {subprocess.py:93} INFO - 10454 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T13:24:28.162+0530] {subprocess.py:93} INFO - 10459 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T13:24:28.163+0530] {subprocess.py:93} INFO - 10459 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38336
[2023-05-17T13:24:28.163+0530] {subprocess.py:93} INFO - 10460 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T13:24:28.164+0530] {subprocess.py:93} INFO - 10461 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38336
[2023-05-17T13:24:28.166+0530] {subprocess.py:93} INFO - 10463 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100001e49530005 with negotiated timeout 20000 for client /127.0.0.1:38336
[2023-05-17T13:24:28.167+0530] {subprocess.py:93} INFO - 10464 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100001e49530005, negotiated timeout = 20000
[2023-05-17T13:24:28.168+0530] {subprocess.py:93} INFO - 10464 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T13:24:28.168+0530] {subprocess.py:93} INFO - 10465 [main-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
[2023-05-17T13:24:28.171+0530] {subprocess.py:93} INFO - 10467 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-17T13:24:28.172+0530] {subprocess.py:93} INFO - 10469 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x100001e49530005
[2023-05-17T13:24:28.174+0530] {subprocess.py:93} INFO - 10471 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x100001e49530005 closed
[2023-05-17T13:24:28.175+0530] {subprocess.py:93} INFO - 10471 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x100001e49530005
[2023-05-17T13:24:28.176+0530] {subprocess.py:93} INFO - 10472 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T13:24:28.176+0530] {subprocess.py:93} INFO - 10473 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:38336 which had sessionid 0x100001e49530005
[2023-05-17T13:24:28.177+0530] {subprocess.py:93} INFO - 10474 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@18dbc1b
[2023-05-17T13:24:28.186+0530] {subprocess.py:93} INFO - 10480 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T13:24:28.186+0530] {subprocess.py:93} INFO - 10481 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38352
[2023-05-17T13:24:28.186+0530] {subprocess.py:93} INFO - 10481 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T13:24:28.186+0530] {subprocess.py:93} INFO - 10482 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38352
[2023-05-17T13:24:28.187+0530] {subprocess.py:93} INFO - 10482 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T13:24:28.187+0530] {subprocess.py:93} INFO - 10484 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T13:24:28.189+0530] {subprocess.py:93} INFO - 10485 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@7c5ac0
[2023-05-17T13:24:28.190+0530] {subprocess.py:93} INFO - 10487 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T13:24:28.195+0530] {subprocess.py:93} INFO - 10491 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100001e49530006 with negotiated timeout 20000 for client /127.0.0.1:38352
[2023-05-17T13:24:28.195+0530] {subprocess.py:93} INFO - 10492 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100001e49530006, negotiated timeout = 20000
[2023-05-17T13:24:28.197+0530] {subprocess.py:93} INFO - 10492 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T13:24:28.197+0530] {subprocess.py:93} INFO - 10494 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T13:24:28.198+0530] {subprocess.py:93} INFO - 10495 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T13:24:28.199+0530] {subprocess.py:93} INFO - 10495 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38362
[2023-05-17T13:24:28.199+0530] {subprocess.py:93} INFO - 10496 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38362
[2023-05-17T13:24:28.207+0530] {subprocess.py:93} INFO - 10503 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100001e49530007 with negotiated timeout 20000 for client /127.0.0.1:38362
[2023-05-17T13:24:28.207+0530] {subprocess.py:93} INFO - 10503 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100001e49530007, negotiated timeout = 20000
[2023-05-17T13:24:28.207+0530] {subprocess.py:93} INFO - 10504 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T13:24:28.207+0530] {subprocess.py:93} INFO - 10504 [main-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
[2023-05-17T13:24:28.210+0530] {subprocess.py:93} INFO - 10506 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-17T13:24:28.211+0530] {subprocess.py:93} INFO - 10508 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x100001e49530007
[2023-05-17T13:24:28.214+0530] {subprocess.py:93} INFO - 10511 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:38362 which had sessionid 0x100001e49530007
[2023-05-17T13:24:28.214+0530] {subprocess.py:93} INFO - 10510 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x100001e49530007 closed
[2023-05-17T13:24:28.216+0530] {subprocess.py:93} INFO - 10512 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x100001e49530007
[2023-05-17T13:24:28.216+0530] {subprocess.py:93} INFO - 10513 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T13:24:28.217+0530] {subprocess.py:93} INFO - 10514 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@6a7aa675
[2023-05-17T13:24:28.218+0530] {subprocess.py:93} INFO - 10515 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T13:24:28.219+0530] {subprocess.py:93} INFO - 10515 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T13:24:28.219+0530] {subprocess.py:93} INFO - 10516 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38368
[2023-05-17T13:24:28.220+0530] {subprocess.py:93} INFO - 10517 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T13:24:28.220+0530] {subprocess.py:93} INFO - 10517 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38368
[2023-05-17T13:24:28.224+0530] {subprocess.py:93} INFO - 10520 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100001e49530008, negotiated timeout = 20000
[2023-05-17T13:24:28.224+0530] {subprocess.py:93} INFO - 10520 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100001e49530008 with negotiated timeout 20000 for client /127.0.0.1:38368
[2023-05-17T13:24:28.224+0530] {subprocess.py:93} INFO - 10521 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T13:24:28.309+0530] {subprocess.py:93} INFO - 10606 [main] INFO  o.a.s.z.Zookeeper - Staring ZK Curator
[2023-05-17T13:24:28.309+0530] {subprocess.py:93} INFO - 10606 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T13:24:28.310+0530] {subprocess.py:93} INFO - 10607 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@6d5508a5
[2023-05-17T13:24:28.313+0530] {subprocess.py:93} INFO - 10610 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T13:24:28.321+0530] {subprocess.py:93} INFO - 10618 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T13:24:28.322+0530] {subprocess.py:93} INFO - 10619 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38372
[2023-05-17T13:24:28.322+0530] {subprocess.py:93} INFO - 10619 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T13:24:28.323+0530] {subprocess.py:93} INFO - 10620 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38372
[2023-05-17T13:24:28.325+0530] {subprocess.py:93} INFO - 10622 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100001e49530009 with negotiated timeout 20000 for client /127.0.0.1:38372
[2023-05-17T13:24:28.327+0530] {subprocess.py:93} INFO - 10623 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100001e49530009, negotiated timeout = 20000
[2023-05-17T13:24:28.327+0530] {subprocess.py:93} INFO - 10624 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T13:24:28.332+0530] {subprocess.py:93} INFO - 10629 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-17T13:24:28.334+0530] {subprocess.py:93} INFO - 10630 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x100001e49530009
[2023-05-17T13:24:28.335+0530] {subprocess.py:93} INFO - 10632 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x100001e49530009 closed
[2023-05-17T13:24:28.336+0530] {subprocess.py:93} INFO - 10633 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x100001e49530009
[2023-05-17T13:24:28.337+0530] {subprocess.py:93} INFO - 10634 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:38372 which had sessionid 0x100001e49530009
[2023-05-17T13:24:28.338+0530] {subprocess.py:93} INFO - 10635 [main] INFO  o.a.s.z.Zookeeper - Staring ZK Curator
[2023-05-17T13:24:28.338+0530] {subprocess.py:93} INFO - 10635 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T13:24:28.340+0530] {subprocess.py:93} INFO - 10635 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@4ff0706c
[2023-05-17T13:24:28.340+0530] {subprocess.py:93} INFO - 10637 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T13:24:28.345+0530] {subprocess.py:93} INFO - 10642 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T13:24:28.346+0530] {subprocess.py:93} INFO - 10643 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T13:24:28.347+0530] {subprocess.py:93} INFO - 10644 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38374
[2023-05-17T13:24:28.347+0530] {subprocess.py:93} INFO - 10644 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38374
[2023-05-17T13:24:28.349+0530] {subprocess.py:93} INFO - 10646 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100001e4953000a with negotiated timeout 20000 for client /127.0.0.1:38374
[2023-05-17T13:24:28.350+0530] {subprocess.py:93} INFO - 10647 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100001e4953000a, negotiated timeout = 20000
[2023-05-17T13:24:28.350+0530] {subprocess.py:93} INFO - 10647 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T13:24:28.367+0530] {subprocess.py:93} INFO - 10664 [main] INFO  o.a.s.l.Localizer - Reconstruct localized resource: /tmp/d9d3549b-224f-4cb1-acc0-a6931990f801/supervisor/usercache
[2023-05-17T13:24:28.368+0530] {subprocess.py:93} INFO - 10664 [main] WARN  o.a.s.l.Localizer - No left over resources found for any user during reconstructing of local resources at: /tmp/d9d3549b-224f-4cb1-acc0-a6931990f801/supervisor/usercache
[2023-05-17T13:24:28.387+0530] {subprocess.py:93} INFO - 10677 [main] INFO  o.a.s.d.s.Supervisor - Starting Supervisor with conf {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.nimbus.zookeeper.acls.fixup=true, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=*****, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=[org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=null, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=[localhost], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, backpressure.znode.timeout.secs=30, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/f614faf5-39ea-415e-8817-e526c61e89c6, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/d9d3549b-224f-4cb1-acc0-a6931990f801, backpressure.znode.update.freq.secs=15, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, storm.nimbus.zookeeper.acls.check=true, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, logs.users=null, storm.cluster.metrics.consumer.publish.interval.secs=60, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, blobstore.superuser=nizam, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=[1024, 1025, 1026], topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=[localhost], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.thrift.socket.timeout.ms=600000, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, nimbus.host=localhost, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
[2023-05-17T13:24:28.412+0530] {subprocess.py:93} INFO - 10709 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1024 Starting in state EMPTY - assignment null
[2023-05-17T13:24:28.413+0530] {subprocess.py:93} INFO - 10710 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1025 Starting in state EMPTY - assignment null
[2023-05-17T13:24:28.413+0530] {subprocess.py:93} INFO - 10710 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1026 Starting in state EMPTY - assignment null
[2023-05-17T13:24:28.414+0530] {subprocess.py:93} INFO - 10711 [main] INFO  o.a.s.l.AsyncLocalizer - Cleaning up unused topologies in /tmp/d9d3549b-224f-4cb1-acc0-a6931990f801/supervisor/stormdist
[2023-05-17T13:24:28.419+0530] {subprocess.py:93} INFO - 10715 [main] INFO  o.a.s.d.s.Supervisor - Starting supervisor with id caf43811-4ef8-4c58-b6a7-948efaaa8df4 at host nizam-HP-15-Notebook-PC.
[2023-05-17T13:24:28.422+0530] {subprocess.py:93} INFO - 10718 [main] INFO  o.a.s.z.Zookeeper - Staring ZK Curator
[2023-05-17T13:24:28.422+0530] {subprocess.py:93} INFO - 10718 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T13:24:28.422+0530] {subprocess.py:93} INFO - 10719 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@4a3509b0
[2023-05-17T13:24:28.424+0530] {subprocess.py:93} INFO - 10720 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T13:24:28.425+0530] {subprocess.py:93} INFO - 10722 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T13:24:28.426+0530] {subprocess.py:93} INFO - 10722 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T13:24:28.426+0530] {subprocess.py:93} INFO - 10723 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38378
[2023-05-17T13:24:28.426+0530] {subprocess.py:93} INFO - 10723 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38378
[2023-05-17T13:24:28.429+0530] {subprocess.py:93} INFO - 10725 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100001e4953000b with negotiated timeout 20000 for client /127.0.0.1:38378
[2023-05-17T13:24:28.429+0530] {subprocess.py:93} INFO - 10726 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100001e4953000b, negotiated timeout = 20000
[2023-05-17T13:24:28.430+0530] {subprocess.py:93} INFO - 10726 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T13:24:28.432+0530] {subprocess.py:93} INFO - 10729 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-17T13:24:28.434+0530] {subprocess.py:93} INFO - 10731 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x100001e4953000b
[2023-05-17T13:24:28.437+0530] {subprocess.py:93} INFO - 10732 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x100001e4953000b closed
[2023-05-17T13:24:28.438+0530] {subprocess.py:93} INFO - 10733 [main] INFO  o.a.s.z.Zookeeper - Staring ZK Curator
[2023-05-17T13:24:28.438+0530] {subprocess.py:93} INFO - 10733 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T13:24:28.438+0530] {subprocess.py:93} INFO - 10734 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x100001e4953000b
[2023-05-17T13:24:28.439+0530] {subprocess.py:93} INFO - 10735 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@48860139
[2023-05-17T13:24:28.443+0530] {subprocess.py:93} INFO - 10738 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T13:24:28.447+0530] {subprocess.py:93} INFO - 10743 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:38378 which had sessionid 0x100001e4953000b
[2023-05-17T13:24:28.451+0530] {subprocess.py:93} INFO - 10747 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T13:24:28.457+0530] {subprocess.py:93} INFO - 10754 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38386
[2023-05-17T13:24:28.459+0530] {subprocess.py:93} INFO - 10756 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T13:24:28.462+0530] {subprocess.py:93} INFO - 10758 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38386
[2023-05-17T13:24:28.464+0530] {subprocess.py:93} INFO - 10760 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100001e4953000c with negotiated timeout 20000 for client /127.0.0.1:38386
[2023-05-17T13:24:28.465+0530] {subprocess.py:93} INFO - 10762 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100001e4953000c, negotiated timeout = 20000
[2023-05-17T13:24:28.467+0530] {subprocess.py:93} INFO - 10764 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T13:24:28.487+0530] {subprocess.py:93} INFO - 10784 [main] INFO  o.a.s.l.Localizer - Reconstruct localized resource: /tmp/0db29bea-3c1d-4f56-9f44-201d6e7e046c/supervisor/usercache
[2023-05-17T13:24:28.488+0530] {subprocess.py:93} INFO - 10784 [main] WARN  o.a.s.l.Localizer - No left over resources found for any user during reconstructing of local resources at: /tmp/0db29bea-3c1d-4f56-9f44-201d6e7e046c/supervisor/usercache
[2023-05-17T13:24:28.491+0530] {subprocess.py:93} INFO - 10786 [main] INFO  o.a.s.d.s.Supervisor - Starting Supervisor with conf {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.nimbus.zookeeper.acls.fixup=true, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=*****, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=[org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=null, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=[localhost], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, backpressure.znode.timeout.secs=30, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/f614faf5-39ea-415e-8817-e526c61e89c6, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/0db29bea-3c1d-4f56-9f44-201d6e7e046c, backpressure.znode.update.freq.secs=15, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, storm.nimbus.zookeeper.acls.check=true, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, logs.users=null, storm.cluster.metrics.consumer.publish.interval.secs=60, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, blobstore.superuser=nizam, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=[1027, 1028, 1029], topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=[localhost], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.thrift.socket.timeout.ms=600000, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, nimbus.host=localhost, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
[2023-05-17T13:24:28.506+0530] {subprocess.py:93} INFO - 10803 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1027 Starting in state EMPTY - assignment null
[2023-05-17T13:24:28.507+0530] {subprocess.py:93} INFO - 10803 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1028 Starting in state EMPTY - assignment null
[2023-05-17T13:24:28.507+0530] {subprocess.py:93} INFO - 10804 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1029 Starting in state EMPTY - assignment null
[2023-05-17T13:24:28.507+0530] {subprocess.py:93} INFO - 10804 [main] INFO  o.a.s.l.AsyncLocalizer - Cleaning up unused topologies in /tmp/0db29bea-3c1d-4f56-9f44-201d6e7e046c/supervisor/stormdist
[2023-05-17T13:24:28.509+0530] {subprocess.py:93} INFO - 10805 [main] INFO  o.a.s.d.s.Supervisor - Starting supervisor with id b9100d54-b520-4b7a-8de3-d397fe6bc11c at host nizam-HP-15-Notebook-PC.
[2023-05-17T13:24:28.522+0530] {subprocess.py:93} INFO - 10818 [main] WARN  o.a.s.u.Utils - STORM-VERSION new 1.2.3 old 1.2.3
[2023-05-17T13:24:28.612+0530] {subprocess.py:93} INFO - 10909 [main] INFO  o.a.s.d.nimbus - Received topology submission for first_topology (storm-1.2.3 JDK-11.0.18) with conf {topology.max.task.parallelism=null, topology.submitter.principal=, pystorm.log.backup_count=10, topology.acker.executors=1, topology.eventlogger.executors=0, pystorm.log.level=info, topology.workers=1, storm.zookeeper.superACL=null, pystorm.log.max_bytes=1000000, topology.python.path=/first_topology/bin/python, topology.users=clojure.lang.LazySeq@1, topology.submitter.user=nizam, topology.kryo.register=null, sudo_user=, virtualenv_root=, storm.workers.list=[], topology.kryo.decorators=clojure.lang.LazySeq@1, storm.id=first_topology-1-1684310068, topology.name=first_topology}
[2023-05-17T13:24:28.637+0530] {subprocess.py:93} INFO - 10934 [main] INFO  o.a.s.d.nimbus - uploadedJar
[2023-05-17T13:24:28.682+0530] {subprocess.py:93} INFO - 10979 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x100001e49530001 type:create cxid:0x9 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/storm/blobstoremaxkeysequencenumber Error:KeeperErrorCode = NoNode for /storm/blobstoremaxkeysequencenumber
[2023-05-17T13:24:28.696+0530] {subprocess.py:93} INFO - 10993 [main] INFO  o.a.s.cluster - setup-path/blobstore/first_topology-1-1684310068-stormconf.ser/nizam-HP-15-Notebook-PC:6627-1
[2023-05-17T13:24:28.728+0530] {subprocess.py:93} INFO - 11024 [main] INFO  o.a.s.cluster - setup-path/blobstore/first_topology-1-1684310068-stormcode.ser/nizam-HP-15-Notebook-PC:6627-1
[2023-05-17T13:24:28.745+0530] {subprocess.py:93} INFO - 11042 [main] INFO  o.a.s.d.nimbus - desired replication count 1 achieved, current-replication-count for conf key = 1, current-replication-count for code key = 1, current-replication-count for jar key = 1
[2023-05-17T13:24:28.811+0530] {subprocess.py:93} INFO - 11107 [main] INFO  o.a.s.d.nimbus - Activating first_topology: first_topology-1-1684310068
[2023-05-17T13:24:28.961+0530] {subprocess.py:93} INFO - 11258 [timer] INFO  o.a.s.s.EvenScheduler - Available slots: (["caf43811-4ef8-4c58-b6a7-948efaaa8df4" 1024] ["caf43811-4ef8-4c58-b6a7-948efaaa8df4" 1025] ["caf43811-4ef8-4c58-b6a7-948efaaa8df4" 1026] ["b9100d54-b520-4b7a-8de3-d397fe6bc11c" 1027] ["b9100d54-b520-4b7a-8de3-d397fe6bc11c" 1028] ["b9100d54-b520-4b7a-8de3-d397fe6bc11c" 1029])
[2023-05-17T13:24:28.992+0530] {subprocess.py:93} INFO - 11289 [timer] INFO  o.a.s.d.nimbus - Setting new assignment for topology id first_topology-1-1684310068: #org.apache.storm.daemon.common.Assignment{:master-code-dir "/tmp/f614faf5-39ea-415e-8817-e526c61e89c6", :node->host {"caf43811-4ef8-4c58-b6a7-948efaaa8df4" "nizam-HP-15-Notebook-PC"}, :executor->node+port {[2 2] ["caf43811-4ef8-4c58-b6a7-948efaaa8df4" 1024], [1 1] ["caf43811-4ef8-4c58-b6a7-948efaaa8df4" 1024], [3 3] ["caf43811-4ef8-4c58-b6a7-948efaaa8df4" 1024]}, :executor->start-time-secs {[1 1] 1684310068, [2 2] 1684310068, [3 3] 1684310068}, :worker->resources {["caf43811-4ef8-4c58-b6a7-948efaaa8df4" 1024] [0.0 0.0 0.0]}, :owner "nizam"}
[2023-05-17T13:24:29.420+0530] {subprocess.py:93} INFO - 11717 [SLOT_1024] INFO  o.a.s.d.s.Slot - STATE EMPTY msInState: 1008 -> WAITING_FOR_BASIC_LOCALIZATION msInState: 0
[2023-05-17T13:24:29.421+0530] {subprocess.py:93} INFO - 11717 [Async Localizer] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T13:24:29.421+0530] {subprocess.py:93} INFO - 11718 [Async Localizer] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@325193d2
[2023-05-17T13:24:29.422+0530] {subprocess.py:93} INFO - 11719 [Async Localizer] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T13:24:29.423+0530] {subprocess.py:93} INFO - 11719 [Async Localizer] INFO  o.a.s.b.FileBlobStoreImpl - Creating new blob store based in /tmp/f614faf5-39ea-415e-8817-e526c61e89c6/blobs
[2023-05-17T13:24:29.424+0530] {subprocess.py:93} INFO - 11721 [Async Localizer-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T13:24:29.425+0530] {subprocess.py:93} INFO - 11722 [Async Localizer-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T13:24:29.426+0530] {subprocess.py:93} INFO - 11722 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38390
[2023-05-17T13:24:29.426+0530] {subprocess.py:93} INFO - 11723 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38390
[2023-05-17T13:24:29.427+0530] {subprocess.py:93} INFO - 11724 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100001e4953000d with negotiated timeout 20000 for client /127.0.0.1:38390
[2023-05-17T13:24:29.428+0530] {subprocess.py:93} INFO - 11725 [Async Localizer-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100001e4953000d, negotiated timeout = 20000
[2023-05-17T13:24:29.429+0530] {subprocess.py:93} INFO - 11725 [Async Localizer-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T13:24:29.444+0530] {subprocess.py:93} INFO - 11740 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-17T13:24:29.445+0530] {subprocess.py:93} INFO - 11742 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x100001e4953000d
[2023-05-17T13:24:29.446+0530] {subprocess.py:93} INFO - 11743 [Async Localizer] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x100001e4953000d closed
[2023-05-17T13:24:29.447+0530] {subprocess.py:93} INFO - 11743 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:38390 which had sessionid 0x100001e4953000d
[2023-05-17T13:24:29.447+0530] {subprocess.py:93} INFO - 11743 [Async Localizer-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x100001e4953000d
[2023-05-17T13:24:29.498+0530] {subprocess.py:93} INFO - 11795 [Async Localizer] INFO  o.a.s.l.AsyncLocalizer - Extracting resources from jar at /home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar to /tmp/d9d3549b-224f-4cb1-acc0-a6931990f801/supervisor/tmp/9ca31195-8d8f-46dd-a5a3-efe0b241de1e/
[2023-05-17T13:24:29.515+0530] {subprocess.py:93} INFO - 11811 [SLOT_1024] INFO  o.a.s.d.s.Slot - STATE WAITING_FOR_BASIC_LOCALIZATION msInState: 94 -> WAITING_FOR_BLOB_LOCALIZATION msInState: 1
[2023-05-17T13:24:29.523+0530] {subprocess.py:93} INFO - 11820 [SLOT_1024] INFO  o.a.s.d.s.Container - Setting up caf43811-4ef8-4c58-b6a7-948efaaa8df4:c89a6c62-e37c-4628-9780-ee426f798925
[2023-05-17T13:24:29.525+0530] {subprocess.py:93} INFO - 11822 [SLOT_1024] INFO  o.a.s.d.s.Container - GET worker-user for c89a6c62-e37c-4628-9780-ee426f798925
[2023-05-17T13:24:29.543+0530] {subprocess.py:93} INFO - 11840 [SLOT_1024] INFO  o.a.s.d.s.Container - SET worker-user c89a6c62-e37c-4628-9780-ee426f798925 nizam
[2023-05-17T13:24:29.554+0530] {subprocess.py:93} INFO - 11850 [SLOT_1024] INFO  o.a.s.d.worker - Launching worker for first_topology-1-1684310068 on caf43811-4ef8-4c58-b6a7-948efaaa8df4:1024 with id c89a6c62-e37c-4628-9780-ee426f798925 and conf {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.nimbus.zookeeper.acls.fixup=true, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=*****, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=["org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter"], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=null, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=["localhost"], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, backpressure.znode.timeout.secs=30, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/f614faf5-39ea-415e-8817-e526c61e89c6, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/d9d3549b-224f-4cb1-acc0-a6931990f801, backpressure.znode.update.freq.secs=15, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, storm.nimbus.zookeeper.acls.check=true, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, logs.users=null, storm.cluster.metrics.consumer.publish.interval.secs=60, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, blobstore.superuser=nizam, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=clojure.lang.LazySeq@ff880, topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=["localhost"], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.thrift.socket.timeout.ms=600000, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, nimbus.host=localhost, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
[2023-05-17T13:24:29.555+0530] {subprocess.py:93} INFO - 11852 [SLOT_1024] INFO  o.a.s.m.StormMetricRegistry - Starting metrics reporters...
[2023-05-17T13:24:29.562+0530] {subprocess.py:93} INFO - 11859 [SLOT_1024] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T13:24:29.563+0530] {subprocess.py:93} INFO - 11860 [SLOT_1024] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@1f6bea25
[2023-05-17T13:24:29.565+0530] {subprocess.py:93} INFO - 11861 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T13:24:29.565+0530] {subprocess.py:93} INFO - 11862 [SLOT_1024] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T13:24:29.566+0530] {subprocess.py:93} INFO - 11862 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38406
[2023-05-17T13:24:29.566+0530] {subprocess.py:93} INFO - 11863 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T13:24:29.566+0530] {subprocess.py:93} INFO - 11863 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38406
[2023-05-17T13:24:29.568+0530] {subprocess.py:93} INFO - 11865 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100001e4953000e with negotiated timeout 20000 for client /127.0.0.1:38406
[2023-05-17T13:24:29.569+0530] {subprocess.py:93} INFO - 11866 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100001e4953000e, negotiated timeout = 20000
[2023-05-17T13:24:29.570+0530] {subprocess.py:93} INFO - 11867 [SLOT_1024-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T13:24:29.571+0530] {subprocess.py:93} INFO - 11867 [SLOT_1024-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
[2023-05-17T13:24:29.574+0530] {subprocess.py:93} INFO - 11871 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-17T13:24:29.575+0530] {subprocess.py:93} INFO - 11872 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x100001e4953000e
[2023-05-17T13:24:29.577+0530] {subprocess.py:93} INFO - 11874 [SLOT_1024] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x100001e4953000e closed
[2023-05-17T13:24:29.577+0530] {subprocess.py:93} INFO - 11874 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:38406 which had sessionid 0x100001e4953000e
[2023-05-17T13:24:29.578+0530] {subprocess.py:93} INFO - 11874 [SLOT_1024-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x100001e4953000e
[2023-05-17T13:24:29.579+0530] {subprocess.py:93} INFO - 11875 [SLOT_1024] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T13:24:29.580+0530] {subprocess.py:93} INFO - 11877 [SLOT_1024] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@25584f82
[2023-05-17T13:24:29.582+0530] {subprocess.py:93} INFO - 11879 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T13:24:29.583+0530] {subprocess.py:93} INFO - 11879 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38410
[2023-05-17T13:24:29.584+0530] {subprocess.py:93} INFO - 11880 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T13:24:29.584+0530] {subprocess.py:93} INFO - 11880 [SLOT_1024] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T13:24:29.584+0530] {subprocess.py:93} INFO - 11880 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38410
[2023-05-17T13:24:29.592+0530] {subprocess.py:93} INFO - 11888 [SLOT_1024-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x100001e4953000f, negotiated timeout = 20000
[2023-05-17T13:24:29.592+0530] {subprocess.py:93} INFO - 11888 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x100001e4953000f with negotiated timeout 20000 for client /127.0.0.1:38410
[2023-05-17T13:24:29.592+0530] {subprocess.py:93} INFO - 11889 [SLOT_1024-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T13:24:29.603+0530] {subprocess.py:93} INFO - 11900 [SLOT_1024] INFO  o.a.s.s.a.AuthUtils - Got AutoCreds []
[2023-05-17T13:24:29.615+0530] {subprocess.py:93} INFO - 11912 [SLOT_1024] INFO  o.a.s.d.worker - Reading Assignments.
[2023-05-17T13:24:29.738+0530] {subprocess.py:93} INFO - 12035 [SLOT_1024] INFO  o.a.s.d.worker - Registering IConnectionCallbacks for caf43811-4ef8-4c58-b6a7-948efaaa8df4:1024
[2023-05-17T13:24:29.787+0530] {subprocess.py:93} INFO - 12084 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor filter_bolt:[2 2]
[2023-05-17T13:24:29.816+0530] {subprocess.py:93} INFO - 12113 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks filter_bolt:[2 2]
[2023-05-17T13:24:29.860+0530] {subprocess.py:93} INFO - WARNING: An illegal reflective access operation has occurred
[2023-05-17T13:24:29.860+0530] {subprocess.py:93} INFO - WARNING: Illegal reflective access by com.esotericsoftware.kryo.util.UnsafeUtil (file:/home/nizam/Downloads/apache-storm-1.2.3/lib/kryo-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int,java.lang.Object)
[2023-05-17T13:24:29.861+0530] {subprocess.py:93} INFO - WARNING: Please consider reporting this to the maintainers of com.esotericsoftware.kryo.util.UnsafeUtil
[2023-05-17T13:24:29.861+0530] {subprocess.py:93} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2023-05-17T13:24:29.861+0530] {subprocess.py:93} INFO - WARNING: All illegal access operations will be denied in a future release
[2023-05-17T13:24:30.057+0530] {subprocess.py:93} INFO - 12353 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor filter_bolt:[2 2]
[2023-05-17T13:24:30.073+0530] {subprocess.py:93} INFO - 12370 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor kafka_spout:[3 3]
[2023-05-17T13:24:30.077+0530] {subprocess.py:93} INFO - 12374 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks kafka_spout:[3 3]
[2023-05-17T13:24:30.091+0530] {subprocess.py:93} INFO - 12387 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor kafka_spout:[3 3]
[2023-05-17T13:24:30.120+0530] {subprocess.py:93} INFO - 12417 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor __acker:[1 1]
[2023-05-17T13:24:30.124+0530] {subprocess.py:93} INFO - 12420 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks __acker:[1 1]
[2023-05-17T13:24:30.127+0530] {subprocess.py:93} INFO - 12424 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor __acker:[1 1]
[2023-05-17T13:24:30.139+0530] {subprocess.py:93} INFO - 12436 [SLOT_1024] INFO  o.a.s.d.executor - Loading executor __system:[-1 -1]
[2023-05-17T13:24:30.140+0530] {subprocess.py:93} INFO - 12437 [SLOT_1024] INFO  o.a.s.d.executor - Loaded executor tasks __system:[-1 -1]
[2023-05-17T13:24:30.144+0530] {subprocess.py:93} INFO - 12440 [SLOT_1024] INFO  o.a.s.d.executor - Finished loading executor __system:[-1 -1]
[2023-05-17T13:24:30.162+0530] {subprocess.py:93} INFO - 12459 [SLOT_1024] INFO  o.a.s.d.worker - Started with log levels: {"" #object[org.apache.logging.log4j.Level 0xec4c7f6 "INFO"], "org.apache.zookeeper" #object[org.apache.logging.log4j.Level 0x200d0650 "WARN"]}
[2023-05-17T13:24:30.171+0530] {subprocess.py:93} INFO - 12467 [SLOT_1024] INFO  o.a.s.d.worker - Worker has topology config {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.nimbus.zookeeper.acls.fixup=true, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=*****, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=["org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter"], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, topology.submitter.principal=, pystorm.log.backup_count=10, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=1, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=["localhost"], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, backpressure.znode.timeout.secs=30, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/f614faf5-39ea-415e-8817-e526c61e89c6, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, pystorm.log.level=info, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/f614faf5-39ea-415e-8817-e526c61e89c6, backpressure.znode.update.freq.secs=15, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, storm.nimbus.zookeeper.acls.check=true, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, storm.zookeeper.superACL=null, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, pystorm.log.max_bytes=1000000, logs.users=null, storm.cluster.metrics.consumer.publish.interval.secs=60, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, topology.python.path=/first_topology/bin/python, blobstore.superuser=nizam, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=[6700 6701 6702 6703], topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, topology.users=[], nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.submitter.user=nizam, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, topology.kryo.register=null, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=["localhost"], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.thrift.socket.timeout.ms=600000, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, sudo_user=, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], virtualenv_root=, drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.workers.list=[], topology.kryo.decorators=[], storm.id=first_topology-1-1684310068, topology.name=first_topology, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, nimbus.host=localhost, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
[2023-05-17T13:24:30.171+0530] {subprocess.py:93} INFO - 12467 [SLOT_1024] INFO  o.a.s.d.worker - Worker c89a6c62-e37c-4628-9780-ee426f798925 for storm first_topology-1-1684310068 on caf43811-4ef8-4c58-b6a7-948efaaa8df4:1024 has finished loading
[2023-05-17T13:24:30.171+0530] {subprocess.py:93} INFO - 12467 [SLOT_1024] INFO  o.a.s.d.s.Container - SET worker-user c89a6c62-e37c-4628-9780-ee426f798925 nizam
[2023-05-17T13:24:30.171+0530] {subprocess.py:93} INFO - 12468 [SLOT_1024] INFO  o.a.s.d.s.Slot - STATE WAITING_FOR_BLOB_LOCALIZATION msInState: 657 -> WAITING_FOR_WORKER_START msInState: 0 topo:first_topology-1-1684310068 worker:c89a6c62-e37c-4628-9780-ee426f798925
[2023-05-17T13:24:30.173+0530] {subprocess.py:93} INFO - 12468 [SLOT_1024] INFO  o.a.s.d.s.Slot - SLOT 1024: Changing current assignment from null to LocalAssignment(topology_id:first_topology-1-1684310068, executors:[ExecutorInfo(task_start:2, task_end:2), ExecutorInfo(task_start:1, task_end:1), ExecutorInfo(task_start:3, task_end:3)], resources:WorkerResources(mem_on_heap:0.0, mem_off_heap:0.0, cpu:0.0), owner:nizam)
[2023-05-17T13:24:30.181+0530] {subprocess.py:93} INFO - 12478 [SLOT_1024] INFO  o.a.s.d.s.Slot - STATE WAITING_FOR_WORKER_START msInState: 10 topo:first_topology-1-1684310068 worker:c89a6c62-e37c-4628-9780-ee426f798925 -> RUNNING msInState: 0 topo:first_topology-1-1684310068 worker:c89a6c62-e37c-4628-9780-ee426f798925
[2023-05-17T13:24:30.707+0530] {subprocess.py:93} INFO - 13003 [refresh-active-timer] INFO  o.a.s.d.worker - All connections are ready for worker caf43811-4ef8-4c58-b6a7-948efaaa8df4:1024 with id c89a6c62-e37c-4628-9780-ee426f798925
[2023-05-17T13:24:30.735+0530] {subprocess.py:93} INFO - 13031 [Thread-21-__acker-executor[1 1]] INFO  o.a.s.d.executor - Preparing bolt __acker:(1)
[2023-05-17T13:24:30.743+0530] {subprocess.py:93} INFO - 13040 [Thread-21-__acker-executor[1 1]] INFO  o.a.s.d.executor - Prepared bolt __acker:(1)
[2023-05-17T13:24:30.745+0530] {subprocess.py:93} INFO - 13041 [Thread-23-__system-executor[-1 -1]] INFO  o.a.s.d.executor - Preparing bolt __system:(-1)
[2023-05-17T13:24:30.750+0530] {subprocess.py:93} INFO - 13047 [Thread-23-__system-executor[-1 -1]] INFO  o.a.s.d.executor - Prepared bolt __system:(-1)
[2023-05-17T13:24:30.758+0530] {subprocess.py:93} INFO - 13055 [Thread-17-filter_bolt-executor[2 2]] INFO  o.a.s.d.executor - Preparing bolt filter_bolt:(2)
[2023-05-17T13:24:30.760+0530] {subprocess.py:93} INFO - 13057 [Thread-17-filter_bolt-executor[2 2]] INFO  o.a.s.u.ShellProcess - Storm multilang serializer: org.apache.storm.multilang.JsonSerializer
[2023-05-17T13:24:30.791+0530] {subprocess.py:93} INFO - 13088 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.d.executor - Opening spout kafka_spout:(3)
[2023-05-17T13:24:30.795+0530] {subprocess.py:93} INFO - 13092 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.u.ShellProcess - Storm multilang serializer: org.apache.storm.multilang.JsonSerializer
[2023-05-17T13:24:31.555+0530] {subprocess.py:93} INFO - 13852 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.s.ShellSpout - Launched subprocess with pid 8587
[2023-05-17T13:24:31.564+0530] {subprocess.py:93} INFO - 13861 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.d.executor - Opened spout kafka_spout:(3)
[2023-05-17T13:24:31.570+0530] {subprocess.py:93} INFO - 13867 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.d.executor - Activating spout kafka_spout:(3)
[2023-05-17T13:24:31.570+0530] {subprocess.py:93} INFO - 13867 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.s.ShellSpout - Start checking heartbeat...
[2023-05-17T13:24:31.574+0530] {subprocess.py:93} INFO - 13870 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.s.ShellSpout - ShellLog pid:8587, name:kafka_spout pystorm StormHandler logging enabled, so all messages at levels greater than "pystorm.log.level" (info) will be sent to Storm.
[2023-05-17T13:24:31.640+0530] {subprocess.py:93} INFO - 13937 [Thread-17-filter_bolt-executor[2 2]] INFO  o.a.s.t.ShellBolt - Launched subprocess with pid 8585
[2023-05-17T13:24:31.643+0530] {subprocess.py:93} INFO - 13939 [Thread-17-filter_bolt-executor[2 2]] INFO  o.a.s.t.ShellBolt - Start checking heartbeat...
[2023-05-17T13:24:31.643+0530] {subprocess.py:93} INFO - 13940 [Thread-26] INFO  o.a.s.t.ShellBolt - ShellLog pid:8585, name:filter_bolt pystorm StormHandler logging enabled, so all messages at levels greater than "pystorm.log.level" (info) will be sent to Storm.
[2023-05-17T13:24:31.644+0530] {subprocess.py:93} INFO - 13941 [Thread-17-filter_bolt-executor[2 2]] INFO  o.a.s.d.executor - Prepared bolt filter_bolt:(2)
[2023-05-17T13:24:32.239+0530] {subprocess.py:93} INFO - 14536 [Thread-26] INFO  o.a.s.t.ShellBolt - ShellLog pid:8585, name:filter_bolt amal added to hdfs
[2023-05-17T13:24:33.282+0530] {subprocess.py:93} INFO - 15579 [Thread-26] INFO  o.a.s.t.ShellBolt - ShellLog pid:8585, name:filter_bolt afitha added to hdfs
[2023-05-17T13:24:33.374+0530] {subprocess.py:93} INFO - 15671 [Thread-26] INFO  o.a.s.t.ShellBolt - ShellLog pid:8585, name:filter_bolt amal added to hdfs
[2023-05-17T13:24:33.447+0530] {subprocess.py:93} INFO - 15744 [Thread-26] INFO  o.a.s.t.ShellBolt - ShellLog pid:8585, name:filter_bolt afitha added to hdfs
[2023-05-17T13:24:33.916+0530] {subprocess.py:93} INFO - 16213 [Thread-26] INFO  o.a.s.t.ShellBolt - ShellLog pid:8585, name:filter_bolt afitha added to hdfs
[2023-05-17T14:11:02.840+0530] {subprocess.py:93} INFO - 2805077 [SLOT_1024] WARN  o.a.s.d.s.Slot - SLOT 1024: HB is too old 2757000 > 30000
[2023-05-17T14:11:02.894+0530] {subprocess.py:93} INFO - 2805138 [SLOT_1024] INFO  o.a.s.ProcessSimulator - Begin killing process c89a6c62-e37c-4628-9780-ee426f798925
[2023-05-17T14:11:02.894+0530] {subprocess.py:93} INFO - 2805153 [SLOT_1024] INFO  o.a.s.d.worker - Shutting down worker first_topology-1-1684310068 caf43811-4ef8-4c58-b6a7-948efaaa8df4 1024
[2023-05-17T14:11:02.895+0530] {subprocess.py:93} INFO - 2805153 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:8587, name:kafka_spout 2023-05-17 14:11:02,722 - kafka.client - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]> timed out after 305000 ms. Closing connection.
[2023-05-17T14:11:02.895+0530] {subprocess.py:93} INFO - 2805154 [SLOT_1024] INFO  o.a.s.d.worker - Terminating messaging context
[2023-05-17T14:11:02.895+0530] {subprocess.py:93} INFO - 2805154 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:8587, name:kafka_spout 2023-05-17 14:11:02,777 - kafka.consumer.fetcher - Fetch to node 1001 failed: [Error 7] RequestTimedOutError: Request timed out after 305000 ms
[2023-05-17T14:11:02.896+0530] {subprocess.py:93} INFO - 2805154 [SLOT_1024] INFO  o.a.s.d.worker - Shutting down executors
[2023-05-17T14:11:02.925+0530] {subprocess.py:93} INFO - 2805221 [SLOT_1024] INFO  o.a.s.d.executor - Shutting down executor filter_bolt:[2 2]
[2023-05-17T14:11:02.947+0530] {subprocess.py:93} INFO - 2805243 [Thread-16-disruptor-executor[2 2]-send-queue] INFO  o.a.s.util - Async loop interrupted!
[2023-05-17T14:11:02.975+0530] {subprocess.py:93} INFO - 2805272 [Thread-17-filter_bolt-executor[2 2]] INFO  o.a.s.util - Async loop interrupted!
[2023-05-17T14:11:02.986+0530] {subprocess.py:93} INFO - 2805282 [SLOT_1024] INFO  o.a.s.d.executor - Shut down executor filter_bolt:[2 2]
[2023-05-17T14:11:02.989+0530] {subprocess.py:93} INFO - 2805283 [SLOT_1024] INFO  o.a.s.d.executor - Shutting down executor kafka_spout:[3 3]
[2023-05-17T14:11:02.989+0530] {subprocess.py:93} INFO - 2805284 [Thread-18-disruptor-executor[3 3]-send-queue] INFO  o.a.s.util - Async loop interrupted!
[2023-05-17T14:11:03.049+0530] {subprocess.py:93} INFO - 2805277 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.util - Async loop died!
[2023-05-17T14:11:03.049+0530] {subprocess.py:93} INFO - java.lang.RuntimeException: pid:8587, name:kafka_spout exitCode:-1, errorString:
[2023-05-17T14:11:03.050+0530] {subprocess.py:93} INFO - 	at org.apache.storm.spout.ShellSpout.die(ShellSpout.java:271) ~[storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.050+0530] {subprocess.py:93} INFO - 	at org.apache.storm.spout.ShellSpout.access$300(ShellSpout.java:48) ~[storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.050+0530] {subprocess.py:93} INFO - 	at org.apache.storm.spout.ShellSpout$SpoutHeartbeatTimerTask.run(ShellSpout.java:299) ~[storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.050+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[?:?]
[2023-05-17T14:11:03.050+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[?:?]
[2023-05-17T14:11:03.051+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[?:?]
[2023-05-17T14:11:03.062+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[?:?]
[2023-05-17T14:11:03.063+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[?:?]
[2023-05-17T14:11:03.064+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:829) [?:?]
[2023-05-17T14:11:03.070+0530] {subprocess.py:93} INFO - Caused by: java.lang.RuntimeException: subprocess heartbeat timeout
[2023-05-17T14:11:03.080+0530] {subprocess.py:93} INFO - 	... 7 more
[2023-05-17T14:11:03.081+0530] {subprocess.py:93} INFO - 2805285 [Thread-26] ERROR o.a.s.t.ShellBolt - Halting process: ShellBolt died. Command: [streamparse_run, -s json src.bolts.First_bolt.Emit], ProcessInfo pid:8585, name:filter_bolt exitCode:-1, errorString:(Unable to capture error stream)
[2023-05-17T14:11:03.091+0530] {subprocess.py:93} INFO - java.lang.RuntimeException: org.apache.storm.multilang.NoOutputException: Pipe to subprocess seems to be broken! No output read.
[2023-05-17T14:11:03.121+0530] {subprocess.py:93} INFO - Serializer Exception:
[2023-05-17T14:11:03.122+0530] {subprocess.py:93} INFO - (Unable to capture error stream)
[2023-05-17T14:11:03.122+0530] {subprocess.py:93} INFO - 
[2023-05-17T14:11:03.130+0530] {subprocess.py:93} INFO - 	at org.apache.storm.utils.ShellProcess.readShellMsg(ShellProcess.java:127) ~[storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.130+0530] {subprocess.py:93} INFO - 	at org.apache.storm.task.ShellBolt$BoltReaderRunnable.run(ShellBolt.java:330) [storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.130+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:829) [?:?]
[2023-05-17T14:11:03.130+0530] {subprocess.py:93} INFO - 2805190 [pool-50-thread-1] ERROR o.a.s.t.ShellBolt - Halting process: ShellBolt died. Command: [streamparse_run, -s json src.bolts.First_bolt.Emit], ProcessInfo pid:8585, name:filter_bolt exitCode:-1, errorString:
[2023-05-17T14:11:03.200+0530] {subprocess.py:93} INFO - java.lang.RuntimeException: subprocess heartbeat timeout
[2023-05-17T14:11:03.200+0530] {subprocess.py:93} INFO - 	at org.apache.storm.task.ShellBolt$BoltHeartbeatTimerTask.run(ShellBolt.java:319) [storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.200+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
[2023-05-17T14:11:03.200+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]
[2023-05-17T14:11:03.203+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]
[2023-05-17T14:11:03.203+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
[2023-05-17T14:11:03.205+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
[2023-05-17T14:11:03.205+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:829) [?:?]
[2023-05-17T14:11:03.205+0530] {subprocess.py:93} INFO - 2805339 [Thread-26] ERROR o.a.s.d.executor -
[2023-05-17T14:11:03.206+0530] {subprocess.py:93} INFO - java.lang.RuntimeException: org.apache.storm.multilang.NoOutputException: Pipe to subprocess seems to be broken! No output read.
[2023-05-17T14:11:03.206+0530] {subprocess.py:93} INFO - Serializer Exception:
[2023-05-17T14:11:03.209+0530] {subprocess.py:93} INFO - (Unable to capture error stream)
[2023-05-17T14:11:03.210+0530] {subprocess.py:93} INFO - 
[2023-05-17T14:11:03.210+0530] {subprocess.py:93} INFO - 	at org.apache.storm.utils.ShellProcess.readShellMsg(ShellProcess.java:127) ~[storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.210+0530] {subprocess.py:93} INFO - 	at org.apache.storm.task.ShellBolt$BoltReaderRunnable.run(ShellBolt.java:330) [storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.210+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:829) [?:?]
[2023-05-17T14:11:03.211+0530] {subprocess.py:93} INFO - 2805345 [pool-50-thread-1] ERROR o.a.s.d.executor -
[2023-05-17T14:11:03.211+0530] {subprocess.py:93} INFO - java.lang.RuntimeException: subprocess heartbeat timeout
[2023-05-17T14:11:03.211+0530] {subprocess.py:93} INFO - 	at org.apache.storm.task.ShellBolt$BoltHeartbeatTimerTask.run(ShellBolt.java:319) [storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.211+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
[2023-05-17T14:11:03.211+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]
[2023-05-17T14:11:03.212+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]
[2023-05-17T14:11:03.212+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
[2023-05-17T14:11:03.212+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
[2023-05-17T14:11:03.212+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:829) [?:?]
[2023-05-17T14:11:03.212+0530] {subprocess.py:93} INFO - Exception in thread "Thread-26" java.lang.RuntimeException: java.lang.InterruptedException
[2023-05-17T14:11:03.213+0530] {subprocess.py:93} INFO - 	at org.apache.storm.util$wrap_in_runtime.invoke(util.clj:54)
[2023-05-17T14:11:03.213+0530] {subprocess.py:93} INFO - 	at org.apache.storm.zookeeper$exists_node_QMARK_$fn__2165.invoke(zookeeper.clj:111)
[2023-05-17T14:11:03.213+0530] {subprocess.py:93} INFO - 	at org.apache.storm.zookeeper$exists_node_QMARK_.invoke(zookeeper.clj:107)
[2023-05-17T14:11:03.214+0530] {subprocess.py:93} INFO - 	at org.apache.storm.zookeeper$mkdirs.invoke(zookeeper.clj:127)
[2023-05-17T14:11:03.214+0530] {subprocess.py:93} INFO - 	at org.apache.storm.cluster_state.zookeeper_state_factory$_mkState$reify__12388.mkdirs(zookeeper_state_factory.clj:143)
[2023-05-17T14:11:03.215+0530] {subprocess.py:93} INFO - 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
[2023-05-17T14:11:03.215+0530] {subprocess.py:93} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[2023-05-17T14:11:03.217+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
[2023-05-17T14:11:03.217+0530] {subprocess.py:93} INFO - 	at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93)
[2023-05-17T14:11:03.217+0530] {subprocess.py:93} INFO - 	at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)
[2023-05-17T14:11:03.218+0530] {subprocess.py:93} INFO - 	at org.apache.storm.cluster$mk_storm_cluster_state$reify__3854.report_error(cluster.clj:660)
[2023-05-17T14:11:03.218+0530] {subprocess.py:93} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2023-05-17T14:11:03.218+0530] {subprocess.py:93} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[2023-05-17T14:11:03.218+0530] {subprocess.py:93} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[2023-05-17T14:11:03.218+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
[2023-05-17T14:11:03.219+0530] {subprocess.py:93} INFO - 	at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93)
[2023-05-17T14:11:03.219+0530] {subprocess.py:93} INFO - 	at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)
[2023-05-17T14:11:03.219+0530] {subprocess.py:93} INFO - 	at org.apache.storm.daemon.executor$throttled_report_error_fn$fn__9943.invoke(executor.clj:212)
[2023-05-17T14:11:03.219+0530] {subprocess.py:93} INFO - 	at org.apache.storm.daemon.executor$fn__10180$fn$reify__10205.reportError(executor.clj:851)
[2023-05-17T14:11:03.220+0530] {subprocess.py:93} INFO - 	at org.apache.storm.task.OutputCollector.reportError(OutputCollector.java:234)
[2023-05-17T14:11:03.220+0530] {subprocess.py:93} INFO - 	at org.apache.storm.task.ShellBolt.die(ShellBolt.java:297)
[2023-05-17T14:11:03.220+0530] {subprocess.py:93} INFO - 	at org.apache.storm.task.ShellBolt.access$400(ShellBolt.java:72)
[2023-05-17T14:11:03.220+0530] {subprocess.py:93} INFO - 	at org.apache.storm.task.ShellBolt$BoltReaderRunnable.run(ShellBolt.java:364)
[2023-05-17T14:11:03.221+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2023-05-17T14:11:03.221+0530] {subprocess.py:93} INFO - 2805189 [pool-48-thread-1] ERROR o.a.s.s.ShellSpout - Halting process: ShellSpout died. Command: [streamparse_run, -s json src.spouts.Kafkaspout.KafkaSpout], ProcessInfo pid:8587, name:kafka_spout exitCode:-1, errorString:
[2023-05-17T14:11:03.221+0530] {subprocess.py:93} INFO - java.lang.RuntimeException: subprocess heartbeat timeout
[2023-05-17T14:11:03.221+0530] {subprocess.py:93} INFO - 	at org.apache.storm.spout.ShellSpout$SpoutHeartbeatTimerTask.run(ShellSpout.java:299) [storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.221+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
[2023-05-17T14:11:03.222+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]
[2023-05-17T14:11:03.222+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]
[2023-05-17T14:11:03.222+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
[2023-05-17T14:11:03.224+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
[2023-05-17T14:11:03.224+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:829) [?:?]
[2023-05-17T14:11:03.228+0530] {subprocess.py:93} INFO - 2805399 [pool-48-thread-1] ERROR o.a.s.d.executor -
[2023-05-17T14:11:03.228+0530] {subprocess.py:93} INFO - java.lang.RuntimeException: subprocess heartbeat timeout
[2023-05-17T14:11:03.229+0530] {subprocess.py:93} INFO - 	at org.apache.storm.spout.ShellSpout$SpoutHeartbeatTimerTask.run(ShellSpout.java:299) [storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.229+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
[2023-05-17T14:11:03.229+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) [?:?]
[2023-05-17T14:11:03.229+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) [?:?]
[2023-05-17T14:11:03.231+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
[2023-05-17T14:11:03.232+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
[2023-05-17T14:11:03.233+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:829) [?:?]
[2023-05-17T14:11:03.233+0530] {subprocess.py:93} INFO - Caused by: java.lang.InterruptedException
[2023-05-17T14:11:03.234+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Object.wait(Native Method)
[2023-05-17T14:11:03.235+0530] {subprocess.py:93} INFO - 	at java.base/java.lang.Object.wait(Object.java:328)
[2023-05-17T14:11:03.235+0530] {subprocess.py:93} INFO - 	at org.apache.storm.shade.org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1407)
[2023-05-17T14:11:03.237+0530] {subprocess.py:93} INFO - 	at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1106)
[2023-05-17T14:11:03.237+0530] {subprocess.py:93} INFO - 	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl$3.call(ExistsBuilderImpl.java:268)
[2023-05-17T14:11:03.238+0530] {subprocess.py:93} INFO - 	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl$3.call(ExistsBuilderImpl.java:257)
[2023-05-17T14:11:03.239+0530] {subprocess.py:93} INFO - 2805397 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.d.executor -
[2023-05-17T14:11:03.239+0530] {subprocess.py:93} INFO - java.lang.RuntimeException: pid:8587, name:kafka_spout exitCode:-1, errorString:
[2023-05-17T14:11:03.239+0530] {subprocess.py:93} INFO - 	at org.apache.storm.spout.ShellSpout.die(ShellSpout.java:271) ~[storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.240+0530] {subprocess.py:93} INFO - 	at org.apache.storm.spout.ShellSpout.access$300(ShellSpout.java:48) ~[storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.241+0530] {subprocess.py:93} INFO - 	at org.apache.storm.spout.ShellSpout$SpoutHeartbeatTimerTask.run(ShellSpout.java:299) ~[storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.243+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[?:?]
[2023-05-17T14:11:03.243+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) ~[?:?]
[2023-05-17T14:11:03.243+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[?:?]
[2023-05-17T14:11:03.244+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[?:?]
[2023-05-17T14:11:03.244+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[?:?]
[2023-05-17T14:11:03.244+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:829) [?:?]
[2023-05-17T14:11:03.244+0530] {subprocess.py:93} INFO - Caused by: java.lang.RuntimeException: subprocess heartbeat timeout
[2023-05-17T14:11:03.245+0530] {subprocess.py:93} INFO - 	... 7 more
[2023-05-17T14:11:03.245+0530] {subprocess.py:93} INFO - 	at org.apache.storm.shade.org.apache.curator.connection.StandardConnectionHandlingPolicy.callWithRetry(StandardConnectionHandlingPolicy.java:64)
[2023-05-17T14:11:03.245+0530] {subprocess.py:93} INFO - 	at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:100)
[2023-05-17T14:11:03.246+0530] {subprocess.py:93} INFO - 	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl.pathInForegroundStandard(ExistsBuilderImpl.java:254)
[2023-05-17T14:11:03.246+0530] {subprocess.py:93} INFO - 	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl.pathInForeground(ExistsBuilderImpl.java:247)
[2023-05-17T14:11:03.246+0530] {subprocess.py:93} INFO - 	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl.forPath(ExistsBuilderImpl.java:206)
[2023-05-17T14:11:03.246+0530] {subprocess.py:93} INFO - 	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl.forPath(ExistsBuilderImpl.java:35)
[2023-05-17T14:11:03.246+0530] {subprocess.py:93} INFO - 	at org.apache.storm.zookeeper$exists_node_QMARK_$fn__2165.invoke(zookeeper.clj:110)
[2023-05-17T14:11:03.247+0530] {subprocess.py:93} INFO - 	... 22 more
[2023-05-17T14:11:03.247+0530] {subprocess.py:93} INFO - 2805410 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.d.executor - Error while reporting error to cluster, proceeding with shutdown
[2023-05-17T14:11:03.247+0530] {subprocess.py:93} INFO - 2805493 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.util - Halting process: ("Worker died")
[2023-05-17T14:11:03.248+0530] {subprocess.py:93} INFO - java.lang.RuntimeException: ("Worker died")
[2023-05-17T14:11:03.248+0530] {subprocess.py:93} INFO - 	at org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341) [storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.248+0530] {subprocess.py:93} INFO - 	at clojure.lang.RestFn.invoke(RestFn.java:423) [clojure-1.7.0.jar:?]
[2023-05-17T14:11:03.248+0530] {subprocess.py:93} INFO - 	at org.apache.storm.daemon.worker$fn__10799$fn__10800.invoke(worker.clj:788) [storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.248+0530] {subprocess.py:93} INFO - 	at org.apache.storm.daemon.executor$mk_executor_data$fn__9997$fn__9998.invoke(executor.clj:281) [storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.249+0530] {subprocess.py:93} INFO - 	at org.apache.storm.util$async_loop$fn__624.invoke(util.clj:494) [storm-core-1.2.3.jar:1.2.3]
[2023-05-17T14:11:03.249+0530] {subprocess.py:93} INFO - 	at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]
[2023-05-17T14:11:03.249+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:829) [?:?]
[2023-05-17T14:13:03.667+0530] {subprocess.py:93} INFO - 
[2023-05-17T14:13:03.670+0530] {subprocess.py:93} INFO - Fatal error: local() encountered an error (return code 1) while executing 'storm jar /home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar org.apache.storm.flux.Flux --local --no-splash --sleep 9223372036854775807 /tmp/tmpngtzyk6p.yaml'
[2023-05-17T14:13:03.670+0530] {subprocess.py:93} INFO - 
[2023-05-17T14:13:03.671+0530] {subprocess.py:93} INFO - Aborting.
[2023-05-17T14:13:03.687+0530] {subprocess.py:93} INFO - done
[2023-05-17T14:13:03.687+0530] {subprocess.py:93} INFO - [localhost] local: storm jar /home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar org.apache.storm.flux.Flux --local --no-splash --sleep 9223372036854775807 /tmp/tmpngtzyk6p.yaml
[2023-05-17T14:13:04.704+0530] {subprocess.py:97} INFO - Command exited with return code 1
[2023-05-17T14:13:05.103+0530] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/airflow/operators/bash.py", line 210, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2023-05-17T14:13:05.163+0530] {taskinstance.py:1368} INFO - Marking task as UP_FOR_RETRY. dag_id=storm_topology1, task_id=submit_topology, execution_date=20230517T073545, start_date=20230517T075320, end_date=20230517T084305
[2023-05-17T14:13:05.329+0530] {standard_task_runner.py:104} ERROR - Failed to execute job 331 for task submit_topology (Bash command failed. The command returned a non-zero exit code 1.; 8175)
[2023-05-17T14:13:05.372+0530] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2023-05-17T14:13:05.595+0530] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
