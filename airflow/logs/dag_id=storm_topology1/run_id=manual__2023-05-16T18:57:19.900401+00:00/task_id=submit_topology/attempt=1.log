[2023-05-17T00:27:24.614+0530] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: storm_topology1.submit_topology manual__2023-05-16T18:57:19.900401+00:00 [queued]>
[2023-05-17T00:27:24.635+0530] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: storm_topology1.submit_topology manual__2023-05-16T18:57:19.900401+00:00 [queued]>
[2023-05-17T00:27:24.635+0530] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2023-05-17T00:27:24.666+0530] {taskinstance.py:1350} INFO - Executing <Task(BashOperator): submit_topology> on 2023-05-16 18:57:19.900401+00:00
[2023-05-17T00:27:24.673+0530] {standard_task_runner.py:57} INFO - Started process 21986 to run task
[2023-05-17T00:27:24.678+0530] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'storm_topology1', 'submit_topology', 'manual__2023-05-16T18:57:19.900401+00:00', '--job-id', '288', '--raw', '--subdir', 'DAGS_FOLDER/kafkastorm.py', '--cfg-path', '/tmp/tmp0kq6tnzl']
[2023-05-17T00:27:24.681+0530] {standard_task_runner.py:85} INFO - Job 288: Subtask submit_topology
[2023-05-17T00:27:24.757+0530] {task_command.py:410} INFO - Running <TaskInstance: storm_topology1.submit_topology manual__2023-05-16T18:57:19.900401+00:00 [running]> on host nizam-HP-15-Notebook-PC
[2023-05-17T00:27:24.880+0530] {taskinstance.py:1568} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='your_name' AIRFLOW_CTX_DAG_ID='storm_topology1' AIRFLOW_CTX_TASK_ID='submit_topology' AIRFLOW_CTX_EXECUTION_DATE='2023-05-16T18:57:19.900401+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-05-16T18:57:19.900401+00:00'
[2023-05-17T00:27:24.882+0530] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2023-05-17T00:27:24.883+0530] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'cd /home/nizam/project/Kafka-Storm && sparse run --name first_topology']
[2023-05-17T00:27:24.893+0530] {subprocess.py:86} INFO - Output:
[2023-05-17T00:27:37.406+0530] {subprocess.py:93} INFO - Cleaning from prior builds...
[2023-05-17T00:27:39.787+0530] {subprocess.py:93} INFO - Creating topology Uber-JAR...
[2023-05-17T00:27:59.084+0530] {subprocess.py:93} INFO - Uber-JAR created: /home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar
[2023-05-17T00:28:08.475+0530] {subprocess.py:93} INFO - Removing _resources temporary directory...SLF4J: Class path contains multiple SLF4J bindings.
[2023-05-17T00:28:08.476+0530] {subprocess.py:93} INFO - SLF4J: Found binding in [jar:file:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[2023-05-17T00:28:08.476+0530] {subprocess.py:93} INFO - SLF4J: Found binding in [jar:file:/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[2023-05-17T00:28:08.477+0530] {subprocess.py:93} INFO - SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[2023-05-17T00:28:08.480+0530] {subprocess.py:93} INFO - SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
[2023-05-17T00:28:10.580+0530] {subprocess.py:93} INFO - Running: /usr/lib/jvm/java-11-openjdk-amd64/bin/java -client -Ddaemon.name= -Dstorm.options= -Dstorm.home=/home/nizam/Downloads/apache-storm-1.2.3 -Dstorm.log.dir=/home/nizam/Downloads/apache-storm-1.2.3/logs -Djava.library.path=/usr/local/lib:/opt/local/lib:/usr/lib -Dstorm.conf.file= -cp /home/nizam/Downloads/apache-storm-1.2.3/*:/home/nizam/Downloads/apache-storm-1.2.3/lib/*:/home/nizam/Downloads/apache-storm-1.2.3/extlib/*:/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar:/home/nizam/Downloads/apache-storm-1.2.3/conf:/home/nizam/Downloads/apache-storm-1.2.3/bin -Dstorm.jar=/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar -Dstorm.dependency.jars= -Dstorm.dependency.artifacts={} org.apache.storm.flux.Flux --local --no-splash --sleep 9223372036854775807 /tmp/tmpj5epcg92.yaml
[2023-05-17T00:28:10.734+0530] {subprocess.py:93} INFO - SLF4J: Class path contains multiple SLF4J bindings.
[2023-05-17T00:28:10.734+0530] {subprocess.py:93} INFO - SLF4J: Found binding in [jar:file:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[2023-05-17T00:28:10.735+0530] {subprocess.py:93} INFO - SLF4J: Found binding in [jar:file:/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
[2023-05-17T00:28:10.735+0530] {subprocess.py:93} INFO - SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
[2023-05-17T00:28:10.742+0530] {subprocess.py:93} INFO - SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
[2023-05-17T00:28:11.596+0530] {subprocess.py:93} INFO - Parsing file: /tmp/tmpj5epcg92.yaml
[2023-05-17T00:28:11.644+0530] {subprocess.py:93} INFO - 1040 [main] INFO  o.a.s.f.p.FluxParser - loading YAML from input stream...
[2023-05-17T00:28:11.649+0530] {subprocess.py:93} INFO - 1047 [main] INFO  o.a.s.f.p.FluxParser - Not performing property substitution.
[2023-05-17T00:28:11.650+0530] {subprocess.py:93} INFO - 1048 [main] INFO  o.a.s.f.p.FluxParser - Not performing environment variable substitution.
[2023-05-17T00:28:11.742+0530] {subprocess.py:93} INFO - 1140 [main] INFO  o.a.s.f.FluxBuilder - Detected DSL topology...
[2023-05-17T00:28:11.945+0530] {subprocess.py:93} INFO - 1342 [main] WARN  o.a.s.u.Utils - STORM-VERSION new 1.2.3 old null
[2023-05-17T00:28:11.946+0530] {subprocess.py:93} INFO - ---------- TOPOLOGY DETAILS ----------
[2023-05-17T00:28:11.946+0530] {subprocess.py:93} INFO - Topology Name: first_topology
[2023-05-17T00:28:11.946+0530] {subprocess.py:93} INFO - --------------- SPOUTS ---------------
[2023-05-17T00:28:11.946+0530] {subprocess.py:93} INFO - kafka_spout [1] (org.apache.storm.flux.wrappers.spouts.FluxShellSpout)
[2023-05-17T00:28:11.946+0530] {subprocess.py:93} INFO - ---------------- BOLTS ---------------
[2023-05-17T00:28:11.947+0530] {subprocess.py:93} INFO - filter_bolt [1] (org.apache.storm.flux.wrappers.bolts.FluxShellBolt)
[2023-05-17T00:28:11.947+0530] {subprocess.py:93} INFO - --------------- STREAMS ---------------
[2023-05-17T00:28:11.947+0530] {subprocess.py:93} INFO - kafka_spout --FIELDS--> filter_bolt
[2023-05-17T00:28:11.947+0530] {subprocess.py:93} INFO - --------------------------------------
[2023-05-17T00:28:11.947+0530] {subprocess.py:93} INFO - 1345 [main] INFO  o.a.s.f.Flux - Running in local mode...
[2023-05-17T00:28:16.079+0530] {subprocess.py:93} INFO - 5477 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT
[2023-05-17T00:28:16.079+0530] {subprocess.py:93} INFO - 5477 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:host.name=nizam-HP-15-Notebook-PC
[2023-05-17T00:28:16.079+0530] {subprocess.py:93} INFO - 5477 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.version=11.0.18
[2023-05-17T00:28:16.080+0530] {subprocess.py:93} INFO - 5477 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.vendor=Ubuntu
[2023-05-17T00:28:16.080+0530] {subprocess.py:93} INFO - 5477 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64
[2023-05-17T00:28:16.080+0530] {subprocess.py:93} INFO - 5477 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.class.path=/home/nizam/Downloads/apache-storm-1.2.3/*:/home/nizam/Downloads/apache-storm-1.2.3/lib/ring-cors-0.1.5.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/metrics-graphite-3.1.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/kryo-3.0.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/objenesis-2.1.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-slf4j-impl-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-api-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/disruptor-3.3.11.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-over-slf4j-1.6.6.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-core-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/clojure-1.7.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/storm-core-1.2.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/minlog-1.3.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/servlet-api-2.5.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/reflectasm-1.10.1.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/metrics-core-3.1.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/storm-rename-hack-1.2.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/asm-5.0.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/slf4j-api-1.7.21.jar:/home/nizam/Downloads/apache-storm-1.2.3/extlib/*:/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar:/home/nizam/Downloads/apache-storm-1.2.3/conf:/home/nizam/Downloads/apache-storm-1.2.3/bin
[2023-05-17T00:28:16.080+0530] {subprocess.py:93} INFO - 5477 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib
[2023-05-17T00:28:16.081+0530] {subprocess.py:93} INFO - 5477 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.io.tmpdir=/tmp
[2023-05-17T00:28:16.081+0530] {subprocess.py:93} INFO - 5478 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:java.compiler=<NA>
[2023-05-17T00:28:16.081+0530] {subprocess.py:93} INFO - 5478 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:os.name=Linux
[2023-05-17T00:28:16.081+0530] {subprocess.py:93} INFO - 5478 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:os.arch=amd64
[2023-05-17T00:28:16.081+0530] {subprocess.py:93} INFO - 5478 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:os.version=5.19.0-41-generic
[2023-05-17T00:28:16.082+0530] {subprocess.py:93} INFO - 5478 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:user.name=nizam
[2023-05-17T00:28:16.082+0530] {subprocess.py:93} INFO - 5478 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:user.home=/home/nizam
[2023-05-17T00:28:16.082+0530] {subprocess.py:93} INFO - 5478 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Server environment:user.dir=/home/nizam/project/Kafka-Storm
[2023-05-17T00:28:16.095+0530] {subprocess.py:93} INFO - 5493 [main] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 datadir /tmp/4764c888-302b-4c1b-8f53-f9ee8484a5c6/version-2 snapdir /tmp/4764c888-302b-4c1b-8f53-f9ee8484a5c6/version-2
[2023-05-17T00:28:16.117+0530] {subprocess.py:93} INFO - 5515 [main] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - binding to port 0.0.0.0/0.0.0.0:2000
[2023-05-17T00:28:16.123+0530] {subprocess.py:93} INFO - 5520 [main] INFO  o.a.s.zookeeper - Starting inprocess zookeeper at port 2000 and dir /tmp/4764c888-302b-4c1b-8f53-f9ee8484a5c6
[2023-05-17T00:28:16.246+0530] {subprocess.py:93} INFO - 5643 [main] INFO  o.a.s.d.nimbus - Starting Nimbus with conf {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.nimbus.zookeeper.acls.fixup=true, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=*****, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=["org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter"], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=null, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=["localhost"], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, backpressure.znode.timeout.secs=30, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/f65a4d04-cb2b-4098-8047-772179add1a6, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/f65a4d04-cb2b-4098-8047-772179add1a6, backpressure.znode.update.freq.secs=15, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, storm.nimbus.zookeeper.acls.check=true, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, logs.users=null, storm.cluster.metrics.consumer.publish.interval.secs=60, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, blobstore.superuser=nizam, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=[6700 6701 6702 6703], topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=["localhost"], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.thrift.socket.timeout.ms=600000, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, nimbus.host=localhost, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
[2023-05-17T00:28:16.247+0530] {subprocess.py:93} INFO - 5645 [main] INFO  o.a.s.n.NimbusInfo - Nimbus figures out its name to nizam-HP-15-Notebook-PC
[2023-05-17T00:28:16.317+0530] {subprocess.py:93} INFO - 5715 [main] INFO  o.a.s.s.o.a.c.u.Compatibility - Running in ZooKeeper 3.4.x compatibility mode
[2023-05-17T00:28:16.359+0530] {subprocess.py:93} INFO - 5757 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T00:28:16.367+0530] {subprocess.py:93} INFO - 5765 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT
[2023-05-17T00:28:16.368+0530] {subprocess.py:93} INFO - 5765 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:host.name=nizam-HP-15-Notebook-PC
[2023-05-17T00:28:16.368+0530] {subprocess.py:93} INFO - 5765 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.version=11.0.18
[2023-05-17T00:28:16.368+0530] {subprocess.py:93} INFO - 5765 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.vendor=Ubuntu
[2023-05-17T00:28:16.368+0530] {subprocess.py:93} INFO - 5766 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64
[2023-05-17T00:28:16.368+0530] {subprocess.py:93} INFO - 5766 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.class.path=/home/nizam/Downloads/apache-storm-1.2.3/*:/home/nizam/Downloads/apache-storm-1.2.3/lib/ring-cors-0.1.5.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/metrics-graphite-3.1.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/kryo-3.0.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/objenesis-2.1.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-slf4j-impl-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-api-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/disruptor-3.3.11.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-over-slf4j-1.6.6.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/log4j-core-2.8.2.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/clojure-1.7.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/storm-core-1.2.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/minlog-1.3.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/servlet-api-2.5.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/reflectasm-1.10.1.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/metrics-core-3.1.0.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/storm-rename-hack-1.2.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/asm-5.0.3.jar:/home/nizam/Downloads/apache-storm-1.2.3/lib/slf4j-api-1.7.21.jar:/home/nizam/Downloads/apache-storm-1.2.3/extlib/*:/home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar:/home/nizam/Downloads/apache-storm-1.2.3/conf:/home/nizam/Downloads/apache-storm-1.2.3/bin
[2023-05-17T00:28:16.369+0530] {subprocess.py:93} INFO - 5766 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib
[2023-05-17T00:28:16.369+0530] {subprocess.py:93} INFO - 5766 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.io.tmpdir=/tmp
[2023-05-17T00:28:16.369+0530] {subprocess.py:93} INFO - 5766 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:java.compiler=<NA>
[2023-05-17T00:28:16.369+0530] {subprocess.py:93} INFO - 5766 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:os.name=Linux
[2023-05-17T00:28:16.369+0530] {subprocess.py:93} INFO - 5766 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:os.arch=amd64
[2023-05-17T00:28:16.370+0530] {subprocess.py:93} INFO - 5767 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:os.version=5.19.0-41-generic
[2023-05-17T00:28:16.370+0530] {subprocess.py:93} INFO - 5767 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:user.name=nizam
[2023-05-17T00:28:16.370+0530] {subprocess.py:93} INFO - 5767 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:user.home=/home/nizam
[2023-05-17T00:28:16.370+0530] {subprocess.py:93} INFO - 5767 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Client environment:user.dir=/home/nizam/project/Kafka-Storm
[2023-05-17T00:28:16.371+0530] {subprocess.py:93} INFO - 5768 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@71285693
[2023-05-17T00:28:16.393+0530] {subprocess.py:93} INFO - 5791 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T00:28:16.395+0530] {subprocess.py:93} INFO - 5792 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T00:28:16.397+0530] {subprocess.py:93} INFO - 5795 [main] INFO  o.a.s.b.FileBlobStoreImpl - Creating new blob store based in /tmp/f65a4d04-cb2b-4098-8047-772179add1a6/blobs
[2023-05-17T00:28:16.399+0530] {subprocess.py:93} INFO - 5797 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:37978
[2023-05-17T00:28:16.400+0530] {subprocess.py:93} INFO - 5797 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T00:28:16.406+0530] {subprocess.py:93} INFO - 5804 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T00:28:16.407+0530] {subprocess.py:93} INFO - 5805 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@472719df
[2023-05-17T00:28:16.414+0530] {subprocess.py:93} INFO - 5811 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:37978
[2023-05-17T00:28:16.415+0530] {subprocess.py:93} INFO - 5811 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T00:28:16.415+0530] {subprocess.py:93} INFO - 5812 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T00:28:16.415+0530] {subprocess.py:93} INFO - 5813 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:37980
[2023-05-17T00:28:16.416+0530] {subprocess.py:93} INFO - 5813 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:37980
[2023-05-17T00:28:16.416+0530] {subprocess.py:93} INFO - 5811 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T00:28:16.417+0530] {subprocess.py:93} INFO - 5814 [main] INFO  o.a.s.d.nimbus - Using default scheduler
[2023-05-17T00:28:16.419+0530] {subprocess.py:93} INFO - 5817 [main] INFO  o.a.s.n.NimbusInfo - Nimbus figures out its name to nizam-HP-15-Notebook-PC
[2023-05-17T00:28:16.424+0530] {subprocess.py:93} INFO - 5820 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.p.FileTxnLog - Creating new log file: log.1
[2023-05-17T00:28:16.456+0530] {subprocess.py:93} INFO - 5854 [main] INFO  o.a.s.n.NimbusInfo - Nimbus figures out its name to nizam-HP-15-Notebook-PC
[2023-05-17T00:28:16.478+0530] {subprocess.py:93} INFO - 5876 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x10000876fdf0000, negotiated timeout = 20000
[2023-05-17T00:28:16.479+0530] {subprocess.py:93} INFO - 5877 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x10000876fdf0000 with negotiated timeout 20000 for client /127.0.0.1:37978
[2023-05-17T00:28:16.487+0530] {subprocess.py:93} INFO - 5884 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x10000876fdf0001 with negotiated timeout 20000 for client /127.0.0.1:37980
[2023-05-17T00:28:16.488+0530] {subprocess.py:93} INFO - 5885 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x10000876fdf0001, negotiated timeout = 20000
[2023-05-17T00:28:16.489+0530] {subprocess.py:93} INFO - 5886 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T00:28:16.489+0530] {subprocess.py:93} INFO - 5886 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T00:28:16.492+0530] {subprocess.py:93} INFO - 5885 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T00:28:16.492+0530] {subprocess.py:93} INFO - 5889 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@69a76b74
[2023-05-17T00:28:16.493+0530] {subprocess.py:93} INFO - 5891 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T00:28:16.497+0530] {subprocess.py:93} INFO - 5894 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T00:28:16.497+0530] {subprocess.py:93} INFO - 5894 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T00:28:16.497+0530] {subprocess.py:93} INFO - 5894 [main-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
[2023-05-17T00:28:16.498+0530] {subprocess.py:93} INFO - 5895 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:37986
[2023-05-17T00:28:16.498+0530] {subprocess.py:93} INFO - 5895 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:37986
[2023-05-17T00:28:16.501+0530] {subprocess.py:93} INFO - 5899 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x10000876fdf0002, negotiated timeout = 20000
[2023-05-17T00:28:16.501+0530] {subprocess.py:93} INFO - 5899 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T00:28:16.502+0530] {subprocess.py:93} INFO - 5900 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x10000876fdf0002 with negotiated timeout 20000 for client /127.0.0.1:37986
[2023-05-17T00:28:16.502+0530] {subprocess.py:93} INFO - 5900 [main-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
[2023-05-17T00:28:16.532+0530] {subprocess.py:93} INFO - 5929 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-17T00:28:16.536+0530] {subprocess.py:93} INFO - 5934 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x10000876fdf0002
[2023-05-17T00:28:16.538+0530] {subprocess.py:93} INFO - 5936 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x10000876fdf0002
[2023-05-17T00:28:16.540+0530] {subprocess.py:93} INFO - 5937 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x10000876fdf0002 closed
[2023-05-17T00:28:16.540+0530] {subprocess.py:93} INFO - 5937 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] WARN  o.a.s.s.o.a.z.s.NIOServerCnxn - Unable to read additional data from client sessionid 0x10000876fdf0002, likely client has closed socket
[2023-05-17T00:28:16.541+0530] {subprocess.py:93} INFO - 5939 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:37986 which had sessionid 0x10000876fdf0002
[2023-05-17T00:28:16.543+0530] {subprocess.py:93} INFO - 5941 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T00:28:16.544+0530] {subprocess.py:93} INFO - 5942 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@85cd413
[2023-05-17T00:28:16.545+0530] {subprocess.py:93} INFO - 5943 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T00:28:16.547+0530] {subprocess.py:93} INFO - 5944 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T00:28:16.547+0530] {subprocess.py:93} INFO - 5944 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:37996
[2023-05-17T00:28:16.548+0530] {subprocess.py:93} INFO - 5944 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T00:28:16.548+0530] {subprocess.py:93} INFO - 5944 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:37996
[2023-05-17T00:28:16.550+0530] {subprocess.py:93} INFO - 5947 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T00:28:16.551+0530] {subprocess.py:93} INFO - 5947 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x10000876fdf0003 with negotiated timeout 20000 for client /127.0.0.1:37996
[2023-05-17T00:28:16.551+0530] {subprocess.py:93} INFO - 5947 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x10000876fdf0003, negotiated timeout = 20000
[2023-05-17T00:28:16.551+0530] {subprocess.py:93} INFO - 5948 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@2507a170
[2023-05-17T00:28:16.551+0530] {subprocess.py:93} INFO - 5948 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T00:28:16.552+0530] {subprocess.py:93} INFO - 5950 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T00:28:16.553+0530] {subprocess.py:93} INFO - 5951 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T00:28:16.553+0530] {subprocess.py:93} INFO - 5951 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T00:28:16.554+0530] {subprocess.py:93} INFO - 5951 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38002
[2023-05-17T00:28:16.556+0530] {subprocess.py:93} INFO - 5952 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38002
[2023-05-17T00:28:16.558+0530] {subprocess.py:93} INFO - 5956 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x10000876fdf0004 with negotiated timeout 20000 for client /127.0.0.1:38002
[2023-05-17T00:28:16.559+0530] {subprocess.py:93} INFO - 5956 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x10000876fdf0004, negotiated timeout = 20000
[2023-05-17T00:28:16.559+0530] {subprocess.py:93} INFO - 5957 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T00:28:16.633+0530] {subprocess.py:93} INFO - 6030 [main] INFO  o.a.s.zookeeper - Queued up for leader lock.
[2023-05-17T00:28:16.651+0530] {subprocess.py:93} INFO - 6049 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x10000876fdf0001 type:create cxid:0x1 zxid:0x12 txntype:-1 reqpath:n/a Error Path:/storm/leader-lock Error:KeeperErrorCode = NoNode for /storm/leader-lock
[2023-05-17T00:28:16.658+0530] {subprocess.py:93} INFO - 6055 [Curator-Framework-0] WARN  o.a.s.s.o.a.c.u.ZKPaths - The version of ZooKeeper being used doesn't support Container nodes. CreateMode.PERSISTENT will be used instead.
[2023-05-17T00:28:16.666+0530] {subprocess.py:93} INFO - 6062 [main] INFO  o.a.s.d.m.MetricsUtils - Using statistics reporter plugin:org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter
[2023-05-17T00:28:16.667+0530] {subprocess.py:93} INFO - 6065 [main] INFO  o.a.s.d.m.r.JmxPreparableReporter - Preparing...
[2023-05-17T00:28:16.696+0530] {subprocess.py:93} INFO - 6094 [main] INFO  o.a.s.d.common - Started statistics report plugin...
[2023-05-17T00:28:16.709+0530] {subprocess.py:93} INFO - 6107 [main-EventThread] INFO  o.a.s.z.Zookeeper - active-topology-blobs [] local-topology-blobs [] diff-topology-blobs []
[2023-05-17T00:28:16.711+0530] {subprocess.py:93} INFO - 6108 [main-EventThread] INFO  o.a.s.z.Zookeeper - active-topology-dependencies [] local-blobs [] diff-topology-dependencies []
[2023-05-17T00:28:16.711+0530] {subprocess.py:93} INFO - 6109 [main-EventThread] INFO  o.a.s.z.Zookeeper - Accepting leadership, all active topologies and corresponding dependencies found locally.
[2023-05-17T00:28:16.727+0530] {subprocess.py:93} INFO - 6125 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T00:28:16.728+0530] {subprocess.py:93} INFO - 6126 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@51468039
[2023-05-17T00:28:16.733+0530] {subprocess.py:93} INFO - 6130 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T00:28:16.734+0530] {subprocess.py:93} INFO - 6130 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T00:28:16.734+0530] {subprocess.py:93} INFO - 6131 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38008
[2023-05-17T00:28:16.737+0530] {subprocess.py:93} INFO - 6134 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T00:28:16.738+0530] {subprocess.py:93} INFO - 6135 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38008
[2023-05-17T00:28:16.739+0530] {subprocess.py:93} INFO - 6137 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x10000876fdf0005 with negotiated timeout 20000 for client /127.0.0.1:38008
[2023-05-17T00:28:16.740+0530] {subprocess.py:93} INFO - 6138 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x10000876fdf0005, negotiated timeout = 20000
[2023-05-17T00:28:16.741+0530] {subprocess.py:93} INFO - 6139 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T00:28:16.742+0530] {subprocess.py:93} INFO - 6140 [main-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
[2023-05-17T00:28:16.745+0530] {subprocess.py:93} INFO - 6143 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-17T00:28:16.747+0530] {subprocess.py:93} INFO - 6145 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x10000876fdf0005
[2023-05-17T00:28:16.749+0530] {subprocess.py:93} INFO - 6146 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x10000876fdf0005 closed
[2023-05-17T00:28:16.749+0530] {subprocess.py:93} INFO - 6147 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x10000876fdf0005
[2023-05-17T00:28:16.749+0530] {subprocess.py:93} INFO - 6147 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:38008 which had sessionid 0x10000876fdf0005
[2023-05-17T00:28:16.751+0530] {subprocess.py:93} INFO - 6148 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T00:28:16.752+0530] {subprocess.py:93} INFO - 6149 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@18dbc1b
[2023-05-17T00:28:16.753+0530] {subprocess.py:93} INFO - 6151 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T00:28:16.757+0530] {subprocess.py:93} INFO - 6151 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T00:28:16.757+0530] {subprocess.py:93} INFO - 6153 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T00:28:16.757+0530] {subprocess.py:93} INFO - 6153 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38020
[2023-05-17T00:28:16.758+0530] {subprocess.py:93} INFO - 6153 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@7c5ac0
[2023-05-17T00:28:16.758+0530] {subprocess.py:93} INFO - 6154 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T00:28:16.758+0530] {subprocess.py:93} INFO - 6155 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38020
[2023-05-17T00:28:16.760+0530] {subprocess.py:93} INFO - 6158 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T00:28:16.761+0530] {subprocess.py:93} INFO - 6159 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x10000876fdf0006 with negotiated timeout 20000 for client /127.0.0.1:38020
[2023-05-17T00:28:16.761+0530] {subprocess.py:93} INFO - 6159 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x10000876fdf0006, negotiated timeout = 20000
[2023-05-17T00:28:16.762+0530] {subprocess.py:93} INFO - 6159 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T00:28:16.762+0530] {subprocess.py:93} INFO - 6159 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T00:28:16.762+0530] {subprocess.py:93} INFO - 6160 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T00:28:16.762+0530] {subprocess.py:93} INFO - 6160 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38032
[2023-05-17T00:28:16.763+0530] {subprocess.py:93} INFO - 6161 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38032
[2023-05-17T00:28:16.765+0530] {subprocess.py:93} INFO - 6162 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x10000876fdf0007 with negotiated timeout 20000 for client /127.0.0.1:38032
[2023-05-17T00:28:16.765+0530] {subprocess.py:93} INFO - 6163 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x10000876fdf0007, negotiated timeout = 20000
[2023-05-17T00:28:16.765+0530] {subprocess.py:93} INFO - 6163 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T00:28:16.766+0530] {subprocess.py:93} INFO - 6163 [main-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
[2023-05-17T00:28:16.768+0530] {subprocess.py:93} INFO - 6166 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-17T00:28:16.770+0530] {subprocess.py:93} INFO - 6168 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x10000876fdf0007
[2023-05-17T00:28:16.775+0530] {subprocess.py:93} INFO - 6172 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x10000876fdf0007 closed
[2023-05-17T00:28:16.776+0530] {subprocess.py:93} INFO - 6174 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T00:28:16.777+0530] {subprocess.py:93} INFO - 6174 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x10000876fdf0007
[2023-05-17T00:28:16.777+0530] {subprocess.py:93} INFO - 6170 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:38032 which had sessionid 0x10000876fdf0007
[2023-05-17T00:28:16.778+0530] {subprocess.py:93} INFO - 6176 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@6a7aa675
[2023-05-17T00:28:16.780+0530] {subprocess.py:93} INFO - 6178 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T00:28:16.781+0530] {subprocess.py:93} INFO - 6179 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T00:28:16.782+0530] {subprocess.py:93} INFO - 6179 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T00:28:16.782+0530] {subprocess.py:93} INFO - 6180 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38042
[2023-05-17T00:28:16.783+0530] {subprocess.py:93} INFO - 6181 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38042
[2023-05-17T00:28:16.785+0530] {subprocess.py:93} INFO - 6183 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x10000876fdf0008 with negotiated timeout 20000 for client /127.0.0.1:38042
[2023-05-17T00:28:16.785+0530] {subprocess.py:93} INFO - 6183 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x10000876fdf0008, negotiated timeout = 20000
[2023-05-17T00:28:16.786+0530] {subprocess.py:93} INFO - 6184 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T00:28:16.851+0530] {subprocess.py:93} INFO - 6249 [main] INFO  o.a.s.z.Zookeeper - Staring ZK Curator
[2023-05-17T00:28:16.851+0530] {subprocess.py:93} INFO - 6249 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T00:28:16.853+0530] {subprocess.py:93} INFO - 6250 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@6d5508a5
[2023-05-17T00:28:16.859+0530] {subprocess.py:93} INFO - 6256 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T00:28:16.859+0530] {subprocess.py:93} INFO - 6257 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T00:28:16.860+0530] {subprocess.py:93} INFO - 6257 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38052
[2023-05-17T00:28:16.860+0530] {subprocess.py:93} INFO - 6258 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38052
[2023-05-17T00:28:16.860+0530] {subprocess.py:93} INFO - 6258 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T00:28:16.863+0530] {subprocess.py:93} INFO - 6261 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x10000876fdf0009 with negotiated timeout 20000 for client /127.0.0.1:38052
[2023-05-17T00:28:16.864+0530] {subprocess.py:93} INFO - 6261 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x10000876fdf0009, negotiated timeout = 20000
[2023-05-17T00:28:16.864+0530] {subprocess.py:93} INFO - 6262 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T00:28:16.869+0530] {subprocess.py:93} INFO - 6266 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-17T00:28:16.870+0530] {subprocess.py:93} INFO - 6267 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x10000876fdf0009
[2023-05-17T00:28:16.874+0530] {subprocess.py:93} INFO - 6268 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x10000876fdf0009 closed
[2023-05-17T00:28:16.874+0530] {subprocess.py:93} INFO - 6270 [main] INFO  o.a.s.z.Zookeeper - Staring ZK Curator
[2023-05-17T00:28:16.875+0530] {subprocess.py:93} INFO - 6270 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T00:28:16.875+0530] {subprocess.py:93} INFO - 6272 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x10000876fdf0009
[2023-05-17T00:28:16.876+0530] {subprocess.py:93} INFO - 6274 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@4ff0706c
[2023-05-17T00:28:16.876+0530] {subprocess.py:93} INFO - 6274 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:38052 which had sessionid 0x10000876fdf0009
[2023-05-17T00:28:16.878+0530] {subprocess.py:93} INFO - 6275 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T00:28:16.882+0530] {subprocess.py:93} INFO - 6278 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T00:28:16.883+0530] {subprocess.py:93} INFO - 6281 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38068
[2023-05-17T00:28:16.886+0530] {subprocess.py:93} INFO - 6284 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T00:28:16.887+0530] {subprocess.py:93} INFO - 6285 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38068
[2023-05-17T00:28:16.891+0530] {subprocess.py:93} INFO - 6288 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x10000876fdf000a with negotiated timeout 20000 for client /127.0.0.1:38068
[2023-05-17T00:28:16.892+0530] {subprocess.py:93} INFO - 6289 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x10000876fdf000a, negotiated timeout = 20000
[2023-05-17T00:28:16.894+0530] {subprocess.py:93} INFO - 6291 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T00:28:16.915+0530] {subprocess.py:93} INFO - 6312 [main] INFO  o.a.s.l.Localizer - Reconstruct localized resource: /tmp/d5bc8ef9-a999-417f-884e-323156dbf581/supervisor/usercache
[2023-05-17T00:28:16.916+0530] {subprocess.py:93} INFO - 6312 [main] WARN  o.a.s.l.Localizer - No left over resources found for any user during reconstructing of local resources at: /tmp/d5bc8ef9-a999-417f-884e-323156dbf581/supervisor/usercache
[2023-05-17T00:28:16.934+0530] {subprocess.py:93} INFO - 6325 [main] INFO  o.a.s.d.s.Supervisor - Starting Supervisor with conf {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.nimbus.zookeeper.acls.fixup=true, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=*****, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=[org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=null, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=[localhost], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, backpressure.znode.timeout.secs=30, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/f65a4d04-cb2b-4098-8047-772179add1a6, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/d5bc8ef9-a999-417f-884e-323156dbf581, backpressure.znode.update.freq.secs=15, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, storm.nimbus.zookeeper.acls.check=true, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, logs.users=null, storm.cluster.metrics.consumer.publish.interval.secs=60, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, blobstore.superuser=nizam, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=[1024, 1025, 1026], topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=[localhost], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.thrift.socket.timeout.ms=600000, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, nimbus.host=localhost, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
[2023-05-17T00:28:16.958+0530] {subprocess.py:93} INFO - 6356 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1024 Starting in state EMPTY - assignment null
[2023-05-17T00:28:16.958+0530] {subprocess.py:93} INFO - 6356 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1025 Starting in state EMPTY - assignment null
[2023-05-17T00:28:16.959+0530] {subprocess.py:93} INFO - 6356 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1026 Starting in state EMPTY - assignment null
[2023-05-17T00:28:16.960+0530] {subprocess.py:93} INFO - 6357 [main] INFO  o.a.s.l.AsyncLocalizer - Cleaning up unused topologies in /tmp/d5bc8ef9-a999-417f-884e-323156dbf581/supervisor/stormdist
[2023-05-17T00:28:16.963+0530] {subprocess.py:93} INFO - 6361 [main] INFO  o.a.s.d.s.Supervisor - Starting supervisor with id ac035a4c-8917-4785-80b2-04de97a6e51c at host nizam-HP-15-Notebook-PC.
[2023-05-17T00:28:16.966+0530] {subprocess.py:93} INFO - 6363 [main] INFO  o.a.s.z.Zookeeper - Staring ZK Curator
[2023-05-17T00:28:16.966+0530] {subprocess.py:93} INFO - 6363 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T00:28:16.968+0530] {subprocess.py:93} INFO - 6365 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@4a3509b0
[2023-05-17T00:28:16.971+0530] {subprocess.py:93} INFO - 6369 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T00:28:16.973+0530] {subprocess.py:93} INFO - 6370 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T00:28:16.973+0530] {subprocess.py:93} INFO - 6371 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38084
[2023-05-17T00:28:16.974+0530] {subprocess.py:93} INFO - 6372 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T00:28:16.975+0530] {subprocess.py:93} INFO - 6372 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38084
[2023-05-17T00:28:16.976+0530] {subprocess.py:93} INFO - 6374 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x10000876fdf000b with negotiated timeout 20000 for client /127.0.0.1:38084
[2023-05-17T00:28:16.976+0530] {subprocess.py:93} INFO - 6374 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x10000876fdf000b, negotiated timeout = 20000
[2023-05-17T00:28:16.977+0530] {subprocess.py:93} INFO - 6375 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T00:28:16.980+0530] {subprocess.py:93} INFO - 6378 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-17T00:28:16.983+0530] {subprocess.py:93} INFO - 6380 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x10000876fdf000b
[2023-05-17T00:28:16.986+0530] {subprocess.py:93} INFO - 6383 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:38084 which had sessionid 0x10000876fdf000b
[2023-05-17T00:28:16.986+0530] {subprocess.py:93} INFO - 6383 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x10000876fdf000b closed
[2023-05-17T00:28:16.988+0530] {subprocess.py:93} INFO - 6385 [main] INFO  o.a.s.z.Zookeeper - Staring ZK Curator
[2023-05-17T00:28:16.989+0530] {subprocess.py:93} INFO - 6385 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T00:28:16.989+0530] {subprocess.py:93} INFO - 6385 [main-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x10000876fdf000b
[2023-05-17T00:28:16.990+0530] {subprocess.py:93} INFO - 6386 [main] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@48860139
[2023-05-17T00:28:16.991+0530] {subprocess.py:93} INFO - 6388 [main] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T00:28:16.991+0530] {subprocess.py:93} INFO - 6389 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T00:28:16.992+0530] {subprocess.py:93} INFO - 6390 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38088
[2023-05-17T00:28:16.992+0530] {subprocess.py:93} INFO - 6390 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T00:28:16.993+0530] {subprocess.py:93} INFO - 6390 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38088
[2023-05-17T00:28:16.994+0530] {subprocess.py:93} INFO - 6392 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x10000876fdf000c with negotiated timeout 20000 for client /127.0.0.1:38088
[2023-05-17T00:28:16.994+0530] {subprocess.py:93} INFO - 6392 [main-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x10000876fdf000c, negotiated timeout = 20000
[2023-05-17T00:28:16.994+0530] {subprocess.py:93} INFO - 6392 [main-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T00:28:17.007+0530] {subprocess.py:93} INFO - 6404 [main] INFO  o.a.s.l.Localizer - Reconstruct localized resource: /tmp/df607c88-507c-4fb4-9df3-2a31d51ea5a6/supervisor/usercache
[2023-05-17T00:28:17.007+0530] {subprocess.py:93} INFO - 6405 [main] WARN  o.a.s.l.Localizer - No left over resources found for any user during reconstructing of local resources at: /tmp/df607c88-507c-4fb4-9df3-2a31d51ea5a6/supervisor/usercache
[2023-05-17T00:28:17.011+0530] {subprocess.py:93} INFO - 6406 [main] INFO  o.a.s.d.s.Supervisor - Starting Supervisor with conf {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.nimbus.zookeeper.acls.fixup=true, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=*****, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=[org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=null, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=[localhost], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, backpressure.znode.timeout.secs=30, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/f65a4d04-cb2b-4098-8047-772179add1a6, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/df607c88-507c-4fb4-9df3-2a31d51ea5a6, backpressure.znode.update.freq.secs=15, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, storm.nimbus.zookeeper.acls.check=true, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, logs.users=null, storm.cluster.metrics.consumer.publish.interval.secs=60, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, blobstore.superuser=nizam, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=[1027, 1028, 1029], topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=[localhost], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.thrift.socket.timeout.ms=600000, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, nimbus.host=localhost, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
[2023-05-17T00:28:17.017+0530] {subprocess.py:93} INFO - 6414 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1027 Starting in state EMPTY - assignment null
[2023-05-17T00:28:17.017+0530] {subprocess.py:93} INFO - 6415 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1028 Starting in state EMPTY - assignment null
[2023-05-17T00:28:17.017+0530] {subprocess.py:93} INFO - 6415 [main] WARN  o.a.s.d.s.Slot - SLOT nizam-HP-15-Notebook-PC:1029 Starting in state EMPTY - assignment null
[2023-05-17T00:28:17.017+0530] {subprocess.py:93} INFO - 6415 [main] INFO  o.a.s.l.AsyncLocalizer - Cleaning up unused topologies in /tmp/df607c88-507c-4fb4-9df3-2a31d51ea5a6/supervisor/stormdist
[2023-05-17T00:28:17.022+0530] {subprocess.py:93} INFO - 6419 [main] INFO  o.a.s.d.s.Supervisor - Starting supervisor with id db39506e-710b-41a0-b8c1-c8cfa5163f75 at host nizam-HP-15-Notebook-PC.
[2023-05-17T00:28:17.041+0530] {subprocess.py:93} INFO - 6439 [main] WARN  o.a.s.u.Utils - STORM-VERSION new 1.2.3 old 1.2.3
[2023-05-17T00:28:17.128+0530] {subprocess.py:93} INFO - 6526 [main] INFO  o.a.s.d.nimbus - Received topology submission for first_topology (storm-1.2.3 JDK-11.0.18) with conf {topology.max.task.parallelism=null, topology.submitter.principal=, pystorm.log.backup_count=10, topology.acker.executors=1, topology.eventlogger.executors=0, pystorm.log.level=info, topology.workers=1, storm.zookeeper.superACL=null, pystorm.log.max_bytes=1000000, topology.python.path=/first_topology/bin/python, topology.users=clojure.lang.LazySeq@1, topology.submitter.user=nizam, topology.kryo.register=null, sudo_user=, virtualenv_root=, storm.workers.list=[], topology.kryo.decorators=clojure.lang.LazySeq@1, storm.id=first_topology-1-1684263497, topology.name=first_topology}
[2023-05-17T00:28:17.146+0530] {subprocess.py:93} INFO - 6544 [main] INFO  o.a.s.d.nimbus - uploadedJar
[2023-05-17T00:28:17.175+0530] {subprocess.py:93} INFO - 6573 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x10000876fdf0001 type:create cxid:0x9 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/storm/blobstoremaxkeysequencenumber Error:KeeperErrorCode = NoNode for /storm/blobstoremaxkeysequencenumber
[2023-05-17T00:28:17.190+0530] {subprocess.py:93} INFO - 6588 [main] INFO  o.a.s.cluster - setup-path/blobstore/first_topology-1-1684263497-stormconf.ser/nizam-HP-15-Notebook-PC:6627-1
[2023-05-17T00:28:17.227+0530] {subprocess.py:93} INFO - 6625 [main] INFO  o.a.s.cluster - setup-path/blobstore/first_topology-1-1684263497-stormcode.ser/nizam-HP-15-Notebook-PC:6627-1
[2023-05-17T00:28:17.257+0530] {subprocess.py:93} INFO - 6654 [main] INFO  o.a.s.d.nimbus - desired replication count 1 achieved, current-replication-count for conf key = 1, current-replication-count for code key = 1, current-replication-count for jar key = 1
[2023-05-17T00:28:17.343+0530] {subprocess.py:93} INFO - 6741 [main] INFO  o.a.s.d.nimbus - Activating first_topology: first_topology-1-1684263497
[2023-05-17T00:28:17.660+0530] {subprocess.py:93} INFO - 7057 [timer] INFO  o.a.s.s.EvenScheduler - Available slots: (["db39506e-710b-41a0-b8c1-c8cfa5163f75" 1027] ["db39506e-710b-41a0-b8c1-c8cfa5163f75" 1028] ["db39506e-710b-41a0-b8c1-c8cfa5163f75" 1029] ["ac035a4c-8917-4785-80b2-04de97a6e51c" 1024] ["ac035a4c-8917-4785-80b2-04de97a6e51c" 1025] ["ac035a4c-8917-4785-80b2-04de97a6e51c" 1026])
[2023-05-17T00:28:17.695+0530] {subprocess.py:93} INFO - 7092 [timer] INFO  o.a.s.d.nimbus - Setting new assignment for topology id first_topology-1-1684263497: #org.apache.storm.daemon.common.Assignment{:master-code-dir "/tmp/f65a4d04-cb2b-4098-8047-772179add1a6", :node->host {"db39506e-710b-41a0-b8c1-c8cfa5163f75" "nizam-HP-15-Notebook-PC"}, :executor->node+port {[2 2] ["db39506e-710b-41a0-b8c1-c8cfa5163f75" 1027], [1 1] ["db39506e-710b-41a0-b8c1-c8cfa5163f75" 1027], [3 3] ["db39506e-710b-41a0-b8c1-c8cfa5163f75" 1027]}, :executor->start-time-secs {[1 1] 1684263497, [2 2] 1684263497, [3 3] 1684263497}, :worker->resources {["db39506e-710b-41a0-b8c1-c8cfa5163f75" 1027] [0.0 0.0 0.0]}, :owner "nizam"}
[2023-05-17T00:28:19.024+0530] {subprocess.py:93} INFO - 8422 [SLOT_1027] INFO  o.a.s.d.s.Slot - STATE EMPTY msInState: 2008 -> WAITING_FOR_BASIC_LOCALIZATION msInState: 1
[2023-05-17T00:28:19.025+0530] {subprocess.py:93} INFO - 8422 [Async Localizer] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T00:28:19.026+0530] {subprocess.py:93} INFO - 8424 [Async Localizer] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@40ca8b52
[2023-05-17T00:28:19.028+0530] {subprocess.py:93} INFO - 8425 [Async Localizer-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T00:28:19.028+0530] {subprocess.py:93} INFO - 8426 [Async Localizer] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T00:28:19.028+0530] {subprocess.py:93} INFO - 8426 [Async Localizer] INFO  o.a.s.b.FileBlobStoreImpl - Creating new blob store based in /tmp/f65a4d04-cb2b-4098-8047-772179add1a6/blobs
[2023-05-17T00:28:19.029+0530] {subprocess.py:93} INFO - 8427 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38094
[2023-05-17T00:28:19.030+0530] {subprocess.py:93} INFO - 8428 [Async Localizer-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T00:28:19.032+0530] {subprocess.py:93} INFO - 8428 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38094
[2023-05-17T00:28:19.036+0530] {subprocess.py:93} INFO - 8434 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x10000876fdf000d with negotiated timeout 20000 for client /127.0.0.1:38094
[2023-05-17T00:28:19.036+0530] {subprocess.py:93} INFO - 8434 [Async Localizer-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x10000876fdf000d, negotiated timeout = 20000
[2023-05-17T00:28:19.037+0530] {subprocess.py:93} INFO - 8434 [Async Localizer-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T00:28:19.041+0530] {subprocess.py:93} INFO - 8439 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-17T00:28:19.043+0530] {subprocess.py:93} INFO - 8440 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x10000876fdf000d
[2023-05-17T00:28:19.044+0530] {subprocess.py:93} INFO - 8441 [Async Localizer-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x10000876fdf000d
[2023-05-17T00:28:19.044+0530] {subprocess.py:93} INFO - 8441 [Async Localizer] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x10000876fdf000d closed
[2023-05-17T00:28:19.045+0530] {subprocess.py:93} INFO - 8442 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:38094 which had sessionid 0x10000876fdf000d
[2023-05-17T00:28:19.093+0530] {subprocess.py:93} INFO - 8490 [Async Localizer] INFO  o.a.s.l.AsyncLocalizer - Extracting resources from jar at /home/nizam/project/Kafka-Storm/_build/Kafka_storm-0.0.1-SNAPSHOT-standalone.jar to /tmp/df607c88-507c-4fb4-9df3-2a31d51ea5a6/supervisor/tmp/81a2c1af-1a6d-4698-8f00-894cd653a044/
[2023-05-17T00:28:19.116+0530] {subprocess.py:93} INFO - 8514 [SLOT_1027] INFO  o.a.s.d.s.Slot - STATE WAITING_FOR_BASIC_LOCALIZATION msInState: 93 -> WAITING_FOR_BLOB_LOCALIZATION msInState: 0
[2023-05-17T00:28:19.127+0530] {subprocess.py:93} INFO - 8524 [SLOT_1027] INFO  o.a.s.d.s.Container - Setting up db39506e-710b-41a0-b8c1-c8cfa5163f75:d32cd19d-d540-4dc9-bd3c-0f8b94fe8be9
[2023-05-17T00:28:19.128+0530] {subprocess.py:93} INFO - 8526 [SLOT_1027] INFO  o.a.s.d.s.Container - GET worker-user for d32cd19d-d540-4dc9-bd3c-0f8b94fe8be9
[2023-05-17T00:28:19.154+0530] {subprocess.py:93} INFO - 8552 [SLOT_1027] INFO  o.a.s.d.s.Container - SET worker-user d32cd19d-d540-4dc9-bd3c-0f8b94fe8be9 nizam
[2023-05-17T00:28:19.167+0530] {subprocess.py:93} INFO - 8564 [SLOT_1027] INFO  o.a.s.d.worker - Launching worker for first_topology-1-1684263497 on db39506e-710b-41a0-b8c1-c8cfa5163f75:1027 with id d32cd19d-d540-4dc9-bd3c-0f8b94fe8be9 and conf {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.nimbus.zookeeper.acls.fixup=true, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=*****, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=["org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter"], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=null, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=["localhost"], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, backpressure.znode.timeout.secs=30, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/f65a4d04-cb2b-4098-8047-772179add1a6, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/df607c88-507c-4fb4-9df3-2a31d51ea5a6, backpressure.znode.update.freq.secs=15, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, storm.nimbus.zookeeper.acls.check=true, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, logs.users=null, storm.cluster.metrics.consumer.publish.interval.secs=60, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, blobstore.superuser=nizam, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=clojure.lang.LazySeq@100423, topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=["localhost"], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.thrift.socket.timeout.ms=600000, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, nimbus.host=localhost, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
[2023-05-17T00:28:19.168+0530] {subprocess.py:93} INFO - 8566 [SLOT_1027] INFO  o.a.s.m.StormMetricRegistry - Starting metrics reporters...
[2023-05-17T00:28:19.176+0530] {subprocess.py:93} INFO - 8574 [SLOT_1027] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T00:28:19.176+0530] {subprocess.py:93} INFO - 8574 [SLOT_1027] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@638704ae
[2023-05-17T00:28:19.178+0530] {subprocess.py:93} INFO - 8575 [SLOT_1027] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T00:28:19.179+0530] {subprocess.py:93} INFO - 8577 [SLOT_1027-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T00:28:19.179+0530] {subprocess.py:93} INFO - 8577 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38106
[2023-05-17T00:28:19.180+0530] {subprocess.py:93} INFO - 8578 [SLOT_1027-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T00:28:19.180+0530] {subprocess.py:93} INFO - 8578 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38106
[2023-05-17T00:28:19.182+0530] {subprocess.py:93} INFO - 8579 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x10000876fdf000e with negotiated timeout 20000 for client /127.0.0.1:38106
[2023-05-17T00:28:19.182+0530] {subprocess.py:93} INFO - 8580 [SLOT_1027-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x10000876fdf000e, negotiated timeout = 20000
[2023-05-17T00:28:19.182+0530] {subprocess.py:93} INFO - 8580 [SLOT_1027-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T00:28:19.182+0530] {subprocess.py:93} INFO - 8580 [SLOT_1027-EventThread] INFO  o.a.s.zookeeper - Zookeeper state update: :connected:none
[2023-05-17T00:28:19.185+0530] {subprocess.py:93} INFO - 8582 [Curator-Framework-0] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - backgroundOperationsLoop exiting
[2023-05-17T00:28:19.186+0530] {subprocess.py:93} INFO - 8584 [ProcessThread(sid:0 cport:2000):] INFO  o.a.s.s.o.a.z.s.PrepRequestProcessor - Processed session termination for sessionid: 0x10000876fdf000e
[2023-05-17T00:28:19.188+0530] {subprocess.py:93} INFO - 8585 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxn - Closed socket connection for client /127.0.0.1:38106 which had sessionid 0x10000876fdf000e
[2023-05-17T00:28:19.188+0530] {subprocess.py:93} INFO - 8586 [SLOT_1027-EventThread] INFO  o.a.s.s.o.a.z.ClientCnxn - EventThread shut down for session: 0x10000876fdf000e
[2023-05-17T00:28:19.189+0530] {subprocess.py:93} INFO - 8586 [SLOT_1027] INFO  o.a.s.s.o.a.z.ZooKeeper - Session: 0x10000876fdf000e closed
[2023-05-17T00:28:19.190+0530] {subprocess.py:93} INFO - 8588 [SLOT_1027] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Starting
[2023-05-17T00:28:19.191+0530] {subprocess.py:93} INFO - 8588 [SLOT_1027] INFO  o.a.s.s.o.a.z.ZooKeeper - Initiating client connection, connectString=localhost:2000/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@13947647
[2023-05-17T00:28:19.193+0530] {subprocess.py:93} INFO - 8590 [SLOT_1027] INFO  o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl - Default schema
[2023-05-17T00:28:19.193+0530] {subprocess.py:93} INFO - 8591 [SLOT_1027-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:2000. Will not attempt to authenticate using SASL (unknown error)
[2023-05-17T00:28:19.194+0530] {subprocess.py:93} INFO - 8592 [SLOT_1027-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Socket connection established to localhost/127.0.0.1:2000, initiating session
[2023-05-17T00:28:19.194+0530] {subprocess.py:93} INFO - 8592 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:38120
[2023-05-17T00:28:19.194+0530] {subprocess.py:93} INFO - 8592 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2000] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:38120
[2023-05-17T00:28:19.196+0530] {subprocess.py:93} INFO - 8594 [SyncThread:0] INFO  o.a.s.s.o.a.z.s.ZooKeeperServer - Established session 0x10000876fdf000f with negotiated timeout 20000 for client /127.0.0.1:38120
[2023-05-17T00:28:19.196+0530] {subprocess.py:93} INFO - 8594 [SLOT_1027-SendThread(localhost:2000)] INFO  o.a.s.s.o.a.z.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:2000, sessionid = 0x10000876fdf000f, negotiated timeout = 20000
[2023-05-17T00:28:19.196+0530] {subprocess.py:93} INFO - 8594 [SLOT_1027-EventThread] INFO  o.a.s.s.o.a.c.f.s.ConnectionStateManager - State change: CONNECTED
[2023-05-17T00:28:19.206+0530] {subprocess.py:93} INFO - 8604 [SLOT_1027] INFO  o.a.s.s.a.AuthUtils - Got AutoCreds []
[2023-05-17T00:28:19.211+0530] {subprocess.py:93} INFO - 8609 [SLOT_1027] INFO  o.a.s.d.worker - Reading Assignments.
[2023-05-17T00:28:19.402+0530] {subprocess.py:93} INFO - 8800 [SLOT_1027] INFO  o.a.s.d.worker - Registering IConnectionCallbacks for db39506e-710b-41a0-b8c1-c8cfa5163f75:1027
[2023-05-17T00:28:19.478+0530] {subprocess.py:93} INFO - 8875 [SLOT_1027] INFO  o.a.s.d.executor - Loading executor filter_bolt:[2 2]
[2023-05-17T00:28:19.517+0530] {subprocess.py:93} INFO - 8915 [SLOT_1027] INFO  o.a.s.d.executor - Loaded executor tasks filter_bolt:[2 2]
[2023-05-17T00:28:19.568+0530] {subprocess.py:93} INFO - WARNING: An illegal reflective access operation has occurred
[2023-05-17T00:28:19.568+0530] {subprocess.py:93} INFO - WARNING: Illegal reflective access by com.esotericsoftware.kryo.util.UnsafeUtil (file:/home/nizam/Downloads/apache-storm-1.2.3/lib/kryo-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int,java.lang.Object)
[2023-05-17T00:28:19.568+0530] {subprocess.py:93} INFO - WARNING: Please consider reporting this to the maintainers of com.esotericsoftware.kryo.util.UnsafeUtil
[2023-05-17T00:28:19.569+0530] {subprocess.py:93} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2023-05-17T00:28:19.569+0530] {subprocess.py:93} INFO - WARNING: All illegal access operations will be denied in a future release
[2023-05-17T00:28:19.807+0530] {subprocess.py:93} INFO - 9205 [SLOT_1027] INFO  o.a.s.d.executor - Finished loading executor filter_bolt:[2 2]
[2023-05-17T00:28:19.826+0530] {subprocess.py:93} INFO - 9224 [SLOT_1027] INFO  o.a.s.d.executor - Loading executor kafka_spout:[3 3]
[2023-05-17T00:28:19.830+0530] {subprocess.py:93} INFO - 9228 [SLOT_1027] INFO  o.a.s.d.executor - Loaded executor tasks kafka_spout:[3 3]
[2023-05-17T00:28:19.838+0530] {subprocess.py:93} INFO - 9236 [SLOT_1027] INFO  o.a.s.d.executor - Finished loading executor kafka_spout:[3 3]
[2023-05-17T00:28:19.850+0530] {subprocess.py:93} INFO - 9248 [SLOT_1027] INFO  o.a.s.d.executor - Loading executor __acker:[1 1]
[2023-05-17T00:28:19.851+0530] {subprocess.py:93} INFO - 9249 [SLOT_1027] INFO  o.a.s.d.executor - Loaded executor tasks __acker:[1 1]
[2023-05-17T00:28:19.855+0530] {subprocess.py:93} INFO - 9252 [SLOT_1027] INFO  o.a.s.d.executor - Finished loading executor __acker:[1 1]
[2023-05-17T00:28:19.865+0530] {subprocess.py:93} INFO - 9263 [SLOT_1027] INFO  o.a.s.d.executor - Loading executor __system:[-1 -1]
[2023-05-17T00:28:19.866+0530] {subprocess.py:93} INFO - 9264 [SLOT_1027] INFO  o.a.s.d.executor - Loaded executor tasks __system:[-1 -1]
[2023-05-17T00:28:19.870+0530] {subprocess.py:93} INFO - 9268 [SLOT_1027] INFO  o.a.s.d.executor - Finished loading executor __system:[-1 -1]
[2023-05-17T00:28:19.891+0530] {subprocess.py:93} INFO - 9289 [SLOT_1027] INFO  o.a.s.d.worker - Started with log levels: {"" #object[org.apache.logging.log4j.Level 0x28d97fe7 "INFO"], "org.apache.zookeeper" #object[org.apache.logging.log4j.Level 0x14c9349e "WARN"]}
[2023-05-17T00:28:19.900+0530] {subprocess.py:93} INFO - 9298 [SLOT_1027] INFO  o.a.s.d.worker - Worker has topology config {topology.builtin.metrics.bucket.size.secs=60, nimbus.childopts=-Xmx1024m, ui.filter.params=null, storm.cluster.mode=local, storm.messaging.netty.client_worker_threads=1, logviewer.max.per.worker.logs.size.mb=2048, supervisor.run.worker.as.user=false, topology.max.task.parallelism=null, topology.priority=29, zmq.threads=1, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, transactional.zookeeper.root=/transactional, topology.sleep.spout.wait.strategy.time.ms=1, ui.pagination=20, scheduler.display.resource=false, topology.max.replication.wait.time.sec=60, drpc.invocations.port=3773, supervisor.localizer.cache.target.size.mb=10240, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, storm.messaging.netty.server_worker_threads=1, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, resource.aware.scheduler.eviction.strategy=org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy, topology.max.error.report.per.interval=5, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, zmq.hwm=0, storm.group.mapping.service.params=null, worker.profiler.enabled=false, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, supervisor.worker.shutdown.sleep.secs=3, pacemaker.host=localhost, storm.zookeeper.retry.times=5, ui.actions.enabled=true, zmq.linger.millis=0, supervisor.enable=true, topology.stats.sample.rate=0.05, storm.nimbus.zookeeper.acls.fixup=true, storm.messaging.netty.min_wait_ms=100, worker.log.level.reset.poll.secs=30, storm.zookeeper.port=2000, supervisor.heartbeat.frequency.secs=5, topology.enable.message.timeouts=true, supervisor.cpu.capacity=400.0, drpc.worker.threads=64, supervisor.blobstore.download.thread.count=5, task.backpressure.poll.secs=30, drpc.queue.size=128, topology.backpressure.enable=false, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.blobstore.inputstream.buffer.size.bytes=65536, topology.shellbolt.max.pending=100, drpc.https.keystore.password=*****, nimbus.code.sync.freq.secs=120, logviewer.port=8000, topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, topology.executor.send.buffer.size=1024, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, pacemaker.auth.method=NONE, storm.daemon.metrics.reporter.plugins=["org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter"], topology.worker.logwriter.childopts=-Xmx64m, topology.spout.wait.strategy=org.apache.storm.spout.SleepSpoutWaitStrategy, ui.host=0.0.0.0, topology.submitter.principal=, pystorm.log.backup_count=10, storm.nimbus.retry.interval.millis=2000, nimbus.inbox.jar.expiration.secs=3600, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.acker.executors=1, topology.fall.back.on.java.serialization=true, topology.eventlogger.executors=0, supervisor.localizer.cleanup.interval.ms=600000, storm.zookeeper.servers=["localhost"], nimbus.thrift.threads=64, logviewer.cleanup.age.mins=10080, topology.worker.childopts=null, topology.classpath=null, supervisor.monitor.frequency.secs=3, nimbus.credential.renewers.freq.secs=600, backpressure.znode.timeout.secs=30, topology.skip.missing.kryo.registrations=true, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, pacemaker.kerberos.users=[], storm.group.mapping.service.cache.duration.secs=120, blobstore.dir=/tmp/f65a4d04-cb2b-4098-8047-772179add1a6, topology.testing.always.try.serialize=false, nimbus.monitor.freq.secs=10, storm.health.check.timeout.ms=5000, pystorm.log.level=info, supervisor.supervisors=[], topology.tasks=null, topology.bolts.outgoing.overflow.buffer.enable=false, storm.messaging.netty.socket.backlog=500, topology.workers=1, pacemaker.base.threads=10, storm.local.dir=/tmp/f65a4d04-cb2b-4098-8047-772179add1a6, backpressure.znode.update.freq.secs=15, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, storm.auth.simple-white-list.users=[], topology.disruptor.batch.timeout.millis=1, topology.message.timeout.secs=30, topology.state.synchronization.timeout.secs=60, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, supervisor.supervisors.commands=[], nimbus.blobstore.expiration.secs=600, logviewer.childopts=-Xmx128m, storm.nimbus.zookeeper.acls.check=true, topology.environment=null, topology.debug=false, topology.disruptor.batch.size=100, storm.disable.symlinks=false, storm.messaging.netty.max_retries=300, ui.childopts=-Xmx768m, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, storm.zookeeper.session.timeout=20000, drpc.childopts=-Xmx768m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.connection.timeout=15000, storm.zookeeper.auth.user=null, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, topology.max.spout.pending=null, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, nimbus.supervisor.timeout.secs=60, nimbus.task.timeout.secs=30, storm.zookeeper.superACL=null, drpc.port=3772, pacemaker.max.threads=50, storm.zookeeper.retry.intervalceiling.millis=30000, nimbus.thrift.port=6627, storm.auth.simple-acl.admins=[], topology.component.cpu.pcore.percent=10.0, supervisor.memory.capacity.mb=3072.0, storm.nimbus.retry.times=5, supervisor.worker.start.timeout.secs=120, storm.zookeeper.retry.interval=1000, pystorm.log.max_bytes=1000000, logs.users=null, storm.cluster.metrics.consumer.publish.interval.secs=60, worker.profiler.command=flight.bash, transactional.zookeeper.port=null, drpc.max_buffer_size=1048576, pacemaker.thread.timeout=10, task.credentials.poll.secs=30, topology.python.path=/first_topology/bin/python, blobstore.superuser=nizam, drpc.https.keystore.type=JKS, topology.worker.receiver.thread.count=1, topology.state.checkpoint.interval.ms=1000, supervisor.slots.ports=[6700 6701 6702 6703], topology.transfer.buffer.size=1024, storm.health.check.dir=healthchecks, topology.worker.shared.thread.pool.size=4, drpc.authorizer.acl.strict=false, nimbus.file.copy.expiration.secs=600, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, topology.executor.receive.buffer.size=1024, backpressure.disruptor.low.watermark=0.4, topology.users=[], nimbus.task.launch.secs=120, storm.local.mode.zmq=false, storm.messaging.netty.buffer_size=5242880, storm.cluster.state.store=org.apache.storm.cluster_state.zookeeper_state_factory, worker.heartbeat.frequency.secs=1, storm.log4j2.conf.dir=log4j2, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, storm.zookeeper.root=/storm, topology.submitter.user=nizam, topology.tick.tuple.freq.secs=null, drpc.https.port=-1, storm.workers.artifacts.dir=workers-artifacts, supervisor.blobstore.download.max_retries=3, task.refresh.poll.secs=10, storm.exhibitor.port=8080, task.heartbeat.frequency.secs=3, pacemaker.port=6699, storm.messaging.netty.max_wait_ms=1000, topology.component.resources.offheap.memory.mb=0.0, drpc.http.port=3774, topology.error.throttle.interval.secs=10, storm.messaging.transport=org.apache.storm.messaging.netty.Context, topology.disable.loadaware.messaging=false, storm.messaging.netty.authentication=false, topology.component.resources.onheap.memory.mb=128.0, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, topology.kryo.register=null, worker.gc.childopts=, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, nimbus.seeds=["localhost"], nimbus.queue.size=100000, nimbus.cleanup.inbox.freq.secs=600, storm.blobstore.replication.factor=3, worker.heap.memory.mb=768, logviewer.max.sum.worker.logs.size.mb=4096, pacemaker.childopts=-Xmx1024m, ui.users=null, transactional.zookeeper.servers=null, supervisor.worker.timeout.secs=30, storm.zookeeper.auth.password=null, storm.blobstore.acl.validation.enabled=false, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, storm.thrift.socket.timeout.ms=600000, supervisor.childopts=-Xmx256m, topology.worker.max.heap.size.mb=768.0, ui.http.x-frame-options=DENY, backpressure.disruptor.high.watermark=0.9, ui.filter=null, ui.header.buffer.bytes=4096, topology.min.replication.count=1, sudo_user=, topology.disruptor.wait.timeout.millis=1000, storm.nimbus.retry.intervalceiling.millis=60000, topology.trident.batch.emit.interval.millis=50, storm.auth.simple-acl.users=[], virtualenv_root=, drpc.invocations.threads=64, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib, ui.port=8080, storm.workers.list=[], topology.kryo.decorators=[], storm.id=first_topology-1-1684263497, topology.name=first_topology, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.messaging.netty.transfer.batch.size=262144, logviewer.appender.name=A1, nimbus.thrift.max_buffer_size=1048576, nimbus.host=localhost, storm.auth.simple-acl.users.commands=[], drpc.request.timeout.secs=600}
[2023-05-17T00:28:19.901+0530] {subprocess.py:93} INFO - 9299 [SLOT_1027] INFO  o.a.s.d.worker - Worker d32cd19d-d540-4dc9-bd3c-0f8b94fe8be9 for storm first_topology-1-1684263497 on db39506e-710b-41a0-b8c1-c8cfa5163f75:1027 has finished loading
[2023-05-17T00:28:19.902+0530] {subprocess.py:93} INFO - 9299 [SLOT_1027] INFO  o.a.s.d.s.Container - SET worker-user d32cd19d-d540-4dc9-bd3c-0f8b94fe8be9 nizam
[2023-05-17T00:28:19.903+0530] {subprocess.py:93} INFO - 9300 [SLOT_1027] INFO  o.a.s.d.s.Slot - STATE WAITING_FOR_BLOB_LOCALIZATION msInState: 786 -> WAITING_FOR_WORKER_START msInState: 0 topo:first_topology-1-1684263497 worker:d32cd19d-d540-4dc9-bd3c-0f8b94fe8be9
[2023-05-17T00:28:19.903+0530] {subprocess.py:93} INFO - 9300 [SLOT_1027] INFO  o.a.s.d.s.Slot - SLOT 1027: Changing current assignment from null to LocalAssignment(topology_id:first_topology-1-1684263497, executors:[ExecutorInfo(task_start:2, task_end:2), ExecutorInfo(task_start:1, task_end:1), ExecutorInfo(task_start:3, task_end:3)], resources:WorkerResources(mem_on_heap:0.0, mem_off_heap:0.0, cpu:0.0), owner:nizam)
[2023-05-17T00:28:19.908+0530] {subprocess.py:93} INFO - 9306 [SLOT_1027] INFO  o.a.s.d.s.Slot - STATE WAITING_FOR_WORKER_START msInState: 6 topo:first_topology-1-1684263497 worker:d32cd19d-d540-4dc9-bd3c-0f8b94fe8be9 -> RUNNING msInState: 0 topo:first_topology-1-1684263497 worker:d32cd19d-d540-4dc9-bd3c-0f8b94fe8be9
[2023-05-17T00:28:20.364+0530] {subprocess.py:93} INFO - 9759 [refresh-active-timer] INFO  o.a.s.d.worker - All connections are ready for worker db39506e-710b-41a0-b8c1-c8cfa5163f75:1027 with id d32cd19d-d540-4dc9-bd3c-0f8b94fe8be9
[2023-05-17T00:28:20.412+0530] {subprocess.py:93} INFO - 9810 [Thread-17-filter_bolt-executor[2 2]] INFO  o.a.s.d.executor - Preparing bolt filter_bolt:(2)
[2023-05-17T00:28:20.418+0530] {subprocess.py:93} INFO - 9816 [Thread-17-filter_bolt-executor[2 2]] INFO  o.a.s.u.ShellProcess - Storm multilang serializer: org.apache.storm.multilang.JsonSerializer
[2023-05-17T00:28:20.444+0530] {subprocess.py:93} INFO - 9840 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.d.executor - Opening spout kafka_spout:(3)
[2023-05-17T00:28:20.448+0530] {subprocess.py:93} INFO - 9845 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.u.ShellProcess - Storm multilang serializer: org.apache.storm.multilang.JsonSerializer
[2023-05-17T00:28:20.463+0530] {subprocess.py:93} INFO - 9854 [Thread-21-__acker-executor[1 1]] INFO  o.a.s.d.executor - Preparing bolt __acker:(1)
[2023-05-17T00:28:20.464+0530] {subprocess.py:93} INFO - 9856 [Thread-21-__acker-executor[1 1]] INFO  o.a.s.d.executor - Prepared bolt __acker:(1)
[2023-05-17T00:28:20.471+0530] {subprocess.py:93} INFO - 9869 [Thread-23-__system-executor[-1 -1]] INFO  o.a.s.d.executor - Preparing bolt __system:(-1)
[2023-05-17T00:28:20.484+0530] {subprocess.py:93} INFO - 9882 [Thread-23-__system-executor[-1 -1]] INFO  o.a.s.d.executor - Prepared bolt __system:(-1)
[2023-05-17T00:28:20.956+0530] {subprocess.py:93} INFO - 10354 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.s.ShellSpout - Launched subprocess with pid 22369
[2023-05-17T00:28:20.963+0530] {subprocess.py:93} INFO - 10361 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.d.executor - Opened spout kafka_spout:(3)
[2023-05-17T00:28:20.966+0530] {subprocess.py:93} INFO - 10363 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.d.executor - Activating spout kafka_spout:(3)
[2023-05-17T00:28:20.966+0530] {subprocess.py:93} INFO - 10364 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.s.ShellSpout - Start checking heartbeat...
[2023-05-17T00:28:20.969+0530] {subprocess.py:93} INFO - 10366 [Thread-19-kafka_spout-executor[3 3]] INFO  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout pystorm StormHandler logging enabled, so all messages at levels greater than "pystorm.log.level" (info) will be sent to Storm.
[2023-05-17T00:28:21.027+0530] {subprocess.py:93} INFO - 10424 [Thread-17-filter_bolt-executor[2 2]] INFO  o.a.s.t.ShellBolt - Launched subprocess with pid 22368
[2023-05-17T00:28:21.029+0530] {subprocess.py:93} INFO - 10427 [Thread-17-filter_bolt-executor[2 2]] INFO  o.a.s.t.ShellBolt - Start checking heartbeat...
[2023-05-17T00:28:21.030+0530] {subprocess.py:93} INFO - 10428 [Thread-26] INFO  o.a.s.t.ShellBolt - ShellLog pid:22368, name:filter_bolt pystorm StormHandler logging enabled, so all messages at levels greater than "pystorm.log.level" (info) will be sent to Storm.
[2023-05-17T00:28:21.031+0530] {subprocess.py:93} INFO - 10429 [Thread-17-filter_bolt-executor[2 2]] INFO  o.a.s.d.executor - Prepared bolt filter_bolt:(2)
[2023-05-17T00:37:44.770+0530] {subprocess.py:93} INFO - 574111 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:44,680 - kafka.client - Node coordinator-1001 connection failed -- refreshing metadata
[2023-05-17T00:37:44.830+0530] {subprocess.py:93} INFO - 574126 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:44,699 - kafka.coordinator - Marking the coordinator dead (node coordinator-1001) for group group1: Node Disconnected.
[2023-05-17T00:37:44.830+0530] {subprocess.py:93} INFO - 574126 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:44,703 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:44.831+0530] {subprocess.py:93} INFO - 574127 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:44,706 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:44.831+0530] {subprocess.py:93} INFO - 574127 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:44,707 - kafka.consumer.fetcher - Fetch to node 1001 failed: KafkaConnectionError: socket disconnected
[2023-05-17T00:37:44.832+0530] {subprocess.py:93} INFO - 574127 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:44,710 - kafka.coordinator - Error sending GroupCoordinatorRequest_v0 to node 1001 [KafkaConnectionError: socket disconnected]
[2023-05-17T00:37:44.938+0530] {subprocess.py:93} INFO - 574335 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:44,935 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:44.938+0530] {subprocess.py:93} INFO - 574335 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:44,936 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:45.042+0530] {subprocess.py:93} INFO - 574439 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:45,040 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:45.042+0530] {subprocess.py:93} INFO - 574440 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:45,041 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:45.045+0530] {subprocess.py:93} INFO - 574441 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:45,042 - kafka.coordinator - Error sending GroupCoordinatorRequest_v0 to node 1001 [KafkaConnectionError: socket disconnected]
[2023-05-17T00:37:45.197+0530] {subprocess.py:93} INFO - 574594 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:45,196 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:45.197+0530] {subprocess.py:93} INFO - 574595 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:45,196 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:45.356+0530] {subprocess.py:93} INFO - 574754 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:45,354 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:45.357+0530] {subprocess.py:93} INFO - 574754 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:45,355 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:45.513+0530] {subprocess.py:93} INFO - 574911 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:45,512 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:45.515+0530] {subprocess.py:93} INFO - 574913 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:45,514 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:45.674+0530] {subprocess.py:93} INFO - 575071 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:45,672 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:45.674+0530] {subprocess.py:93} INFO - 575072 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:45,673 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:45.827+0530] {subprocess.py:93} INFO - 575224 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:45,826 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:45.827+0530] {subprocess.py:93} INFO - 575225 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:45,826 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:45.981+0530] {subprocess.py:93} INFO - 575379 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:45,980 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:45.981+0530] {subprocess.py:93} INFO - 575379 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:45,981 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:46.138+0530] {subprocess.py:93} INFO - 575535 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:46,136 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:46.138+0530] {subprocess.py:93} INFO - 575536 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:46,137 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:46.292+0530] {subprocess.py:93} INFO - 575690 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:46,291 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:46.292+0530] {subprocess.py:93} INFO - 575690 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:46,291 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:46.446+0530] {subprocess.py:93} INFO - 575843 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:46,444 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:46.446+0530] {subprocess.py:93} INFO - 575843 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:46,445 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:46.599+0530] {subprocess.py:93} INFO - 575997 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:46,598 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:46.600+0530] {subprocess.py:93} INFO - 575997 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:46,599 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:46.756+0530] {subprocess.py:93} INFO - 576153 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:46,755 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:46.756+0530] {subprocess.py:93} INFO - 576154 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:46,755 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:46.910+0530] {subprocess.py:93} INFO - 576308 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:46,909 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:46.911+0530] {subprocess.py:93} INFO - 576308 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:46,910 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:47.065+0530] {subprocess.py:93} INFO - 576463 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:47,064 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:47.065+0530] {subprocess.py:93} INFO - 576463 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:47,064 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:47.222+0530] {subprocess.py:93} INFO - 576619 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:47,220 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:47.222+0530] {subprocess.py:93} INFO - 576619 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:47,221 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:47.377+0530] {subprocess.py:93} INFO - 576775 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:47,376 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:47.378+0530] {subprocess.py:93} INFO - 576775 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:47,376 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:47.533+0530] {subprocess.py:93} INFO - 576930 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:47,531 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:47.533+0530] {subprocess.py:93} INFO - 576931 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:47,532 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:47.687+0530] {subprocess.py:93} INFO - 577085 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:47,686 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:47.688+0530] {subprocess.py:93} INFO - 577085 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:47,687 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:47.843+0530] {subprocess.py:93} INFO - 577241 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:47,842 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:47.844+0530] {subprocess.py:93} INFO - 577241 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:47,842 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:47.998+0530] {subprocess.py:93} INFO - 577395 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:47,996 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:47.998+0530] {subprocess.py:93} INFO - 577396 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:47,997 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:48.155+0530] {subprocess.py:93} INFO - 577551 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:48,152 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:48.156+0530] {subprocess.py:93} INFO - 577553 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:48,153 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:48.309+0530] {subprocess.py:93} INFO - 577706 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:48,308 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:48.310+0530] {subprocess.py:93} INFO - 577707 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:48,308 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:48.463+0530] {subprocess.py:93} INFO - 577861 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:48,462 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:48.463+0530] {subprocess.py:93} INFO - 577861 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:48,463 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:48.617+0530] {subprocess.py:93} INFO - 578015 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:48,616 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:48.618+0530] {subprocess.py:93} INFO - 578015 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:48,617 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:48.773+0530] {subprocess.py:93} INFO - 578170 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:48,771 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:48.773+0530] {subprocess.py:93} INFO - 578170 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:48,771 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:48.929+0530] {subprocess.py:93} INFO - 578326 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:48,926 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:48.929+0530] {subprocess.py:93} INFO - 578326 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:48,927 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:49.087+0530] {subprocess.py:93} INFO - 578484 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:49,085 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:49.087+0530] {subprocess.py:93} INFO - 578485 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:49,086 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:49.241+0530] {subprocess.py:93} INFO - 578639 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:49,240 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:49.241+0530] {subprocess.py:93} INFO - 578639 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:49,240 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:49.396+0530] {subprocess.py:93} INFO - 578793 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:49,394 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:49.396+0530] {subprocess.py:93} INFO - 578793 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:49,395 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:49.551+0530] {subprocess.py:93} INFO - 578948 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:49,550 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:49.551+0530] {subprocess.py:93} INFO - 578949 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:49,550 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:49.705+0530] {subprocess.py:93} INFO - 579103 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:49,704 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:49.706+0530] {subprocess.py:93} INFO - 579103 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:49,705 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:49.859+0530] {subprocess.py:93} INFO - 579257 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:49,859 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:49.860+0530] {subprocess.py:93} INFO - 579257 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:49,859 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:50.018+0530] {subprocess.py:93} INFO - 579414 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:50,015 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:50.020+0530] {subprocess.py:93} INFO - 579414 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:50,015 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:50.176+0530] {subprocess.py:93} INFO - 579574 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:50,175 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:50.177+0530] {subprocess.py:93} INFO - 579574 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:50,175 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:50.330+0530] {subprocess.py:93} INFO - 579728 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:50,329 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:50.331+0530] {subprocess.py:93} INFO - 579728 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:50,329 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:50.485+0530] {subprocess.py:93} INFO - 579883 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:50,485 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:50.486+0530] {subprocess.py:93} INFO - 579883 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:50,485 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:50.639+0530] {subprocess.py:93} INFO - 580037 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:50,638 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:50.640+0530] {subprocess.py:93} INFO - 580037 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:50,639 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:50.794+0530] {subprocess.py:93} INFO - 580192 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:50,792 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:50.795+0530] {subprocess.py:93} INFO - 580192 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:50,793 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:50.949+0530] {subprocess.py:93} INFO - 580346 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:50,948 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:50.949+0530] {subprocess.py:93} INFO - 580347 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:50,948 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:51.103+0530] {subprocess.py:93} INFO - 580501 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:51,102 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:51.104+0530] {subprocess.py:93} INFO - 580501 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:51,103 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:51.258+0530] {subprocess.py:93} INFO - 580655 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:51,256 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:51.258+0530] {subprocess.py:93} INFO - 580656 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:51,257 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:51.411+0530] {subprocess.py:93} INFO - 580809 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:51,410 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:51.412+0530] {subprocess.py:93} INFO - 580809 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:51,411 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:51.567+0530] {subprocess.py:93} INFO - 580963 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:51,564 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:51.568+0530] {subprocess.py:93} INFO - 580965 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:51,565 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:51.721+0530] {subprocess.py:93} INFO - 581119 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:51,720 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:51.722+0530] {subprocess.py:93} INFO - 581120 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:51,721 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:51.876+0530] {subprocess.py:93} INFO - 581273 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:51,874 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:51.876+0530] {subprocess.py:93} INFO - 581274 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:51,875 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:52.030+0530] {subprocess.py:93} INFO - 581428 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:52,029 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:52.030+0530] {subprocess.py:93} INFO - 581428 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:52,029 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:53.165+0530] {subprocess.py:93} INFO - 582563 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:53,163 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:53.166+0530] {subprocess.py:93} INFO - 582563 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:53,164 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:53.266+0530] {subprocess.py:93} INFO - 582664 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:53,266 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:53.268+0530] {subprocess.py:93} INFO - 582665 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:53,266 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:53.269+0530] {subprocess.py:93} INFO - 582665 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:53,266 - kafka.coordinator - Error sending GroupCoordinatorRequest_v0 to node 1001 [KafkaConnectionError: socket disconnected]
[2023-05-17T00:37:53.424+0530] {subprocess.py:93} INFO - 582822 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:53,423 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:53.425+0530] {subprocess.py:93} INFO - 582823 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:53,424 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:53.579+0530] {subprocess.py:93} INFO - 582977 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:53,579 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:53.580+0530] {subprocess.py:93} INFO - 582978 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:53,579 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:53.736+0530] {subprocess.py:93} INFO - 583133 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:53,735 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:53.736+0530] {subprocess.py:93} INFO - 583134 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:53,735 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:53.893+0530] {subprocess.py:93} INFO - 583291 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:53,892 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:53.893+0530] {subprocess.py:93} INFO - 583291 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:53,893 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:55.029+0530] {subprocess.py:93} INFO - 584427 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:55,027 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:55.030+0530] {subprocess.py:93} INFO - 584427 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:55,028 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:55.131+0530] {subprocess.py:93} INFO - 584529 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:55,131 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:55.132+0530] {subprocess.py:93} INFO - 584529 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:55,131 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:55.132+0530] {subprocess.py:93} INFO - 584530 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:55,131 - kafka.coordinator - Error sending GroupCoordinatorRequest_v0 to node 1001 [KafkaConnectionError: socket disconnected]
[2023-05-17T00:37:55.288+0530] {subprocess.py:93} INFO - 584685 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:55,287 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:55.288+0530] {subprocess.py:93} INFO - 584686 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:55,287 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:55.442+0530] {subprocess.py:93} INFO - 584840 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:55,441 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:55.442+0530] {subprocess.py:93} INFO - 584840 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:55,441 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:55.596+0530] {subprocess.py:93} INFO - 584994 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:55,595 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:55.596+0530] {subprocess.py:93} INFO - 584994 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:55,595 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:55.750+0530] {subprocess.py:93} INFO - 585148 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:55,749 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:55.751+0530] {subprocess.py:93} INFO - 585148 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:55,750 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:55.906+0530] {subprocess.py:93} INFO - 585303 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:55,904 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:55.906+0530] {subprocess.py:93} INFO - 585303 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:55,905 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:56.067+0530] {subprocess.py:93} INFO - 585465 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:56,066 - kafka.conn - <BrokerConnection node_id=1001 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: socket disconnected
[2023-05-17T00:37:56.068+0530] {subprocess.py:93} INFO - 585465 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:56,066 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:56.220+0530] {subprocess.py:93} INFO - 585617 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:56,219 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:37:56.221+0530] {subprocess.py:93} INFO - 585618 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:56,220 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:56.423+0530] {subprocess.py:93} INFO - 585820 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:56,422 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:37:56.423+0530] {subprocess.py:93} INFO - 585820 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:56,422 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:56.726+0530] {subprocess.py:93} INFO - 586124 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:56,725 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:37:56.726+0530] {subprocess.py:93} INFO - 586124 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:56,726 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:57.230+0530] {subprocess.py:93} INFO - 586628 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:57,229 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:37:57.230+0530] {subprocess.py:93} INFO - 586628 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:57,230 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:57.986+0530] {subprocess.py:93} INFO - 587384 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:57,985 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:37:57.986+0530] {subprocess.py:93} INFO - 587384 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:57,986 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:37:58.994+0530] {subprocess.py:93} INFO - 588392 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:58,993 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:37:58.995+0530] {subprocess.py:93} INFO - 588392 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:37:58,994 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:00.055+0530] {subprocess.py:93} INFO - 589453 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:00,054 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:38:00.055+0530] {subprocess.py:93} INFO - 589453 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:00,054 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:01.216+0530] {subprocess.py:93} INFO - 590613 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:01,215 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:38:01.216+0530] {subprocess.py:93} INFO - 590614 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:01,215 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:02.425+0530] {subprocess.py:93} INFO - 591823 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:02,424 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:38:02.426+0530] {subprocess.py:93} INFO - 591823 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:02,425 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:03.583+0530] {subprocess.py:93} INFO - 592980 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:03,582 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:38:03.583+0530] {subprocess.py:93} INFO - 592981 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:03,582 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:04.492+0530] {subprocess.py:93} INFO - 593889 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:04,491 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:38:04.492+0530] {subprocess.py:93} INFO - 593890 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:04,491 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:05.603+0530] {subprocess.py:93} INFO - 595001 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:05,602 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:38:05.603+0530] {subprocess.py:93} INFO - 595001 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:05,602 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:06.512+0530] {subprocess.py:93} INFO - 595909 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:06,510 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:38:06.512+0530] {subprocess.py:93} INFO - 595910 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:06,511 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:07.671+0530] {subprocess.py:93} INFO - 597069 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:07,670 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:38:07.671+0530] {subprocess.py:93} INFO - 597069 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:07,671 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:08.580+0530] {subprocess.py:93} INFO - 597978 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:08,579 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:38:08.580+0530] {subprocess.py:93} INFO - 597978 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:08,580 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:09.591+0530] {subprocess.py:93} INFO - 598989 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:09,590 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:38:09.592+0530] {subprocess.py:93} INFO - 598989 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:09,591 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:10.549+0530] {subprocess.py:93} INFO - 599946 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:10,548 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:38:10.549+0530] {subprocess.py:93} INFO - 599947 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:10,548 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:11.458+0530] {subprocess.py:93} INFO - 600855 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:11,456 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:38:11.458+0530] {subprocess.py:93} INFO - 600856 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:11,457 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:12.718+0530] {subprocess.py:93} INFO - 602116 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:12,717 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:38:12.719+0530] {subprocess.py:93} INFO - 602117 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:12,718 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:13.981+0530] {subprocess.py:93} INFO - 603378 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:13,980 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:38:13.981+0530] {subprocess.py:93} INFO - 603379 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:13,980 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:15.142+0530] {subprocess.py:93} INFO - 604540 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:15,141 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:38:15.143+0530] {subprocess.py:93} INFO - 604540 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:15,142 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:16.151+0530] {subprocess.py:93} INFO - 605549 [Thread-19-kafka_spout-executor[3 3]] ERROR o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:16,150 - kafka.conn - Connect attempt to <BrokerConnection node_id=1001 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]> returned error 111. Disconnecting.
[2023-05-17T00:38:16.152+0530] {subprocess.py:93} INFO - 605549 [Thread-19-kafka_spout-executor[3 3]] WARN  o.a.s.s.ShellSpout - ShellLog pid:22369, name:kafka_spout 2023-05-17 00:38:16,151 - kafka.client - Node 1001 connection failed -- refreshing metadata
[2023-05-17T00:38:16.217+0530] {process_utils.py:131} INFO - Sending Signals.SIGTERM to group 21986. PIDs of all processes in the group: [21987, 22153, 22154, 22368, 22369, 21986]
[2023-05-17T00:38:16.243+0530] {process_utils.py:86} INFO - Sending the signal Signals.SIGTERM to group 21986
[2023-05-17T00:38:16.250+0530] {taskinstance.py:1540} ERROR - Received SIGTERM. Terminating subprocesses.
[2023-05-17T00:38:16.255+0530] {subprocess.py:104} INFO - Sending SIGTERM signal to process group
[2023-05-17T00:38:16.300+0530] {process_utils.py:79} INFO - Process psutil.Process(pid=22153, status='terminated', started='00:27:58') (22153) terminated with exit code None
[2023-05-17T00:38:16.615+0530] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/airflow/operators/bash.py", line 201, in execute
    result = self.subprocess_hook.run_command(
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/airflow/hooks/subprocess.py", line 91, in run_command
    for raw_line in iter(self.sub_process.stdout.readline, b""):
  File "/home/nizam/env_airflow/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1542, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2023-05-17T00:38:16.650+0530] {process_utils.py:79} INFO - Process psutil.Process(pid=22368, status='terminated', started='00:28:19') (22368) terminated with exit code None
[2023-05-17T00:38:16.676+0530] {taskinstance.py:1368} INFO - Marking task as FAILED. dag_id=storm_topology1, task_id=submit_topology, execution_date=20230516T185719, start_date=20230516T185724, end_date=20230516T190816
[2023-05-17T00:38:16.783+0530] {standard_task_runner.py:104} ERROR - Failed to execute job 288 for task submit_topology (Task received SIGTERM signal; 21986)
[2023-05-17T00:38:16.823+0530] {process_utils.py:79} INFO - Process psutil.Process(pid=21987, status='terminated', started='00:27:24') (21987) terminated with exit code None
[2023-05-17T00:38:16.824+0530] {process_utils.py:79} INFO - Process psutil.Process(pid=22369, status='terminated', started='00:28:19') (22369) terminated with exit code None
[2023-05-17T00:38:16.825+0530] {process_utils.py:79} INFO - Process psutil.Process(pid=21986, status='terminated', exitcode=1, started='00:27:24') (21986) terminated with exit code 1
[2023-05-17T00:38:16.826+0530] {process_utils.py:79} INFO - Process psutil.Process(pid=22154, status='terminated', started='00:27:58') (22154) terminated with exit code None
